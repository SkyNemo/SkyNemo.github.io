<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[排序算法-2：归并、快速]]></title>
    <url>%2F2019%2F06%2F27%2Falgo-sort-2%2F</url>
    <content type="text"><![CDATA[上一篇文章讲了冒泡排序、插入排序、选择排序这三种排序算法，它们的时间复杂度都是$O(n^2)$，比较高，适合小规模数据的排序。而归并排序和快速排序时间复杂度均为$O(n\log(n))$。适合大规模的数据排序。归并排序和快速排序有一个共同点，它们都用到了分治思想。 归并排序（Merge Sort）归并排序的核心思想还是蛮简单的。如果要排序一个数组，我们先把数组从中间分成前后两部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起，这样整个数组就都有序了 这就是分治思想。将一个大问题分解成小的子问题来解决。小的子问题解决了，大问题也就解决了。 分治思想与递归思想很像。分治是一种解决问题的处理思想，递归是一种编程技巧，分治算法一般都是用递归来实现的。 回顾：递归代码两要素：1.递推公式，2.终止条件。然后将递推公式翻译成递归代码。 所以，要想写出归并排序的代码，我们先写出归并排序的递推公式。 12345递推公式：merge_sort(p…r) = merge(merge_sort(p…q), merge_sort(q+1…r))终止条件：p &gt;= r 不用再继续分解 merge_sort(p..r)表示，给下标从p到r之间的数组排序。我们将这个排序问题转化为了两个子问题，merge_sort(p..q)和merge_sort(q+1..r)，其中下标q等于p和r的中间位置，也就是$\frac{(\ p\ +\ r\ )}{2}$。当下标从p到q和从q+1到r这两个子数组都排好序之后，我们再将两个有序的子数组合并在一起，这样下标从p到r之间的数据就也排好序了。当p &gt;= r时，表示数组中只有一个元素。 将递推公式转化成代码（C） 123456789void __merge_sort(int* arr, int p, int r) &#123; int q; if (p &gt;= r) return; q = (p + r) / 2; __merge_sort(arr, p, q); __merge_sort(arr, q + 1, r); __merge(arr, p, q, r);&#125; 你可能已经发现了， __merge()这个函数的作用就是，将已经有序的arr[p..q]和arr[q+1..r]合并成一个有序的数组。那这个过程具体该如何做呢？我们可以申请一个临时数组tmp，大小与arr[p..r]相同。我们用两个游标 i 和 j ，分别指向arr[p..q]和arr[q+1..r]的第一个元素。比较这两个元素arr[i]和arr[j]，如果arr[i]&lt;=arr[j]，我们就把arr[i]放入到临时数组tmp，并且 i 后移一位，否则将arr[j]放入到数组tmp， j 后移一位。继续上述比较过程，直到其中一个子数组中的所有数据都放入临时数组中，再把另一个数组中的数据依次加入到临时数组的未尾，这个时候，临时数组中存储的就是两个子数组合并之后的结果了。最后再把临时数组tmp中的数据拷贝到原数组arr[p..r]中。 代码如下（C）： 1234567891011121314151617181920212223242526272829303132// 合并两个有序数组arr[p]-arr[q]、arr[q+1]-arr[r]，p为下标起点，q为下标中点，r为下标终点void __merge(int* arr, int p, int q, int r) &#123; int* tmp; int i, j, k; // 申请一个临时数组，大小与arr[p...r]相同 tmp = (int*)malloc((r - p + 1) * sizeof(int)); if (!tmp) &#123; abort(); &#125; // 循环判断两个数组中较小的数据，拷贝至临时数组 for (i = p, j = q + 1, k = 0; i &lt;= q &amp;&amp; j &lt;= r;) &#123; if (arr[i] &lt;= arr[j]) &#123; tmp[k++] = arr[i++]; &#125; else &#123; tmp[k++] = arr[j++]; &#125; &#125; // 判断哪个子数组有剩余数据 ，拷贝至临时数组中 if (i == q + 1) &#123; for (; j &lt;= r;) tmp[k++] = arr[j++]; &#125; else &#123; for (; i &lt;= q;) tmp[k++] = arr[i++]; &#125; // 将tmp数组在内存区直接复制到原数组中 memcpy(arr + p, tmp, (r - p + 1) * sizeof(int)); free(tmp);&#125; 归并排序的性能分析还记得分析排序算法的三个问题吗？接下来，我们来看归并排序的三个问题。 归并排序是稳定的排序算法吗？ 是。我们可以很明显看出，归并排序稳不稳定关键要看__merge()函数，也就是两个有序子数组合并成一个大的有序数组的那部分代码。在合并的过程中，如果arr[p..q]和arr[q+1..r]之间有值相同的元素，我们可以先把arr[p..q]中的元素（前部分中的元素）放入tmp数组。这样就保证了值相同的元素，在合并前后的先后顺序不变。所以，归并排序是一个稳定的排序算法。 归并排序的时间复杂度是多少？ 情况 时间复杂度 最好、最坏、平均情况 $O(n\log(n))$ 递归时间复杂度分析较复杂，初学者可以跳过。 回顾：递归的适用场景是，一个问题a可以分解为多个子问题b、c，那求解问题a就可以分解为求解问题b、c。问题b、c解决之后，我们再把b、c的结果合并成a的结果。 如果我们定义求解问题a的时间是T(a)，求解问题b、c的时间分别是T(b)和T(c)，那我们就可以得到这样的递推关系式： 1T(a) = T(b) + T(c) + K 其中K等于将两个子问题b、c的结果合并成问题a的结果所消耗的时间。 套用这个公式，我们来分析一下归并排序的时间复杂度。 我们假设对n个元素进行归并排序需要的时间是T(n)，那分解成两个子数组排序的时间都是T($\frac{n}{2}$)。我们知道，merge0函数合并两个有序子数组的时间复杂度是$O(n)$。所以，套用前面的公式，归并排序的时间复杂度的计算公式就是: 12T(1) = C； n=1 时，只需要常量级的执行时间，所以表示为 C。T(n) = 2*T(n/2) + n； n&gt;1 继续分解： 1234567T(n) = 2*T(n/2) + n = 2*(2*T(n/4) + n/2) + n = 4*T(n/4) + 2*n = 4*(2*T(n/8) + n/4) + 2*n = 8*T(n/8) + 3*n = 8*(2*T(n/16) + n/8) + 3*n = 16*T(n/16) + 4*n ...... = 2^k * T(n/2^k) + k * n ...... 通过这样一步一步分解推导，我们可以得到 ：$$T(n) = 2\cdot k \cdot T(\frac{n}{2^k}) + k\cdot n$$当 $T(\frac{n}{2^k}) = T(1)$时，也就是$\frac{n}{2^k} = 1$，我们得到 $k = log_2(n)$。们将k值代入上面的公式，得到 $T(n) = c \cdot n + n \cdot \log_2(n)$ 。如果我们用大O标记法来表示的话，T(n)就等于$O(n\log(n))$。所以归并排序的时间复杂度是$O(n\log(n))$。 归并排序的空间复杂度是多少？ 归并排序的空间复杂度$O(n)$。不是原地排序算法。 因为归并排序的合并函数，在合并两个有序数组为一个有序数组时，需要借助额外的存储空间。合并完成之后，临时开辟的内存空间就被释放掉了。临时内存空间最大也不会超过n个数据的大小，所以空间复杂度是$O(n)$。 快速排序（Quick Sort）快速排序算法（Quicksort），简称为“快排”。快排利用的也是分治思想。 快排的思想是这样的：如果要排序数组中下标从p到r之间的一组数据arr[p..r]，我们选择p到r之间的任意一个数据作为pivot（分区点）。遍历p到r之间的数据，将小于pivot的放到左边，将大于pivot的放到右边，将pivot放到中间。经过这一步骤之后，数组p到r之间的数据就被分成了三个部分，前面p到q-1之间都是小于pivot的（arr[p..q-1] &lt; pivot），中间是pivot，后面的q+1到r之间是大于pivot的（arr[p..q-1] &gt;= pivot）。 根据分治、递归的处理思想，我们可以用递归排序下标从p到q-1之间的数据和下标从q+1到r之间的数据，直到区间缩小为1，就说明所有的数据都有序了。如果我们用递推公式来将上面的过程写出来的话，就是这样： 12345递推公式：quick_sort(p…r) = quick_sort(p…q-1) + quick_sort(q+1, r)终止条件：p &gt;= r 翻译成代码(C)就是 : 12345678910111213// 快速排序递归函数，p，r为下标void _quick_sort(int* arr, int p, int r) &#123; // q为分区点下标 int q; if (p &gt;= r) &#123; return; &#125; // 获取分区点,对两个分区再快排 q = _quick_partition(arr, p, r); _quick_sort(arr, p, q - 1); _quick_sort(arr, q + 1, r);&#125; 归并排序中有一个 __merge()合并函数，我们这里有一个_quick_partition()分区函数。_quick_partition()分区函数实际上我们前面已经讲过了，就是随机选择一个元素作为pivot（一般情况下，可以选择p到r区间的最后一个元素），然后对arr[p..r]分区，函数返回pivot的下标。如果我们不考虑空间消耗的话，_quick_partition()分区函数可以写得非常简单。我们申请两个临时数组X和Y，遍历arr[p..r]，将小于pivot的元素都拷贝到临时数组X，将大于pivot的元素都拷贝到临时数组Y，最后再将数组X和数组Y中数据顺序拷贝到arr[p..r]。 但是，如果按照这种思路实现的话，_quick_partition()函数就需要很多额外的内存空间，所以快排就不是原地排序算法了。如果我们希望快排是原地排序算法，那它的空间复杂度得是$O(1)$，那_quick_partition()分区函数就不能占用太多额外的内存空间，我们就需要在arr[p..r]的原地完成分区操作。 这里先给出伪代码 123456789101112partition(A, p, r) &#123; pivot := A[r] i := p for j := p to r-1 do &#123; if A[j] &lt; pivot &#123; swap A[i] with A[j] i := i+1 &#125; &#125; swap A[i] with A[r] return i&#125; 这里的思想类似于选择排序。我们通过游标 i把arr[p..r-1]分成两部分。arr[p..i-1]的元素都是小于pivot的，我们暂且叫它“已处理区间“，arr[i..r-1]是“未处理区间“。我们每次都从未处理的区间arr[i..r-1]中取一个元素arr[j]，与pivot对比，如果小于pivot，则将其加入到已处理区间的尾部，也就是A[i]的位置。数组的插入操作还记得吗？在数组某个位置插入元素，需要搬移数据，非常耗时。当时我们也讲了一种处理技巧，就是交换，在$O(1)$的时间复杂度内完成插入操作。这里我们也借助这个思想，只需要将arr[i]与arr[j]交换，就可以在$O(n)$时间复杂度内将arr[j]放到下标为i的位置。 翻译成代码（C）： 12345678910111213141516171819202122232425262728// 交换元素void swap(int* a, int* b) &#123; int tmp = *a; *a = *b; *b = tmp;&#125;// 分区函数，返回分区点下标,取a[r]为pivotint _quick_partition(int* a, int p, int r) &#123; // i将数组分成已处理区间（arr[p]--arr[i-1]）和 // 未处理区间(arr[i]--arr[r-1]) // j遍历arr[p]--arr[r-1] int i,j; i = j = p; for (; j &lt; r ; j++) &#123; // 为方便起见，取a[r]为pivot if (a[j] &lt; a[r]) &#123; if (i != j) &#123; swap(a + i, a + j); &#125; i++; &#125; &#125; swap(a + r, a + i); return i;&#125; 快速排序的性能分析 快速排序是稳定的排序算法吗？ 不是，分区函数采用交换的方式，不是稳定的排序算法。 快速排序的空间复杂度是多少？ 空间复杂度$O(1)$，分区函数采用交换的方式，不需要额外的空间。 快速排序的时间复杂度是多少？ 情况 数组 时间复杂度 最坏情况 已有序 $O(n^2)$ 最好情况、平均情况 $O(n\log(n))$ 快排也是用递归来实现的。对于递归代码的时间复杂度，可以用之前的公式来分析。 12T(1) = C； n=1 时，只需要常量级的执行时间，所以表示为 C。T(n) = 2*T(n/2) + n； n&gt;1 但是，公式成立的前提是每次分区操作，我们选择的pivot都很合适，正好能将大区间对等地一分为二。但实际上这种情况是很难实现的。我举一个比较极端的例子。如果数组中的元素原来已经是有序的了，比如1，3，5，6，8。如果我们每次选择最后一个元素作为pivot，那每次分区得到的两个区间都是不均等的。我们需要进行大约n次分区操作，才能完成快排的整个过程。每次分区我们平均要扫描大约n/2个元素，这种情况下，快排的时间复杂度就从$O(n\log(n))$退化成了$O(n^2)$。我们刚刚讲了两个极端情况下的时间复杂度，一个是分区极其均衡，一个是分区极其不均衡。它们分别对应快排的最好情况时间复杂度和最坏情况时间复杂度。那快排的平均情况时间复杂度是多少呢？我们可以继续套用递归时间复杂度的公式进行求解。因为这边平均情况下的递推过程非常复杂，这里直接给出结论:T(n)在大部分情况下的时间复杂度都可以做到$O(n\log(n))$，只有在极端情况下，才会退化到$O(n^2)$。 解答开篇回到开篇的问题：如何用快排思想在$O(n)$内查找第K大元素？比如，4，2，5，12，3这样一组数据，第3大元素就是4，如何快速地找到它。 快排核心思想就是分治和分区，我们可以利用分区的思想，来解答开篇的问题。我们选择数组区间arr[0..n-1]的最后一个元素arr[n-1]作为pivot，对数组arr[0..n-1]原地分区，这样数组就分成了三部分，arr[0.…p-1]、arr[p]以及arr[p+1..n-1]。 如果p + 1 = K，那arr[p]就是要求解的元素；如果K &gt; p + 1，说明第K大元素出现在arr[p+1..n-1]区间，我们再按照上面的思路递归地在arr[p+1..n-1]这个区间内查找。同理，如果K &lt; p + 1，那我们就在arr[0..p-1]区间查找。 我们再来分析下这样查找的时间复杂度。 第一次分区查找，我们需要对大小为n的数组执行分区操作，需要遍历n个元素；第二次分区查找，我们只需要对大小为 $\frac{n}{2}$ 的数组执行分区操作，需要遍历$\frac{n}{2}$个元素。依次类推，分区遍历元素的个数分别为、$\frac{n}{2}$、$\frac{n}{4}$、$\frac{n}{8}$、$\frac{n}{16}$…..直到区间缩小为1。如果我们把每次分区遍历的元素个数加起来，就是：$$n + \frac{n}{2} + \frac{n}{4} + \frac{n}{8} + .. + 1$$这是一个等比数列求和，最后的和等于$2n-1$ 。所以，上述解决思路的时间复杂度就为$O(n)$。你可能会说，我有个很笨的办法，每次取数组中的最小值，将其移动到数组的最前面，然后在剩下的数组中继续找最小值，以此类推，执行K次，找到的数据不就是第K大元素了吗？不过，时间复杂度就并不是$O(n)$了，而是 $O(K \cdot n)$ 。你可能会说，时间复杂度前面的系数不是可以忽略吗？$O(K \cdot n)$ 不就等于$O(n)$吗？这个可不能这么简单地划等号。当K是比较小的常量时，比如1、2，那最好时间复杂度确实是 $O(n)$ ；但当K等于n/2或者n时，这种最坏情况下的时间复杂度就是 $O(n^2)$ 了。 小结归并排序和快速排序是两种稍微复杂的排序算法，它们用的都是分治的思想，代码都通过递归来实现，过程非常相似。理解归并排序的重点是理解递推公式和merge0合并函数。同理，理解快排的重点也是理解递推公式，还有 partition0分区函数。 归并排序算法是一种在任何情况下时间复杂度都比较稳定的排序算法，这也使它存在致命的缺点，即归并排序不是原地排序算法，空间复杂度比较高，是$O(n)$。正因为此，它也没有快排应用广泛。快速排序算法虽然最坏情况下的时间复杂度是$O(n^2)$ ，但是平均情况下时间复杂度都是$O(n\log(n))$。不仅如此，快速排序算法时间复杂度退化到$O(n^2)$的概率非常小，我们可以通过合理地选择pivot来避免这种情况。 归并排序和快速排序的区别，归并排序的处理过程是由下到上的，先处理子问题，然后再合并。而快排正好相反，它的处理过程是由上到下的，先分区，然后再处理子问题。 思考题现在你有10个接口访问日志文件，每个日志文件大小约300MB，每个文件里的日志都是按照时间戳从小到大排序的。你希望将这10个较小的日志文件，合并为1个日志文件，合并之后的日志仍然按照时间戳从小到大排列。如果处理上述排序任务的机器内存只有1GB，你有什么好的解决思路，能“快速”地将这10个日志文件合并吗？]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法-1：插入、冒泡、选择]]></title>
    <url>%2F2019%2F06%2F17%2Falgo-sort-1%2F</url>
    <content type="text"><![CDATA[排序算法可以说是一项基本功，也是大部分程序员学习的第一个算法，一个优秀的算法可以节省大量的资源。目前大部分编程语言都提供了排序函数，但分析理解各种排序算法的特性，结合各个领域中考虑到数据的各种限制和规范，往往能够分析推理一个符合实际的优秀算法。 排序算法太多了，我们将其按照时间复杂度分为3类，分3篇文章进行分析。 注：以下排序均以升序为例 排序算法 时间复杂度 是否基于比较 冒泡、插入、选择 $O(n^2)$ √ 快排、归并 $O(nlogn)$ √ 桶、计数、基数 $O(n)$ × 如何分析一个“排序算法”排序算法的执行效率 最好情况、最坏情况、平均情况的时间复杂度我们在分析算法时，往往需要对最好情况、最坏情况、平均情况进行区分，并且分析对应情况下的时间复杂度。 时间复杂度的系数、常数、低阶时间复杂度反应的是n极大情况下的时间增长趋势，而实际软件开发中，我们需要排序的往往只有10个、20个、100个这种数据。在小规模数据排序情况下，时间复杂度同阶的算法进行对比时，系数、常数、低阶的影响还是比较大的，往往需要进行分析。 比较次数和交换（移动）次数基于比较的排序算法，在执行过程中会涉及到两种操作：一是比较元素的大小，二是元素交换和移动。所以分析排序算法执行效率时，需要考虑元素的比较以及移动次数。 排序算法的内存消耗算法的内存消耗可以通过空间复杂度衡量。针对排序算法，有一个原地排序（Sorted in place）的概念。原地排序，即空间复杂度为$O(1)$的排序算法。本篇的冒泡、插入、选择排序皆为原地排序。 排序算法的稳定性针对排序算法，还有一个重要的指标：稳定性。指的是：待排列的序列（数组）中存在值相等的元素，而这些相等元素经过排序后，相等元素之间原有的顺序是否改变，若不变，则称排序算法稳定，若改变了，不稳定。 冒泡排序（Buddle Sort）冒泡排序只操作相邻的两个元素，每次冒泡操作都会对相邻的两个元素进行比较，根据大小关系，决定是否互换两个元素。一次冒泡操作会至少让一个元素放到正确的位置上，重复n-1次冒泡操作，就完成了n个元素的排序。 以升序为例，假设有一个整型数组a[] = {5，4，6，3，2，1}，第一次冒泡会先对a[0]和a[1]进行比较，即对5和4比较，5比4大，互换元素，此时a[] = {4,5,6,3,2,1}；紧接着再对a[1]和a[2]进行比较，即5和6比较，5比6小，不互换a不变；再对a[2]和a[3]进行比较，6比3大，互换…以此类推，第一次冒泡完成后，数组为a[] = {4,5,3,2,1,6}，其中最大的元素6已经放到了正确的位置上。我们只需要重复n-1次冒泡操作（外层循环次数n-1）即可完成排序。而第二次冒泡时，因为最后一个元素已经正确，我们无需理会，只需要比较前n-1个元素即可，同理，第k次循环只需比较前n-k个元素（内层循环次数n-k）。 代码如下（C++）： 1234567891011121314151617// 冒泡排序，a为数组，n表示数组大小void bubbleSort(int* a, int n) &#123; if (n &lt;= 1) &#123; return; &#125; // 长度为n的数组，需执行n-1次冒泡循环（0到n-2，为方便数组操作，下标从0开始） for (int i = 0; i &lt; n - 1; i++) &#123; // 第k次循环需比较前n-k个元素（k=i+1） for (int j = 0; j &lt; n - i - 1; j++) &#123; if (a[j] &gt;a[j+1]) &#123; // 交换操作 int tmp = a[j]; a[j] = a[j + 1]; a[j + 1] = tmp; &#125; &#125; &#125;&#125; 优化：当某次冒泡操作时，已经没有数据交换，说明序列已经有序，不需要继续执行后续的冒泡操作，可以设置一个标志位提前退出冒泡循环。 代码如下（C++）： 1234567891011121314151617181920212223// 冒泡排序，a为数组，n表示数组大小void bubbleSort(int* a, int n) &#123; if (n &lt;= 1) &#123; return; &#125; // 长度为n的数组，需执行n-1次冒泡循环（0到n-2，为方便数组操作，下标从0开始） for (int i = 0; i &lt; n - 1; i++) &#123; // 提前退出循环的标志位 bool flag = false; // 第k次循环需比较前n-k个元素（k=i+1） for (int j = 0; j &lt; n - i - 1; j++) &#123; if (a[j] &gt;a[j+1]) &#123; // 交换操作 int tmp = a[j]; a[j] = a[j + 1]; a[j + 1] = tmp; flag = true; // 表示存在元素交换 &#125; &#125; if (!flag) &#123; // 不存在元素交换，提前退出 break; &#125; &#125;&#125; 现在，结合排序算法的分析，有三个问题 三个问题 是原地排序吗？ 是，冒泡排序仅涉及相邻元素交换操作，只需常量级临时空间，所以空间复杂度为$O(1)$。 是稳定的排序吗？ 是，冒泡排序时交换元素改变顺序，在元素相同的情况下，可以不做交换，所以冒泡排序是稳定的排序算法。 时间复杂度是多少？ 情况 原始数据展示 时间复杂度 最好情况 {1,2,3,4,5,6} $O(n)$ 最坏情况 {6,5,4,3,2,1} $O(n^2)$ 平均情况 {6,3,2,1,4,5} $O(n^2)$ 最好情况下，需要排序的原序列已经有序，只需进行一次冒泡操作就可以结束，所以时间复杂度为：$O(n)$。 最坏情况下，需要排序的原序列是倒序，需要进行n次冒泡操作，所以时间复杂度为为：$O(n^2)$。 平均情况下，我们可以采用 逆序度 的方式进行分析。 冒泡排序包含两个操作：比较和交换，每交换一次，逆序度减一，所以逆序度表示了原序列到有序序列需要交换的次数，最好情况下逆序度为0，最坏情况下逆序度为$\frac{n \times (n - 1) }{2}$。平均情况我们可以取一个中间值$\frac{n \times (n+1) }{4}$。比较操作肯定比交换操作要多，而复杂度上限为$O(n^2)$，所以平均情况下的时间复杂度就是$O(n^2)$。 插入排序（Insertion Sort）假设已经有一个有序序列，现在需要往其中添加一个新元素，要求添加后仍然有序，该如何操作呢？只需要遍历原有的有序数组，找到新元素应该插入的位置插入即可，插入排序就是这么来的。 首先，我们将序列中的元素分成两个区间：已排序区间以及未排序区间，当然，初始状态下，已排序区间只有一个元素，即第一个元素，插入排序的思维就是取一个未排序区间的数，在已排序区间内找到合适的位置插入，并且保证已排序区间一直有序，直到未排序区间内没有元素，此时排序完成。 插入排序也包含两种操作：元素的比较和元素的交换。对于不同的查找插入点的方法（从头到尾、从尾到头），元素的比较次数是不一样的，而元素的移动次数都是相同的，等于序列的逆序度。 代码如下（C++） 1234567891011121314151617181920// 插入排序 a 表示数组，n 表示数组大小void insertionSort(int* a, int n) &#123; if (n &lt;= 1) &#123; return; &#125; // 先将a[0]看成已排序区间，所以未排序区间从a[1]开始 for (int i = 1; i &lt; n; i++) &#123; int value = a[i]; // j表示需元素需插入的位置，范围[0,i],a[i]为元素原位置，所以从a[i-1]开始比较 int j = i - 1; for (; j &gt;= 0; j--) &#123; if (a[j] &gt; value) &#123; // 若a[j]&gt;a[i],a[j]元素后移一位 a[j + 1] = a[j]; &#125; else &#123; // 若a[j]&lt;=a[i],即a[j+1]为元素需要插入位置 break; &#125; &#125; a[j + 1] = value; &#125;&#125; 还是三个问题 是原地排序吗？ 是，插入排序不需要额外的存储空间（可以将代码中value直接替换成a[i]，增加value是为了代码更容易看懂），所以空间复杂度为$O(1)$，即，插入排序是原地排序算法。 是稳定的排序吗？ 是，插入排序不需要额外的存储空间（可以将代码中value直接替换成a[i]，增加value是为了代码更容易看懂），所以空间复杂度为$O(1)$，即，插入排序是原地排序算法。 时间复杂度是多少？ 情况 原始数据 时间复杂度 最好情况 已有序 $O(n)$ 最坏情况 倒序 $O(n^2)$ 平均情况 $O(n^2)$ 最好情况下，因为采用的是从尾到头遍历有序数据，所以在第一次比较时就会跳出内层循环。因此不需要搬移任何数据，每次比较一个数据就能确定插入位置。所以最好情况下的时间复杂度为$O(n)$。 最坏情况下，序列倒序，相当于每次插入都需要移动大量元素（i个元素）。所以最坏情况的时间复杂度为$O(n^2)$。 平均情况下，因为我们在数组中插入一个元素的平均时间复杂度为$O(n)$，插入排序每次插入都相当于在数组中插入一个元素，重复了n次插入的过程，所以时间复杂度为$O(n^2)$。 选择排序（Selection Sort）选择排序的思想类似于插入排序，将序列分为已排序区间和未排序区间。但选择排序每次都会从未排序区间内寻找最小的元素，放到已排序区间的末尾（交换操作）。所以重复n-1次操作后，序列即有序。 代码如下： 123456789101112131415161718192021// 选择排序 a 表示数组，n 表示数组大小void selectionSort(int* a, int n) &#123; if (n &lt;= 1) &#123; return; &#125; for (int i = 0; i &lt; n - 1; i++) &#123; // 先默认第i个元素为当前最小元素 int minPos = i; int minValue = a[i]; // 因为默认最小为a[i],所以从a[i+1]开始比较寻找最小元素 int j = i + 1; for (; j &lt; n; j++) &#123; if (a[j] &lt; minValue) &#123; // 若a[j]元素比当前最小元素小，则标记a[j]为当前最小元素 minValue = a[j]; minPos = j; &#125; &#125; a[minPos] = a[i]; a[i] = minValue; &#125;&#125; 依旧三个问题 是原地排序吗？ 是，选择排序空间复杂度为 O(1)，是一种原地排序算法。 是稳定的排序吗？ 否，选择排序每次都要找剩余未排序元素中的最小值，并和前面的元素交换，这样破坏了稳定性。 举例：{5,2,3,4,5,1} 第一次操作会将第一个元素5和最后一个元素1交换，这样，两个5的顺序就变了，所以就不稳定。 时间复杂度是多少？ 情况 时间复杂度 最好、最坏、平均情况 $O(n^2)$ 所有情况下，选择排序的时间复杂度均为$O(n^2)$，因为选择排序在任何情况下，遍历的次数都是固定的，第一次循环对n-1个元素执行比较操作；第k次循环，对n-k个元素执行比较操作，总共需要比较(n-1) + (n-2) + ... + 2，即$\frac{(n - 2) \times (n + 1) }{2}$次，所以选择排序时间复杂度恒为$O(n^2)$。 解答开篇回到开篇的问题：冒泡排序和插入排序的时间复杂度都是$O(n^2)$，都是原地排序算法，都稳定，为什么插入排序比冒泡排序更受欢迎呢？ 前面我们分析到：冒泡排序不管怎么买优化，元素交换的次数都是固定值，等于原始序列的逆序度；同样的，插入排序不管怎么优化，元素移动的次数也是原始序列的逆序度。 但是，从代码实现上来看，冒泡排序的元素交换要比插入排序的元素移动复杂，冒泡排序需要3个赋值操作，而插入排序只需要一个。 代码如下： 1234567891011121314冒泡排序中数据的交换操作：if (a[j] &gt; a[j+1]) &#123; // 交换 int tmp = a[j]; a[j] = a[j+1]; a[j+1] = tmp; flag = true;&#125;插入排序中数据的移动操作：if (a[j] &gt; value) &#123; a[j+1] = a[j]; // 数据移动&#125; else &#123; break;&#125; 因此，虽然两者的时间复杂度一致，但如果追求极致的性能优化，肯定首选插入排序。而且，插入排序的算法思想有很大的优化空间，比如希尔排序。 小结分析排序算法三个方面 执行效率、内存消耗、稳定性 排序算法总结 排序算法 是否原地排序 是否稳定 最好 最坏 平均 冒泡排序 是 是 $O(n)$ $O(n^2)$ $O(n^2)$ 插入排序 是 是 $O(n)$ $O(n^2)$ $O(n^2)$ 选择排序 是 否 $O(n^2)$ $O(n^2)$ $O(n^2)$ 冒泡排序、选择排序实际开发应用并不多，但插入排序还是很有用的，有些编程语言的排序函数的实现原理就用到了插入排序算法。 思考题这三种排序算法数据如果存储在链表中，排序算法还能工作吗，如果能，那时间复杂度、空间复杂度又是多少？]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序算法</tag>
      </tags>
  </entry>
</search>
