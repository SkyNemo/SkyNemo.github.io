<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[CentOS 7 下 Oracle12c 图形化界面安装]]></title>
    <url>%2F2020%2F11%2F26%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%2Foracle12c_install%2F</url>
    <content type="text"><![CDATA[准备 主机：IP 操作系统 角色 192.168.1.174 CentOS Linux release 7.8.2003 (Core) Minimal Install oracle服务端 192.168.1.240 Windows 10 专业工作站版 2004 plsql客户端 基础配置配置主机名 1[root@localhost ~]# hostnamectl set-hostname oracledb 配置时区 1[root@oracledb ~]# timedatectl set-timezone Asia/Shanghai 关闭防火墙和selinux 123456[root@oracledb ~]# systemctl stop firewalld[root@oracledb ~]# systemctl disable firewalld[root@oracledb ~]# setenforce 0[root@oracledb ~]# sed -i 's/=enforcing/=disabled/g' /etc/sysconfig/selinux 关闭NetworkManager 12[root@oracledb ~]# systemctl stop NetworkManager[root@oracledb ~]# systemctl disable NetworkManager 配置yum源备份 1[root@oracledb ~]# mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 下载新的 CentOS-Base.repo 到 /etc/yum.repos.d/ 1[root@oracledb ~]# curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo 生成缓存 1[root@oracledb ~]# yum makecache 安装一些常用工具 1[root@oracledb ~]# yum install -y wget vim oracle适配安装oracle所需依赖 1[root@oracledb ~]# yum install -y binutils compat-libcap1 compat-libstdc++-33 gcc gcc-c++ glibc glibc-devel ksh make sysstat unixODBC unixODBC-devel libgcc libstdc++ libstdc++-devel libaio libaio-devel libXp 建立用户和组 如果要安装Oracle数据库，则需要以下本地操作系统组和用户： Oracle inventory组(通常为 oinstall) OSDBA组 (通常为 dba) OSOPER组 (通常为 oper) Oracle软件所有者(通常为 oracle） 1234567[root@oracledb ~]# groupadd oinstall[root@oracledb ~]# groupadd dba[root@oracledb ~]# groupadd oper[root@oracledb ~]# useradd -g oinstall -G dba,oper oracle# 设置oracle用户的登录密码[root@oracledb ~]# echo "123456" | passwd --stdin oracle 创建安装目录 123[root@oracledb ~]# mkdir -p /orcl/app/[root@oracledb ~]# chown -R oracle:oinstall /orcl/app/[root@oracledb ~]# chmod -R 775 /orcl/app/ 修改内核参数 123456789101112131415[root@oracledb ~]# vim /etc/sysctl.conf# 添加以下参数fs.aio-max-nr = 1048576 fs.file-max = 6815744 kernel.shmall = 2097152 kernel.shmmax = 1200000000 kernel.shmmni = 4096 kernel.sem = 250 32000 100 128 net.ipv4.ip_local_port_range = 9000 65500 net.core.rmem_default = 262144 net.core.rmem_max = 4194304 net.core.wmem_default = 262144 net.core.wmem_max = 1048576# 重新载入配置[root@oracledb ~]# sysctl -p 修改连接限制和打开文件限制 123456789101112131415161718192021222324252627282930[root@oracledb ~]# vim /etc/security/limits.conf# 添加以下参数oracle soft nproc 2047oracle hard nproc 16384oracle soft nofile 1024oracle hard nofile 65536oracle soft stack 10240[root@oracledb ~]# vim /etc/pam.d/login# 添加以下参数session required pam_limits.sosession required /lib64/security/pam_limits.so# 修改oracle用户资源限制# 指定管道缓冲区大小16384# 修改同一时间可开启文件数65536[root@oracledb ~]# vim /etc/profile# 添加以下参数if [ $USER = "oracle" ]; then if [ $SHELL = "/bin/ksh" ]; then ulimit -p 16384 ulimit -n 65536 else ulimit -u 16384 -n 65536 fi fi[root@oracledb ~]# source /etc/profile 修改oracle用户环境变量 123456789101112[root@oracledb ~]# vim /home/oracle/.bash_profileORACLE_BASE=/orcl/app/oracle ORACLE_HOME=$ORACLE_BASE/product/12.2.0ORACLE_SID=orcl export ORACLE_BASE ORACLE_HOME ORACLE_SID PATH=$ORACLE_HOME/bin:$PATH export PATH DISPLAY=:0.0export DISPLAY[root@oracledb ~]# xhost + 卸载系统自带的open-jdk，安装oracle-jdk 网址：https://www.oracle.com/java/technologies/javase-downloads.html 根据需要下载对应版本，此处下载Java SE 11 12345[root@oracledb ~]# yum remove jdk# 下载对应的jdk（rpm或压缩包）并上传到服务器[root@oracledb ~]# rpm -ivh jdk-11.0.9_linux-x64_bin.rpm 安装界面 123[root@oracledb ~]# yum groupinstall -y "X Window System"yum groupinstall -y "GNOME Desktop" 增加swap空间 1234567891011121314151617181920212223242526# 此处swap为2G，oracle12c需要swap为2.67G[root@oracledb ~]# free total used free shared buff/cache availableMem: 1863012 850396 68524 29640 944092 825836Swap: 2097148 0 2097148# 增加1G swap# 创建一个1G文件[root@oracledb ~]# dd if=/dev/zero of=/home/swap bs=1024 count=10485761048576+0 records in1048576+0 records out1073741824 bytes (1.1 GB) copied, 4.21729 s, 255 MB/s# 格式化成swap文件类型[root@oracledb ~]# mkswap /home/swapSetting up swapspace version 1, size = 1048572 KiBno label, UUID=e1bf10ce-ebaf-4ead-9343-1cf58736661f# 扩容[root@oracledb ~]# swapon /home/swapswapon: /home/swap: insecure permissions 0644, 0600 suggested.# 写入fstab[root@oracledb ~]# vim /etc/fstab/home/swap swap swap defaults 0 0 安装oracle1234# 上传oracle安装包到/orcl/app/database[root@oracledb ~]# cd /orcl/app/# 解压安装包[root@oracledb app]# unzip linuxx64_12201_database.zip 安装1234567# 界面登录，切换到oracle用户,进入/orcl/app/database,运行runInstaller[root@oracledb ~]# init 5# 切换到oracle用户[root@oracledb ~]# su - oracle# 安装oracle[oracle@oracledb ~]$ cd /orcl/app/database./runInstaller 不接收oracle推送信息 只安装数据库管理软件，之后再建数据库 安装单实例还是数据库集群，选择单实例 选择企业版 软件存放目录，默认以安装包放置的路径开头 选择产品清单目录 配置安装组 检查安装的先决条件，如果有不通过的会显示，全部通过则确定安装即可 如果出现如图情况，先不要着急的点OK，需要用 root 用户执行如图提示的两条命令，执行完后再点OK 12345678910111213141516171819202122232425262728[root@oracledb ~]# cd /orcl/app/oraInventory[root@oracledb oraInventory]# ./orainstRoot.sh [root@oracledb ~]# cd /orcl/app/oracle/product/12.2.0/[root@oracledb 12.2.0]# ./root.sh Performing root user operation.The following environment variables are set as: ORACLE_OWNER= oracle ORACLE_HOME= /orcl/app/oracle/product/12.2.0Enter the full pathname of the local bin directory: [/usr/local/bin]: Copying dbhome to /usr/local/bin ... Copying oraenv to /usr/local/bin ... Copying coraenv to /usr/local/bin ...Creating /etc/oratab file...Entries will be added to the /etc/oratab file as needed byDatabase Configuration Assistant when a database is createdFinished running generic part of root script.Now product-specific root actions will be performed.Do you want to setup Oracle Trace File Analyzer (TFA) now ? yes|[no] : yesInstalling Oracle Trace File Analyzer (TFA).Log File: /orcl/app/oracle/product/12.2.0/install/root_oracledb_2020-11-05_23-23-29-185770578.logFinished installing Oracle Trace File Analyzer (TFA) 软件安装成功 配置监听也可以在配置数据库时再一同配置 12# 图形化界面运行命令[oracle@oracledb ~]$ netca 选择配置监听 选择添加一个监听 监听名称，默认即可 监听所遵从的协议，默认即可 选择监听端口号 是否创建下一个监听，选择否 监听配置完成 创建数据库12# 图形化界面运行命令dbca[oracle@oracledb ~]$ dbca 创建数据库 默认方式还是高级模式，选择高级模式 数据库用途 配置CBD容器数据库 选择存储方式，文件存储还是流存储 快速恢复选项，默认即可 选择监听器 数据库安全配置 内存、块、连接数、字符集、连接模式、添加实例配置 连接数量配置 字符集配置 选择连接模式，直连还是共享连接池 是否创建简单实例 配置Oracle EM（企业管理） 口令配置，此处用的是统一口令 创建数据库配置 创建数据库 创建数据库模板（以后可以基于模板创建一模一样的数据库） 创建数据库脚本（以后可以基于脚本创建一模一样的数据库） 总结界面，确认配置 创建数据库完成 plsql安装和配置plsql下载地址：https://www.allroundautomations.com/registered-plsqldev/ Oracle Instant Client下载地址：https://www.oracle.com/database/technologies/instant-client/downloads.html 安装plsql 安装免费版本 完全安装 将oracle instant client解压 此处解压到到plsql安装目录，并在解压后的目录新建文件夹network，network下新建文件夹admin 下载oracle安装目录下的tnsnames.ora到admin文件夹下 tnsnames.ora路径如下 1234root@oracledb admin]# pwd/orcl/app/oracle/product/12.2.0/network/admin[root@oracledb admin]# lslistener.ora samples shrept.lst tnsnames.ora 配置plsql配置环境变量 启动plsql，先取消登录，进入主界面，点击配置选项卡的首选项（configure–&gt;preferences） 配置Oracle Home为oracle instant client目录（此处为） 配置OCI library为oracle instant client下oci.dll完整路径（此处为） 测试连接 关闭plsql，重新打开就会出现Database下拉列表以及Connect As下拉框，代表配置成功 输入用户名和密码（之前配置）即可连接oracle，左侧tables下可以检索到表数据 scott用户测试数据导入oracle 12c自带了scott的脚本，路径为$ORACLE_HOME/rdbms/admin/utlsampl.sql，我们需要做的就是要将该脚本导入 查看已有PDB（也可以新建）12345678910111213141516171819202122232425262728293031323334# sqlplus连接oracle[root@oracledb ~]# su - oracle[oracle@oracledb ~]$ sqlplus / as sysdba# 设置行宽、设置列宽;使得数据显示更直观点SQL&gt; set linesize 200;SQL&gt; col name format a20;# 查看当前容器SQL&gt; show con_name;CON_NAME------------------------------CDB$ROOT# 查看CDB容器中的PDB信息SQL&gt; select con_id,dbid,guid,name,open_mode from v$pdbs; CON_ID DBID GUID NAME OPEN_MODE---------- ---------- -------------------------------- -------------------- ---------- 2 4290827074 B372306B8D476B69E05302D00B6F0A31 PDB$SEED READ ONLY 3 999196482 B3724BF4FFA877CDE05302D00B6F4E6B ORCLPDB READ WRITE# 或者直接查看有哪些PDBSQL&gt; show pdbs; CON_ID CON_NAME OPEN MODE RESTRICTED---------- ------------------------------ ---------- ---------- 2 PDB$SEED READ ONLY NO 3 ORCLPDB READ WRITE NO 修改配置1234567891011121314151617181920212223242526272829303132# 另开一个会话，登录oracle用户# 为orclpdb添加tnsnames，plsql中的tnsnames.ora同样需要修改[oracle@oracledb ~]$ vim /orcl/app/oracle/product/12.2.0/network/admin/tnsnames.ora# tnsnames.ora Network Configuration File: /orcl/app/oracle/product/12.2.0/network/admin/tnsnames.ora# Generated by Oracle configuration tools.LISTENER_ORCL = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.1.174)(PORT = 1521))ORCL = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.1.174)(PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = orcl.192.168.1.174) ) )ORCLPDB = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.1.174)(PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = orclpdb.192.168.1.174) ) ) # 修改utlsampl.sql，使其直连到ORCLPDB进行操作[oracle@oracledb ~]$ vim /orcl/app/oracle/product/12.2.0/rdbms/admin/utlsampl.sql# 修改CONNECT SCOTT/tiger 为 CONNECT SCOTT/tiger@ORCLPDB 导入脚本1234# 返回sqlplus的会话# 执行脚本utlsampl.sql，导入测试用户scottSQL&gt; @$ORACLE_HOME/rdbms/admin/utlsampl.sql;# 执行完成后会退出连接 验证1234567891011121314151617181920# 以scott用户登录，查询数据SQL&gt; conn scott/tiger@orclpdb;Connected.SQL&gt; select table_name from user_tables;TABLE_NAME--------------------------------------------------------------------------------DEPTEMPBONUSSALGRADESQL&gt; select * from DEPT; DEPTNO DNAME LOC---------- -------------- ------------- 10 ACCOUNTING NEW YORK 20 RESEARCH DALLAS 30 SALES CHICAGO 40 OPERATIONS BOSTON plsql使用scott用户登录修改tnsnames.ora后，Database里会出现ORCLPDB选项 连接后查看Table，有测试的四个表 至此，oracle12c安装以及相关操作全部完成]]></content>
      <categories>
        <category>数据库基础</category>
      </categories>
      <tags>
        <tag>数据库基础</tag>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS ssh密钥认证(免密登录)]]></title>
    <url>%2F2020%2F10%2F13%2FLinux%E6%9C%8D%E5%8A%A1%2Fssh_with_key%2F</url>
    <content type="text"><![CDATA[简介SSH （Secure Shell ）是一个安全的远程登录工具，由 IETF 的网络小组（Network Working Group）所制定，是建立在应用层基础上的安全协议，常监听于TCP的22端口。SSH最初是UNIX系统上的一个程序，后来又迅速扩展到其他操作平台。SSH客户端适用于多种平台，几乎所有UNIX平台—包括HP-UX、Linux、AIX、Solaris、Digital UNIX、Irix，以及其他平台，都可运行SSH。 ssh服务有两种验证用户登录的方式，一种是基于密码口令的认证，一种是基于密钥的认证，本文主要是实现基于密钥的认证。 密钥认证原理： 准备 主机：IP 操作系统 角色 node1:192.168.1.171 CentOS Linux release 7.8.2003 (Core) Minimal Install 客户端 node2:192.168.1.172 CentOS Linux release 7.8.2003 (Core) Minimal Install 服务端 配置客户端生成密钥对1234567891011121314151617181920212223# 格式：ssh-keygen -t rsa [-P ''] [-f ~/.ssh/id_rsa]# [-P '']:指定私钥密码为空# [-f ~/.ssh/id_rsa]:指定密钥对保存路径[root@node1 ~]# ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsaGenerating public/private rsa key pair.Created directory '/root/.ssh'.Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:SHA256:MFEhbpes0PiW6AQpKardZakmzvfabNVOIdboi/WS7lQ root@node1The key's randomart image is:+---[RSA 2048]----+| o.o. || . . + + . ||+ o o * +o ||o. . = B+ o ||. o OoSoE. ||.. + = +.o ||. o = +.* || o o.oo.+ o || o..++oo. |+----[SHA256]-----+ 复制公钥到远程主机（服务端）将生成的公钥传给远程主机，并加入到文件~/.ssh/authorized_keys；只要写入文件即可，写入方式多种，也可以复制粘贴过去，推荐ssh-copy-id方式 12345678910111213141516# 格式：ssh-copy-id [-i indetify_file ] USER@REMOTE_HOST# [-i indetify_file ]:指定公钥[root@node1 ~]# ssh-copy-id -i .ssh/id_rsa.pub root@192.168.1.172/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: ".ssh/id_rsa.pub"The authenticity of host '192.168.1.172 (192.168.1.172)' can't be established.ECDSA key fingerprint is SHA256:rRRfvxHXkXXyc0qBcfpbt3mXlxAaWP551y07Ysoqn+U.ECDSA key fingerprint is MD5:fa:a8:e1:c8:35:da:b5:ff:ec:4f:d2:bf:55:da:ce:31.Are you sure you want to continue connecting (yes/no)? yes/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keysroot@192.168.1.172's password: Number of key(s) added: 1Now try logging into the machine, with: "ssh 'root@192.168.1.172'"and check to make sure that only the key(s) you wanted were added. 测试1234# 此时已经可以使用root免密登录到node2[root@node1 ~]# ssh root@192.168.1.172Last login: Sun Oct 4 11:17:05 2020 from 192.168.1.154[root@node2 ~]# 优化（以下为进阶内容）这里我们会发现，在复制公钥的时候，如果是首次登陆，需要进行指纹核对（fingerprint verification），并且需要手动输入密码，可以使用shell脚本编程中的expect语法，代替我们验证指纹以及输入登录密码 expect依赖于tcl，CentOS 7最小化安装默认不包含tcl以及expect，网络上的主机可以yum安装，局域网的下载rpm安装，以网络上主机为例 配置阿里云yum源（可选）123456# 备份原有的yum仓库[root@node1 ~]# mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup# 配置阿里云yum源[root@node1 ~]# curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo# 生成缓存[root@node1 ~]# yum makecache 安装expect123[root@node1 ~]# yum install -y expect[root@node1 ~]# expect -vexpect version 5.45 编写自动远程执行脚本第一版：免指纹核对以及输入密码脚本使用expect来代替我们验证指纹以及输入登录密码 12345678910#!/usr/bin/expectspawn ssh 192.168.1.172expect &#123; # 指纹核对回复yes "yes/no" &#123; send "yes\n";exp_continue &#125; # 输入密码 "password" &#123; send "YOUR_PASSWORD\n" &#125;&#125;interactexpect eof 第二版：配置多主机ssh免密登录脚本结合密钥对生成以及复制公钥到远程多个主机 1234567891011121314151617181920212223#!/bin/bash# 判断密钥对是否存在，若不存在则创建密钥[ ! -f /root/.ssh/id_rsa.pub ] &amp;&amp; ssh-keygen -t rsa -P '' -f /root/.ssh/id_rsa &amp;&gt;/dev/null# 读取存储ip的文件while read line;do # 提取文件中的ip remote_host=$( echo $line | cut -d' ' -f1 ) # 提取文件中的用户名 username=$( echo $line | cut -d' ' -f2 ) # 提取文件中的密码 password=$( echo $line | cut -d' ' -f3 )expect &gt;&gt; ./expect.log &lt;&lt; EOF spawn ssh-copy-id -i /root/.ssh/id_rsa.pub $username@$remote_host expect &#123; "yes/no" &#123; send "yes\n";exp_continue &#125; "password" &#123; send "$password\n" &#125; &#125; expect eofEOFdone &lt; ./host_ip.txt 其中./host_ip.txt为保存主机信息的文件，格式如下 123[root@node1 workspace]# cat ./host_ip.txt 192.168.1.172 root 520123192.168.1.173 root 520123 第三版：基于ssh多主机运行本地脚本的shell脚本结合远程运行本地脚本文件并将输出收集到日志 123456789101112131415161718192021222324252627282930313233343536#!/bin/bash#------------------------------------------## FileName: ssh_auto.sh# Revision: 1.1.0# Date: 2020-10-05 00:21:00# Author: nemo# Email: sky.nemo@outlook.com# Website: www.skynemo.cn# Description: This script can achieve ssh password-free login, # and can be deployed in batches, configuration # 判断密钥对是否存在，若不存在则创建密钥[ ! -f /root/.ssh/id_rsa.pub ] &amp;&amp; ssh-keygen -t rsa -P '' -f /root/.ssh/id_rsa &amp;&gt;/dev/null# 读取存储ip的文件while read line;do # 提取文件中的ip remote_host=$( echo $line | cut -d' ' -f1 ) # 提取文件中的用户名 username=$( echo $line | cut -d' ' -f2 ) # 提取文件中的密码 password=$( echo $line | cut -d' ' -f3 )expect &gt;&gt; ./expect.log &lt;&lt; EOF spawn ssh-copy-id -i /root/.ssh/id_rsa.pub $username@$remote_host expect &#123; "yes/no" &#123; send "yes\n";exp_continue &#125; "password" &#123; send "$password\n" &#125; &#125; expect eofEOF date=$( ssh -T $username@$remote_host &lt; ./date.sh) echo $remote_host date : $date &gt;&gt; ./date.logdone &lt; ./host_ip.txt 其中其中./host_ip.txt为保存主机信息的文件，格式同上；./date.sh为远程执行的shell脚本，格式如下 123[root@node1 workspace]# cat ./date.sh #!/bin/bashdate 测试脚本 123456# 网络中没有192.168.1.173这台主机，所以提示连接失败[root@node1 workspace]# ./ssh_auto.sh ssh: connect to host 192.168.1.173 port 22: No route to host[root@node1 workspace]# cat date.log 192.168.1.172 date : Sun Oct 4 13:41:47 EDT 2020192.168.1.173 date : 第四版：解耦将脚本文件分成： 配置多主机免密登录脚本：./bin/ssh_auto.sh 在多主机运行本地脚本的调用脚本：./bin/remote_run_script.sh 待运行的本地脚本：./bin/uptime.sh（根据需求自定义，此处以获取uptime为例） 主机信息表：./conf/host.conf 入口脚本：./bin/main.sh 日志文件分为： 分发公钥expect日志：./log/expect.log 返回信息：./log/info.log 配置多主机免密登录脚本 1234567891011121314151617181920212223#!/bin/bash# 判断密钥对是否存在，若不存在则创建密钥[ ! -f /root/.ssh/id_rsa.pub ] &amp;&amp; ssh-keygen -t rsa -f /root/.ssh/id_rsa -P '' &amp;&gt;/dev/null# 读取存储ip的文件while read line;do # 提取文件中的ip remote_host=$( echo $line | cut -d' ' -f1 ) # 提取文件中的用户名 username=$( echo $line | cut -d' ' -f2 ) # 提取文件中的密码 password=$( echo $line | cut -d' ' -f3 )expect &gt;&gt; ../log/expect.log &lt;&lt; EOF spawn ssh-copy-id -i /root/.ssh/id_rsa.pub $username@$remote_host expect &#123; "yes/no" &#123; send "yes\n";exp_continue &#125; "password" &#123; send "$password\n" &#125; &#125; expect eof EOFdone &lt; ../conf/host.conf 在多主机运行本地脚本的调用脚本 123456789101112131415161718192021222324252627282930313233343536373839404142#!/bin/bashdatetime=$( date -d today +"%Y-%m-%d %H:%M:%S" )read -e -p "please input the script path : " -t 30 script# 判断待运行脚本是否存在if [[ ! -f $script ]];then echo "ERROR $script is not a file, check please!" exit 10fi# 判断主机信息配置文件是否存在if [[ ! -f ../conf/host.conf ]];then echo "ERROR ../conf/host.conf is no exits, check please!" exit 10fiwhile read linedo &#123; # 提取文件中的ip remote_host=$( echo $line | cut -d' ' -f1 ) # 提取文件中的用户名 username=$( echo $line | cut -d' ' -f2 ) return_info=$( ssh -T $username@$remote_host &lt; $script 2&gt;/dev/null ) return_code=$? #退出状态码不为0，说明ssh连接没有成功 if [[ ! $return_code -eq 0 ]];then &#123; echo "$remote_host connect fail, please check the host infomation or MaxStartups" exit 10 &#125; fi echo "$remote_host is running script..." echo -e "$datetime at remote host $remote_host run $script \n $return_info" &gt;&gt; ../log/info.log&#125; &amp;done &lt; ../conf/host.confwait 待运行的本地脚本 12345# 根据实际需要编写脚本，此处只为测试，所以写个获取uptime的简单脚本#!/bin/bashuptime=$( uptime | awk '&#123; print $3 &#125;')echo $uptime 主机信息表 1234567# 此处有一些重复的行，在入口脚本时进行删除[root@node1 conf]# cat host.conf192.168.1.173 root 520123192.168.1.172 root 520123192.168.1.173 root 520123192.168.1.172 root 520123192.168.1.172 root 520123 入口脚本 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#!/bin/bashconf=../conf/host.confdatetime=$( date -d today +"%Y-%m-%d %H:%M:%S" )# 清洗函数：删除host.conf重复行,生成MD5文件host_config_cleaning()&#123;# 清除host.conf的重复行sort -n $conf | uniq &gt; ../conf/host.conf.tmprm -rf $confmv ../conf/host.conf.tmp $conf# 重新生成md5文件host_md5=$( md5sum -b $conf | awk '&#123;print $1&#125;'| sed 's/ //g' )echo $host_md5 &gt; ../conf/host.conf.md5&#125;# 检查主机信息host.conf是否存在if [[ ! -f $conf ]];then &#123; echo "./conf/host.conf does no exist, check please !" exit 10&#125;fi# 检查免密登录脚本是否存在if [[ ! -f ./ssh_auto.sh ]];then &#123; echo "./bin/ssh_auto.sh does no exist, check please !" exit 10&#125;fi# 检查调用脚本是否存在if [[ ! -f ./run_auto.sh ]];then &#123; echo "./bin/run_auto.sh does no exist, check please !" exit 10&#125;fi# 检查host.conf是否有变化，通过MD5# 检查./conf/host.conf.md5文件是否存在，若不存在删除host.conf重复行,生成MD5文件if [[ ! -f ../conf/host.conf.md5 ]];then &#123; # 调用清洗函数 host_config_cleaning # 调用免密登录脚本，发放公钥 ./ssh_auto.sh &#125; else &#123; host_md5_old=$( cat ../conf/host.conf.md5 | sed 's/ //g') host_md5_new=$( md5sum -b $conf | awk '&#123;print $1&#125;'|sed 's/ //g' ) # 若当前MD5与原有的不同，说明主机配置文件(./conf/host.conf)发生改变 # 删除host.conf重复行,生成MD5文件 if [[ "$host_md5_old" == "$host_md5_new" ]];then &#123; echo "$datetime : host.conf is no change !" &gt; ../log/info.log &#125; else &#123; # 调用清洗函数 host_config_cleaning # 调用免密登录脚本，发放公钥 ./ssh_auto.sh &#125; fi &#125;fi# 调用多主机运行本地脚本的调用脚本./remote__run_script.sh 最终脚本打包链接（包含expect和tcl的rpm包，适用于centos7） https://skynemo-1258540788.cos.ap-chengdu.myqcloud.com/SkyNemo-Blog/linux/service/remote_service/0_ssh/ssh_auto.tar.gz]]></content>
      <categories>
        <category>Linux服务</category>
      </categories>
      <tags>
        <tag>Linux服务</tag>
        <tag>远程服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 安装Nginx]]></title>
    <url>%2F2020%2F09%2F12%2FLinux%E6%9C%8D%E5%8A%A1%2Fnginx_install_commend%2F</url>
    <content type="text"><![CDATA[简介&amp;准备简介nginx（读音：engine x）是可以作为HTTP和反向代理服务器、邮件代理服务器和通用TCP/UDP代理服务器，通常用于高负载的场景下，因为它的稳定性、丰富的模块库、灵活的配置和低系统资源的消耗而闻名 nginx的版本mainline version：主线版本，版本号通常是奇数，目前最新但是还未经过大量测试的版本 stable version：最新稳定版本，版本号通常为偶数，经过大量测试，企业中经常使用该版本 lagacy version：历史稳定版本，往期的稳定版本 nginx安装方式 yum安装部署 源码安装部署 准备主机CentOS Linux release 7.8.2003 (Core) Minimal Install 1台 关闭防火墙和selinux123456789# 关闭防火墙firewall并设置开机不启动[root@node1 ~]# systemctl stop firewalld[root@node1 ~]# systemctl disable firewalldRemoved symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.# 关闭selinux并设置开机不启动[root@node1 ~]# setenforce 0[root@node1 ~]# sed -i 's/=enforcing/=disabled/g' /etc/sysconfig/selinux 配置aliyun的yum仓库(可选)1234567# 参考：https://developer.aliyun.com/mirror/centos?spm=a2c6h.13651102.0.0.3e221b119TjB18# 备份[root@node1 ~]# mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup# 下载新的 CentOS-Base.repo 到 /etc/yum.repos.d/[root@node1 ~]# curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo#运行 yum makecache 生成缓存[root@node1 ~]# yum makecache 安装vim、yum-utils、wget（可选）1[root@node1 ~]# yum install vim yum-utils wget -y yum安装参考官网：http://nginx.org/en/linux_packages.html#RHEL-CentOS 配置yum仓库1234567891011121314151617# 此处的配置默认使用stable版本，根据需要将enbaled置为0或1[root@node1 ~]# vim /etc/yum.repos.d/nginx.repo[nginx-stable]name=nginx stable repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=1enabled=1gpgkey=https://nginx.org/keys/nginx_signing.keymodule_hotfixes=true[nginx-mainline]name=nginx mainline repobaseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/gpgcheck=1enabled=0gpgkey=https://nginx.org/keys/nginx_signing.keymodule_hotfixes=true 安装稳定版本12345# 由于默认配置即为稳定版本，所以直接安装即可[root@node1 ~]# yum install nginx -y# 查看版本信息[root@node1 ~]# nginx -vnginx version: nginx/1.18.0 安装主线版本12345678910# 卸载刚才安装的稳定版本[root@node1 ~]# yum remove nginx -y# 配置mainline版本为enabled，也可以vim配置文件修改[root@node1 ~]# yum-config-manager --enable nginx-mainline# 安装[root@node1 ~]# yum install nginx -y# 查看版本信息[root@node1 ~]# nginx -vnginx version: nginx/1.19.2 源码安装安装依赖1[root@node1 ~]# yum install gcc gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel -y 下载解压源码包1234567# 官网下载页面（http://nginx.org/en/download.html）复制下载链接，wget下载到/usr/local/src# 下载[root@node1 ~]# wget -P /usr/local/src http://nginx.org/download/nginx-1.18.0.tar.gz[root@node1 ~]# cd /usr/local/src# 解压[root@node1 src]# tar -zxvf nginx-1.18.0.tar.gz [root@node1 src]# cd nginx-1.18.0 预编译12345678910格式：./configure [options]预编译主要是用来检查系统环境是否满足安装软件包的条件，并生成Makefile文件，该文件为编译、安装、升级nginx指明了相应参数。./configure --help可以查看预编译参数以及详细解释，常用参数如下：--prefix 指定nginx编译安装的目录；--user=*** 指定nginx的属主--group=*** 指定nginx的属主与属组--with-*** 指定编译某模块--without-** 指定不编译某模块--add-module 编译第三方模块 1234567891011# 查看目录[root@node1 nginx-1.18.0]# lsauto CHANGES CHANGES.ru conf configure contrib html LICENSE man README src# 预编译[root@node1 nginx-1.18.0]# ./configure --prefix=/usr/local/nginx# 再次查看目录，可以发现多了Makefile文件以及objs目录[root@node1 nginx-1.18.0]# lsauto CHANGES.ru configure html Makefile objs srcCHANGES conf contrib LICENSE man README 编译并安装1234567891011121314151617181920212223242526格式：make [options]# 查看Makefile文件，可以看到编译命令make的常用参数以及作用[root@node1 nginx-1.18.0]# cat Makefile default: buildclean: rm -rf Makefile objsbuild: $(MAKE) -f objs/Makefileinstall: $(MAKE) -f objs/Makefile installmodules: $(MAKE) -f objs/Makefile modulesupgrade: /usr/local/nginx/sbin/nginx -t kill -USR2 `cat /usr/local/nginx/logs/nginx.pid` sleep 1 test -f /usr/local/nginx/logs/nginx.pid.oldbin kill -QUIT `cat /usr/local/nginx/logs/nginx.pid.oldbin` 格式:make [options]make clean : 重新预编译时，通常执行这条命令删除上次的编译文件make build : 编译，默认参数，可省略build参数make install : 安装make modules : 编译模块make upgrade : 在线升级 12345# 编译并安装[root@node1 nginx-1.18.0]# make &amp;&amp; make install# 查看版本[root@node1 ~]# /usr/local/nginx/sbin/nginx -vnginx version: nginx/1.18.0 启动nginx123456[root@node1 ~]# /usr/local/nginx/sbin/nginx# 检查进程和端口[root@node1 ~]# ps -ef | grep nginxroot 17249 1 0 23:48 ? 00:00:00 nginx: master process /usr/local/nginx/sbin/nginxnobody 17250 17249 0 23:48 ? 00:00:00 nginx: worker processroot 17252 12403 0 23:48 pts/0 00:00:00 grep --color=auto nginx 简便操作简化路径12345678910111213# 如果觉得每次都需要输入绝对路径执行命令麻烦，可以通过以下3种方法（选一执行即可）实现直接使用nginx命令1、建立软连接（推荐）[root@node1 ~]# ln -s /usr/local/nginx/sbin/* /usr/local/sbin2、配置环境变量[root@node1 ~]# echo "export PATH=/usr/local/nginx/sbin:$PATH" &gt; /etc/profile.d/nginx.sh# 重新读取profile[root@node1 ~]# source /etc/profile3、设置别名alias nginx='/usr/local/nginx/sbin/nginx'# 注：which会优先找别名 加入systemd管理123456789101112131415161718192021222324# 源码安装需要手动添加至systemd管理[root@node1 conf]# vim /usr/lib/systemd/system/nginx.service [Unit]Description=nginx - high performance web serverDocumentation=http://nginx.org/en/docs/After=network-online.target remote-fs.target nss-lookup.targetWants=network-online.target[Service]Type=forking# 若要指定pidfile，则nginx.conf中应该配置同一个pidfile，否则会导致systemctl start nginx卡住PIDFile=/var/run/nginx.pidExecStart=/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.confExecReload=/bin/sh -c "/bin/kill -s HUP $(/bin/cat /var/run/nginx.pid)"ExecStop=/bin/sh -c "/bin/kill -s TERM $(/bin/cat /var/run/nginx.pid)"[Install]WantedBy=multi-user.target# 重新加载[root@node1 conf]# systemctl daemon-reload# 可用systemctl运行[root@node1 conf]# systemctl start nginx 卸载yum方式安装的卸载 1[root@node1 system]# yum remove nginx -y 源码安装方式的卸载 1234567891011# 查看nginx是否启动[root@node1 ~]# ps -ef | grep nginxroot 17249 1 0 03:11 ? 00:00:00 nginx: master process /usr/local/nginx/sbin/nginxnobody 17250 17249 0 03:11 ? 00:00:00 nginx: worker processroot 20447 20222 0 09:38 pts/1 00:00:00 grep --color=auto nginx# 停止nginx服务[root@node1 ~]# nginx -s quit[root@node1 ~]# ps -ef | grep nginx root 20534 20222 0 09:39 pts/1 00:00:00 grep --color=auto nginx# find查找路径后卸载[root@node1 ~]# find / -name nginx* | grep /usr | xargs -i rm -rf &#123;&#125; nginx常用命令12345678910111213141516# 查看帮助[root@node1 ~]# nginx -hnginx version: nginx/1.18.0Usage: nginx [-?hvVtTq] [-s signal] [-c filename] [-p prefix] [-g directives]Options: -?,-h : this help -v : show version and exit -V : show version and configure options then exit -t : test configuration and exit -T : test configuration, dump it and exit -q : suppress non-error messages during configuration testing -s signal : send signal to a master process: stop, quit, reopen, reload -p prefix : set prefix path (default: /usr/local/nginx/) -c filename : set configuration file (default: conf/nginx.conf) -g directives : set global directives out of configuration file 启动nginx 1nginx 立即停止nginx 1nginx -s stop 优雅停止nginx 1nginx -s quit 重新打开日志文件 1nginx -s reopen 重新加载配置文件 1nginx -s reload 启动并指定配置文件 1nginx -c [conf file] 设置全局变量 1234# 通过设置全局变量，让nginx在前端运行nginx -g "daemon off;"# 此时ctrl +c，则nginx就退出了。可以使用ctrl +z放置后台运行。]]></content>
      <categories>
        <category>Linux服务</category>
      </categories>
      <tags>
        <tag>Linux服务</tag>
        <tag>web服务</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 文件共享FTP部署配置]]></title>
    <url>%2F2020%2F09%2F09%2FLinux%E6%9C%8D%E5%8A%A1%2Fftp_install_config%2F</url>
    <content type="text"><![CDATA[简介&amp;准备vsftpd 是“very secure FTP daemon”的缩写，是一个完全免费的、开放源代码的ftp服务器软件。特点是：非常高的安全性需求、带宽限制、良好的可伸缩性等 主机信息CentOS Linux release 7.8.2003 (Core) 最小安装两台主机 主机角色 主机：IP 角色 安装服务 node1:192.168.1.201 ftp服务端 vsftp node1:192.168.1.202 ftp客户端 ftp或lftp 关闭防火墙和selinux12345678910# 两个节点都操作# 关闭selinuxsetenforce 0# 设置selinux开机不自启sed -i 's/=enforcing/=disabled/g' /etc/sysconfig/selinux# 关闭firewallsystemctl stop firewalld# 设置firewall开机不启动systemctl disable firewalld 安装服务端安装 1[root@node1 ~]# yum install -y vsftpd 客户端安装 12# ftp与lftp选一即可，基础用法相似，高级用法查看man ftp和man lftp[root@node2 ~]# yum -y install ftp lftp 启动服务 12[root@node1 ~]# systemctl start vsftpd [root@node1 ~]# systemctl enable vsftpd 常用操作为测试客户端常用命令，在服务端创建一些文件 1234# 默认的共享目录是 /var/ftp，在/var/ftp/pub下创建一些文件[root@node1 pub]# for i in $(seq 1 10); do echo $i &gt; file$i ; done[root@node1 pub]# lsfile1 file10 file2 file3 file4 file5 file6 file7 file8 file9 ftp客户端常用命令连接123456789101112131415# 使用ftp连接，需要手动输入匿名用户ftp，默认密码为空[root@node2 ~]# ftp 192.168.1.201Connected to 192.168.1.201 (192.168.1.201).220 (vsFTPd 3.0.2)Name (192.168.1.201:root): ftp331 Please specify the password.Password:230 Login successful.Remote system type is UNIX.Using binary mode to transfer files.ftp&gt; # 使用lftp连接，默认使用匿名用户ftp[root@node2 ~]# lftp 192.168.1.201lftp 192.168.1.201:~&gt; help查看帮助1234567891011121314151617181920212223242526272829303132# 连接上服务器后，可以使用help获取帮助，以ftp为例，lftp类似ftp&gt; helpCommands may be abbreviated. Commands are:! debug mdir sendport site$ dir mget put sizeaccount disconnect mkdir pwd statusappend exit mls quit structascii form mode quote systembell get modtime recv suniquebinary glob mput reget tenexbye hash newer rstatus tickcase help nmap rhelp tracecd idle nlist rename typecdup image ntrans reset userchmod lcd open restart umaskclose ls prompt rmdir verbosecr macdef passive runique ?delete mdelete proxy send# 常用命令如下：# ascii：设置以ascii码方式传输数据，一般用于传输文本文件ftp&gt; ascii200 Switching to ASCII mode.# binary：设置以二进制方式传输数据，一般用于传输压缩包、库文件、二进制等除文本以外的文件ftp&gt; binary200 Switching to Binary mode.# passive：用于开启和关闭ftp的主被动模式ftp&gt; passivePassive mode off.ftp&gt; passivePassive mode on.# ls、pwd同linux；文件操作命令下面详解 get下载单个文件12345678910111213141516171819202122232425ftp&gt; ls227 Entering Passive Mode (192,168,1,201,28,47).150 Here comes the directory listing.drwxr-xr-x 2 0 0 137 Sep 07 14:41 pub226 Directory send OK.# 切换到pub目录ftp&gt; cd pub250 Directory successfully changed.ftp&gt; ls227 Entering Passive Mode (192,168,1,201,60,75).150 Here comes the directory listing.-rw-r--r-- 1 0 0 2 Sep 07 14:41 file1-rw-r--r-- 1 0 0 3 Sep 07 14:41 file10-rw-r--r-- 1 0 0 2 Sep 07 14:41 file2-rw-r--r-- 1 0 0 2 Sep 07 14:41 file3-rw-r--r-- 1 0 0 2 Sep 07 14:41 file4-rw-r--r-- 1 0 0 2 Sep 07 14:41 file5-rw-r--r-- 1 0 0 2 Sep 07 14:41 file6-rw-r--r-- 1 0 0 2 Sep 07 14:41 file7-rw-r--r-- 1 0 0 2 Sep 07 14:41 file8-rw-r--r-- 1 0 0 2 Sep 07 14:41 file9226 Directory send OK.# get下载单个文件，默认会下载到你客户端使用ftp命令的当前目录下# cd用于切换服务端目录，lcd切换本地目录ftp&gt; get file1 mget批量下载12345# ftp客户端批量下载时需关闭交互，否则每个文件都会讯问；lftp不需要ftp&gt; prompt offInteractive mode off.# 下载所有file开头的文件ftp&gt; mget file* put上传单个文件默认配置只能进行文件的读取和下载，不能上传，先配置开启匿名用户创建文件、重命名、删除、上传权限 12345678910# node1(服务端)配置匿名用户权限[root@node1 ~]# vim /etc/vsftpd/vsftpd.conf#开启匿名用户上传权限anon_upload_enable=YES#开启匿名用户创建文件权限anon_mkdir_write_enable=YES#开启匿名用户重命名，删除权限anon_other_write_enable=YES# ftp用户属于other；所以给other组用户添加写权限[root@node1 ~]# chmod o+w /var/ftp/pub 12345# 创建目录ftp&gt; mkdir testDir257 "/pub/testDir" created# 上传文件ftp&gt; put anaconda-ks.cfg mput批量上传1ftp&gt; mput file_* miror下载目录123# ftp不提供下载目录，lftp可以用miror下载目录lftp 192.168.1.201:/pub&gt; mirror testDirTotal: 1 directory, 0 files, 0 symlinks rmdir删除目录123456# ftp均使用rmdir删除目录ftp&gt; rmdir testDir250 Remove directory operation successful.lftp 192.168.1.201:/pub&gt; rmdir testDir2rmdir ok, `testDir2' removed 删除文件1234567# ftp使用delete删除文件ftp&gt; delete file6250 Delete operation successful.# lftp使用rm删除文件lftp 192.168.1.201:/pub&gt; rm file7 rm ok, `file7' removed bye断开连接123456# 断开连接# ftp与lftp一样，bye和quit均可以 [root@node2 ~]# lftp 192.168.1.201lftp 192.168.1.201:~&gt; quit[root@node2 ~]# lftp 192.168.1.201lftp 192.168.1.201:~&gt; bye ftp的主被动模式注：当vsftpd配置为主动模式时，客户端需要同步开启主动模式，否则无法正常操作；被动模式同理 主动模式主动模式，也称为active模式、port模式；连接过程如下： 客户端从一个任意的非特权端口N（N&gt;1024）向服务器的FTP端口（默认是21）发送连接请求，服务器接受连接，建立一条命令链路。 客户端开始监听端口N+1 下载数据时，客户端发送FTP命令port N+1到FTP服务器，告诉服务器：“我打开了N+1端口，你过来连接我”。接着服务器会从它自己的数据端口（20）连接到客户端指定的数据端口（N+1）。建立一条数据链路来传送数据 下图为连接过程简要描述： 主动模式配置服务端配置 1234[root@node1 ~]# vim /etc/vsftpd/vsftpd.conf pasv_enable=NOport_enable=YES[root@node1 ~]# systemctl restart vsftpd 客户端配置 12345# ftpftp&gt; passive off# lftplftp 192.168.1.201:/&gt; set ftp:passive-mode 0 被动模式注：常用于客户端在局域网，与服务端中间有防火墙或NAT映射的情形下 被动模式，也称为passive模式、pasv模式；被动方式FTP中，命令连接和数据连接都由客户端发起，这样就可以解决从服务器到客户端的数据端口的入方向连接被防火墙过滤掉的问题，vsftpd默认就是使用被动模式；连接过程如下： 客户端打开两个任意的非特权本地端口（N&gt;1024和N+1）。第一个端口连接服务器的21端口 下载数据时，与主动模式不同，客户端不会提交PORT信令并允许服务器来回连它的数据端口，而是提交PASV信令，告诉服务端连接模式是被动模式。 服务端接收待PASV信令后，会开启一个任意的非特权端口（P&gt;1024），并发送port P命令给客户端。然后客户端发起从本地端口N+1到服务器的端口P的连接用来传送数据。 下图为连接过程简要描述： 被动模式配置服务端配置 1234[root@node1 ~]# vim /etc/vsftpd/vsftpd.conf pasv_enable=YESport_enable=NO[root@node1 ~]# systemctl restart vsftpd 客户端配置 12345# ftpftp&gt; passive on# lftplftp 192.168.1.201:/&gt; set ftp:passive-mode 1 ftp服务端常用配置举例例1-配置本地用户访问 12345678910111213# 服务端node1添加一个测试用户testUser[root@node1 ~]# useradd testUser[root@node1 ~]# echo "123456" | passwd --stdin testUser# 修改配置文件，设置本地用户可以登录[root@node1 ~]# vim /etc/vsftpd/vsftpd.conf local_enable=YES# 重启生效[root@node1 ~]# systemctl restart vsftpd# 客户端node2测试登录[root@node2 test]# lftp testUser@192.168.1.201Password: lftp testUser@192.168.1.201:~&gt; 例2-配置不让匿名用户登录 12345678910# 修改配置文件，设置不让匿名用户登录[root@node1 ~]# vim /etc/vsftpd/vsftpd.conf anonymous_enable=NO# 重启生效[root@node1 ~]# systemctl restart vsftpd# 客户端node2测试登录，已经无法正常操作[root@node2 test]# lftp 192.168.1.201lftp 192.168.1.201:~&gt; ls`ls' at 0 [Sending commands...] 例3-配置全部用户都不能切换家目录 1234567891011# 安装vsftpd后不做配置的话，系统用户是可以向上切换到其他目录的（默认用户不行）# 修改配置文件，设置限制系统用户在其主目录[root@node1 ~]# vim /etc/vsftpd/vsftpd.conf chroot_local_user=YESchroot_list_enable=NOallow_writeable_chroot=YES# chroot_local_user： 是否将所有用户限制在主目录,YES为启用，NO禁用.(该项默认值是NO)# chroot_list_enable： 是否启动限制用户（特例）的名单 YES为启用，NO禁用(包括注释掉也为禁用)# allow_writeable_chroot:如果用户被限定在了其主目录下，则该用户的主目录不能再具有写权限了,如果检查发现还有写权限，就会报错误;allow_writeable_chroot=YES允许该用户的主目录具有写权限 故障解决12345678910111213# 如果重启或者登陆服务器时，报错如下：[root@node1 ~]# systemctl restart vsftpdJob for vsftpd.service failed because the control process exited with errorcode. See "systemctl status vsftpd.service" and "journalctl -xe" for details.[root@node1 ~]# journalctl -xe-- Unit vsftpd.service has begun starting up.8月 08 02:59:14 localhost.localdomain vsftpd[12751]: 500 OOPS: bad bool value inconfig file for: anonymous_en8月 08 02:59:14 localhost.localdomain systemd[1]: vsftpd.service: controlprocess exited, code=exited status=2# 这种问题一般就是空格导致的，是每一行配置后面都不能有空格，也不能跟注释。 通常而言，vsftp服务器放置于内部局域网使用，前面还有防火墙，一般来说很安全了，不过vsftpd还有更安全的配置方式，就是虚拟用户。 虚拟用户较为复杂，打算在另一篇文章介绍 附录vsftpd.conf常用配置1234567891011121314151617181920212223242526272829303132333435listen=&lt;YES/NO&gt; :设置为YES时vsftpd以独立运行方式启动，设置为NO时以xinetd方式启动（xinetd是管理守护进程的，将服务集中管理，可以减少大量服务的资源消耗）listen_port=&lt;port&gt; :设置控制连接的监听端口号，默认为21listen_address=&lt;ip address&gt; :将在绑定到指定IP地址运行，适合多网卡connect_from_port_20=&lt;YES/NO&gt; :若为YES，则强迫FTP－DATA的数据传送使用port 20，默认YESpasv_enable=&lt;YES/NO&gt; :是否使用被动模式的数据连接，如果客户机在防火墙后，请开启为YESpasv_min_port=&lt;n&gt;pasv_max_port=&lt;m&gt; :设置被动模式后的数据连接端口范围在n和m之间,建议为50000－60000端口message_file=&lt;filename&gt; :设置使用者进入某个目录时显示的文件内容，默认为 .messagedirmessage_enable=&lt;YES/NO&gt; :设置使用者进入某个目录时是否显示由message_file指定的文件内容ftpd_banner=&lt;message&gt; :设置用户连接服务器后的显示信息，就是欢迎信息banner_file=&lt;filename&gt; :设置用户连接服务器后的显示信息存放在指定的filename文件中connect_timeout=&lt;n&gt; :如果客户机连接服务器超过N秒，则强制断线，默认60accept_timeout=&lt;n&gt; :当使用者以被动模式进行数据传输时，服务器发出passive port指令等待客户机超过N秒，则强制断线，默认60accept_connection_timeout=&lt;n&gt; :设置空闲的数据连接在N秒后中断，默认120data_connection_timeout=&lt;n&gt; : 设置空闲的用户会话在N秒后中断，默认300max_clients=&lt;n&gt; : 在独立启动时限制服务器的连接数，0表示无限制max_per_ip=&lt;n&gt; :在独立启动时限制客户机每IP的连接数，0表示无限制（不知道是否跟多线程下载有没干系）local_enable=&lt;YES/NO&gt; :设置是否支持本地用户帐号访问guest_enable=&lt;YES/NO&gt; :设置是否支持虚拟用户帐号访问write_enable=&lt;YES/NO&gt; :是否开放本地用户的写权限local_umask=&lt;nnn&gt; :设置本地用户上传的文件的生成掩码，默认为077local_max_rate&lt;n&gt; :设置本地用户最大的传输速率，单位为bytes/sec，值为0表示不限制local_root=&lt;file&gt; :设置本地用户登陆后的目录，默认为本地用户的主目录chroot_local_user=&lt;YES/NO&gt; :是否将所有用户限制在主目录,YES为启用，NO禁用.(该项默认值是NO)chroot_list_enable=&lt;YES/NO&gt; :是否启动限制用户（特例）的名单 YES为启用，NO禁用(包括注释掉也为禁用)chroot_list_file=&lt;filename&gt; :当chroot_list_enable=YES时，只有filename文件指定的用户为例外用户anonymous_enable=&lt;YES/NO&gt; :设置是否支持匿名用户访问anon_max_rate=&lt;n&gt; :设置匿名用户的最大传输速率，单位为B/s，值为0表示不限制anon_world_readable_only=&lt;YES/NO&gt; 是否开放匿名用户的浏览权限anon_upload_enable=&lt;YES/NO&gt; 设置是否允许匿名用户上传anon_mkdir_write_enable=&lt;YES/NO&gt; :设置是否允许匿名用户创建目录anon_other_write_enable=&lt;YES/NO&gt; :设置是否允许匿名用户其他的写权限（注意，这个在安全上比较重要，一般不建议开，不过关闭会不支持续传）anon_umask=&lt;nnn&gt; :设置匿名用户上传的文件的生成掩码，默认为077]]></content>
      <categories>
        <category>Linux服务</category>
      </categories>
      <tags>
        <tag>Linux服务</tag>
        <tag>文件共享服务</tag>
        <tag>ftp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 文件共享NFS以及autofs部署配置]]></title>
    <url>%2F2020%2F09%2F05%2FLinux%E6%9C%8D%E5%8A%A1%2Fnfs-autofs_install_config%2F</url>
    <content type="text"><![CDATA[简介NFSNFS，即Network File System，网络文件系统。网络文件系统是FreeBSD支持的文件系统中的一种。他最大的特点就是可以通过网络，让不同的机器，不同的系统实现文件共享。NFS客户端可以将NFS服务器共享的目录挂载在本地的文件系统中，访问目录就如同访问自 己本地目录一样 AutoFSAutofs与Mount/Umount的不同之处在于，它是一种看守程序。如果它检测到用户正试图访问一个尚未挂接的文件系统，它就会自动检测该文件系统，如果存在，那么Autofs会自动将其挂接。另一方面，如果它检测到某个已挂接的文件系统在一段时间内没有被使用，那么Autofs会自动将其卸载。因此一旦运行了Autofs后，用户就不再需要手动完成文件系统的挂接和卸载。 准备操作系统CentOS Linux release 7.8.2003 (Core) 最小安装-两台 主机角色 主机：IP 角色 安装服务 node1：192.168.1.201 NFS服务端，NTP服务端（可选） nfs-utils，ntp（可选） node2：192.168.1.202 NFS客户端，NTP服务端（可选） nfs-utils，autofs，ntp（可选） 关闭防火墙12345678910# 两个节点都操作# 关闭selinuxsetenforce 0# 设置selinux开机不自启sed -i 's/=enforcing/=disabled/g' /etc/sysconfig/selinux# 关闭firewallsystemctl stop firewalld# 设置firewall开机不启动systemctl disable firewalld 修改hostname（可选）123# 两个节点分别操作# 根据规划名称修改主机名,以node1为例hostnamectl set-hostname node1 配置阿里yum源（可选，网速好的可以不配置）1234567# 两个节点都操作# 备份原yum源mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup# 下载新的 CentOS-Base.repo 到 /etc/yum.repos.d/curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo# 运行 yum makecache 生成缓存yum makecache 安装vim（可选）12# 两个节点都操作yum install vim -y 配置时间同步（ntp|可选）12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 也可以用chrony时间同步，本质一样# 两个节点都操作# 关闭chrony并设置开机不自启systemctl stop chronydsystemctl disable chronyd# 安装ntpyum install ntp -y# 设置时区为上海timedatectl set-timezone Asia/Shanghai# 设置允许使用ntptimedatectl set-ntp yes# 配置ntp服务端，node1操作# 注释原有的互联网server[root@node1 ~]# sed -i '/^server/ s/^\(.*\)$/# \1/g' /etc/ntp.conf# 添加配置以自身为时间同步源[root@node1 ~]# sed -i '/^# Please / a\server 127.127.1.0 iburst' /etc/ntp.conf# 添加配置时间服务器层级为10，可配置0~16，0为顶级[root@node1 ~]# sed -i '/^server 127/ a\fudge 127.127.1.0 startum 10' /etc/ntp.conf# 注释默认的不允许查询修改[root@node1 ~]# sed -i '/^restrict default/ s/^\(.*\)$/# \1/g' /etc/ntp.conf# 添加配置可访问的客户端网段[root@node1 ~]# sed -i '/^# Hosts/ a\restrict 192.168.1.0 mask 255.255.255.0 nomodify' /etc/ntp.conf# 配置ntp客户端，node2操作# 注释原有的互联网serversed -i '/^server/ s/^\(.*\)$/# \1/g' /etc/ntp.conf# 添加配置以node1为时间同步源sed -i '/^# Please / a\server 192.168.1.201 iburst' /etc/ntp.conf# 两个节点操作# 重启ntp服务systemctl restart ntpd# 设置开机自启systemctl enable ntpd# node2查看同步状态是否正常[root@node2 ~]# ntpstatsynchronised to NTP server (192.168.1.201) at stratum 7 time correct to within 1387 ms polling server every 64 s[root@node2 ~]# ntpq -p remote refid st t when poll reach delay offset jitter==============================================================================*192.168.1.201 LOCAL(0) 6 u 37 64 1 0.407 -0.014 0.051 NFS安装部署安装12# 两个节点都操作yum -y install nfs-utils 配置服务端123456789101112131415# node1操作# 创建要分享的目录，data为分享目录，share为client操作的目录mkdir -p /data/share# 为share目录other组添加权限，后面会说明原因chmod o+w -R /data/share# 编辑/etc/export文件，格式如下:# [共享目录] [客户端IP(参数)] [客户端IP(参数)][root@node1 ~]# vim /etc/exports/data 192.168.1.0/24(ro) 192.168.1.202(rw)# 可以使用完整的IP或者是网络号# 重启服务，nfs依赖于rpcbind，先重启rpcbind[root@node1 ~]# systemctl restart rpcbind[root@node1 ~]# systemctl restart nfs# 导出nfs维护表，重新共享目录[root@node1 ~]# exportfs -r 配置客户端123456789101112131415161718192021222324252627# node2操作# 发现可用的共享文件[root@node2 ~]# showmount -e 192.168.1.201Export list for 192.168.1.201:/data 192.168.1.0/24# 创建目录，用于挂载[root@node2 ~]# mkdir -p /mnt/nfs# 挂载，二选一执行，推荐软挂载## 硬挂载mount -t nfs 192.168.1.201:/data /mnt/nfs[root@node2 ~]# mount -t nfs 192.168.1.201:/data /mnt/nfs[root@node2 ~]# df -hFilesystem Size Used Avail Use% Mounted on......192.168.1.201:/data 17G 1.5G 16G 9% /mnt/nfs## 软挂载[root@node2 ~]# mount -t nfs -o soft,timeo=1 192.168.1.201:/data /mnt/nfs[root@node2 ~]# df -hFilesystem Size Used Avail Use% Mounted on......192.168.1.201:/data 17G 1.5G 16G 9% /mnt/nfs# 参数说明# soft: 软挂载，遇到报错会终止挂载，并返回信息；默认是硬挂载，一直尝试挂载# timeo: 超时时间，配合软挂载使用 使用以及客户端权限问题12345678910111213141516171819202122232425262728293031323334353637# node2操作# 进入共享的目录[root@node2 ~]# cd /mnt/nfs/[root@node2 nfs]# touch a.txttouch: cannot touch ‘a.txt’: Permission denied# 此时会发现无法没有权限创建文件(可读不可写)# 查看nfs权限，nfs对root用户应该是可写的，问题出在什么地方呢？[root@node2 nfs]# ll /mnt/total 0drwxr-xr-x. 3 root root 32 Sep 4 23:48 nfs# 进入share，可以创建文件(可写)[root@node2 ~]# cd /mnt/nfs/share/[root@node2 share]# touch a.txt# share目录权限不同之处在于other组用户是可写的[root@node2 share]# ll /mnt/nfs/total 0drwxr-xrwx. 2 root root 19 Sep 4 23:59 share# 查看客户端创建的文件，属主是nfsnobody[root@node2 share]# lltotal 0-rw-r--r--. 1 nfsnobody nfsnobody 0 Sep 4 23:59 a.txt# node1操作# 查看详细配置[root@node1 ~]# exportfs -v/data 192.168.1.202(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,root_squash,no_all_squash)......# 可以看到rw和root_squash参数# rw:客户端具有可写权限，默认应该是可写的啊，是什么问题呢？# root_squash:如果客户端用root身份访问，则被压缩成nfsnobody,权限也将受到限制。nfsnobody是属于other组用户。所以，在other有可写权限的share目录中可写，在nfs中不可写# 所以，当客户端有权限问题时# 1、查看服务端配置是否可写，权限是否被压缩# 2、可以通过配置不压缩权限（不推荐），或者新建一个other组可写权限的目录share规避# 3、服务端配置root_squash压缩root时，客户端可以新建非root用户规避，但同样，该用户需要有目录相应权限 解读服务端配置文件-exports12345# node1操作# 查看服务端配置，系统默认会给我们加上很多配置[root@node1 ~]# exportfs -v/data 192.168.1.202(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,root_squash,no_all_squash)/data 192.168.1.0/24(sync,wdelay,hide,no_subtree_check,sec=sys,ro,secure,root_squash,no_all_squash) 参数 说明 ro 该共享目录的权限是只读（read-only） rw 该共享目录的权限是可读写（read-write） hide 隐藏文件系统 noaccess 阻止访问这个目录及其子目录 wdelay 为合并多次更新而延迟写入磁盘 no_wdelay 尽可能快地把数据写入磁盘 sync 将数据同步写入内存缓冲区与磁盘中（同步模式） async 将数据线暂存在内存缓冲区中，而非直接写入磁盘（非同步模式） subtree_check 验证每个被请求的文件都在导出的目录树中 no_subtree_check 只验证涉及被导出的文件系统的文件请求 all_squash 将所有本地和远程账户映射到匿名用户 root_squash 将根用户及所属组都映射为匿名用户或用户组（nfsnobody） no_root_squash 将远程根用户当成本地根用户，不建议使用 all_squash 不管访问者是什么身份，包括root，全部压缩至匿名用户 no_all_squash 保留访问用户的身份uid以及gid,一般只能查看，不能修改，权限问题，但是可以强制保存 anonuid 为匿名用户账户指定组ID anongid 为匿名用户账户指定用户ID 卸载时报错处理123456789[root@node2 ~]# umount /mnt/nfs[root@node2 ~]# umount.nfs4: /mnt/jfedu: device is busy# 强行解除挂载[root@node2 ~]# umount -l /mnt/nfs # 或者使用# 将会显示使用这个模块的pid[root@node2 ~]# fuser -m /mnt/nfs # 直接kill那个pid[root@node2 ~]# fuser -mk /mnt/nfs autofs安装部署autofs服务程序与mount命令不同之处在于它是一种守护进程，只有检测到用户试图访问一个尚未挂载 的文件系统时才自动的检测并挂载该文件系统。 autofs非常方便，主要有两点： 设置不需要在开机就挂载的目录，当用的时候才实现自动挂载。 用户不使用自动挂载的目录一段的时间，会自动卸载（默认时间为5分钟）,可以在autofs.conf修改配置 安装12# node2操作[root@node2 ~]# yum install autofs -y autofs配置12345678910111213141516171819202122232425262728293031323334# node2操作# autofs配置主要由/etc/auto.master及其关联的文件(通常为*.misc)两部分构成# 先配置/etc/auto.master# 注释原有的配置映射，新增自己的配置[root@node2 ~]# vim /etc/auto.master# /misc /etc/auto.misc/mnt/nfs /etc/nfs.misc# /mnt/nfs定义了mount的挂载点，是总的访问目录(客户端的目录)# 而/etc/nfs.misc是对总访问目录的描述，定义了mount的动作，用于子目录的编辑、用户权限分离；/etc/nfs.misc本身不存在，可以自己创建# 创建/etc/nfs.misc[root@node2 ~]# vim /etc/nfs.miscshare -fstype=nfs,rw,sync 192.168.1.201:/data# data是nfs服务器共享的目录# -fstype可以配置绝大部分mount -o的所有配置选项# 如果nfs服务端exportfs，设置的权限为ro，那么即使此处写rw，也是不可写的# 如果nfs服务端exportfs，设置的权限为rw，那么可以在此处设置rw或者ro# 重启autofs[root@node2 ~]# systemctl restart autofs# 查看目录，是空的[root@node2 ~]# ll /mnt/nfstotal 0# 访问目录即可以自动挂载[root@node2 ~]# cd /mnt/nfs/share[root@node2 share]# df -hFilesystem Size Used Avail Use% Mounted on......192.168.1.201:/data 17G 1.5G 16G 9% /mnt/nfs/share#查看挂载的参数，可以根据需要在/etc/nfs.misc设置[root@node2 share]# mount......192.168.1.201:/data on /mnt/nfs/share type nfs4 (rw,relatime,sync,vers=4.1,rsize=131072,wsize=131072,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=192.168.1.202,local_lock=none,addr=192.168.1.201) NFS常用命令1234567891011121314151617181920212223# 格式：nfsstat [参数]# 参数如下：## -m, --mounts 显示已经挂载的nfs文件系统的详细参数## -c, --client 显示NFS客户端的统计信息## -s, --server 显示NFS服务器端的统计信息## -2 显示nfsv2的统计信息## -3 显示nfsv3的统计信息## -4 显示nfsv4的统计信息## nfsstat -o [facility] 显示指定类型的统计信息## facility如下：#### nfs NFS协议信息#### rpc 一般RPC信息#### net 网络统计信息#### all 显示以上所有信息# 格式：rpcinfo [参数]-p 显示注册的端口-m 显示 rpcbind 操作的统计信息表-s 显示所有已注册的 RPC 程序的简明列表-T 显示有关使用特定传输或协议的服务的信息-t 探测使用 TCP 的 RPC 程序-u 探测使用 UDP 的 RPC 程序 NFS简单原理NFS服务由五个守护进程（daemon）负责： rpc.nfsd，它做了大部分的工作； rpc.lockd以及rpc.statd，处理文件锁定； rpc.mountd，它处理初始装载请求， 以及rpc.rquotad，它处理导出卷上的用户文件配额。 每个daemon都需要占用一些端口，但有些daemon是可选的，也许用户根本不会启用它们。所以，NFS并没有给每个NFS daemon保留固定端口。然而，客户端需要知道服务端的这些端口，所以就有了rpcbind进程（之前为rpc.portmap，原理功能一样），用于端口的分配 在系统启动时，给需要启用的NFS daemon分配端口，然后把这些端口号告诉rpcbind。rpcbind的端口号是固定的111。当客户端需要连接NFS的某个daemon时，就先咨询rpcbind，获得该NFS daemon对应的端口号，然后再发送NFS请求。如下图所示 基本流程如下： 首先服务器端启动rpcbind，并开启111端口 服务器端启动NFS服务，并向rpcbind注册端口信息 客户端启动rpcbind，向服务端的rpcbind服务请求服务端的NFS服务端口 服务端的rpcbind服务反馈NFS服务端口信息给客户端。 客户端通过获取的NFS服务端口来建立和服务端的NFS连接并进行数据的传输 注： 1、在启动NFS SERVER之前，首先要启动rpcbind服务（即portmap服务），否则NFS SERVER就无法向RPC服务区注册 2、如果RPC服务重新启动，原来已经注册好的NFS端口数据就会全部丢失。因此此时RPC服务管理的NFS程序也要重新启动以重新向RPC注册 3、一般修改NFS配置文档后，不需要重启NFS的，systemctl reload nfs或exportfs –rv即可使修改的/etc/exports生效 NFS常用优化参数主要优化mount -o 的相关参数（同autofs的-fstype参数） 123456789101112async：异步同步，数据不会立刻同步至磁盘，此参数会提高I/O性能，但会降低数据安全（除非对性能要求很高，对数据可靠性不要求的场合。一般生产环境，不推荐使用）。noatime：取消更新文件系统上的inode访问时间,提升I/O性能，优化I/O目的，推荐使用。nodiratime：取消更新文件系统上的directory inode访问时间，高并发环境，推荐显式应用该选项，提高系统性能noexec：挂载的这个文件系统，要不要执行程序（安全选项）。nosuid：挂载的这个文件系统上面，可不可以设置UID（安全选项）。rsize/wsize：读取（rsize）/写入（wsize）的区块大小（block size），这个设置值可以影响客户端与服务端传输数据的缓冲存储量。一般来说，如果在局域网内，并且客户端与服务端都具有足够内存，这个值可以设置大一点，比如说32768（bytes）,提升缓冲区块将可提升NFS文件系统的传输能力 附录ntp配置文件ntp服务端 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# For more information about this file, see the man pages# ntp.conf(5), ntp_acc(5), ntp_auth(5), ntp_clock(5), ntp_misc(5), ntp_mon(5).driftfile /var/lib/ntp/drift# Permit time synchronization with our time source, but do not# permit the source to query or modify the service on this system.# restrict default nomodify notrap nopeer noquery# Permit all access over the loopback interface. This could# be tightened as well, but to do so would effect some of# the administrative functions.restrict 127.0.0.1 restrict ::1# Hosts on local network are less restricted.restrict 192.168.1.0 mask 255.255.255.0 nomodify#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap# Use public servers from the pool.ntp.org project.# Please consider joining the pool (http://www.pool.ntp.org/join.html).server 127.127.1.0 iburstfudge 127.127.1.0 startum 10# server 0.centos.pool.ntp.org iburst# server 1.centos.pool.ntp.org iburst# server 2.centos.pool.ntp.org iburst# server 3.centos.pool.ntp.org iburst#broadcast 192.168.1.255 autokey # broadcast server#broadcastclient # broadcast client#broadcast 224.0.1.1 autokey # multicast server#multicastclient 224.0.1.1 # multicast client#manycastserver 239.255.254.254 # manycast server#manycastclient 239.255.254.254 autokey # manycast client# Enable public key cryptography.#cryptoincludefile /etc/ntp/crypto/pw# Key file containing the keys and key identifiers used when operating# with symmetric key cryptography. keys /etc/ntp/keys# Specify the key identifiers which are trusted.#trustedkey 4 8 42# Specify the key identifier to use with the ntpdc utility.#requestkey 8# Specify the key identifier to use with the ntpq utility.#controlkey 8# Enable writing of statistics records.#statistics clockstats cryptostats loopstats peerstats# Disable the monitoring facility to prevent amplification attacks using ntpdc# monlist command when default restrict does not include the noquery flag. See# CVE-2013-5211 for more details.# Note: Monitoring will not be disabled with the limited restriction flag.disable monitor ntp客户端 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# For more information about this file, see the man pages# ntp.conf(5), ntp_acc(5), ntp_auth(5), ntp_clock(5), ntp_misc(5), ntp_mon(5).driftfile /var/lib/ntp/drift# Permit time synchronization with our time source, but do not# permit the source to query or modify the service on this system.restrict default nomodify notrap nopeer noquery# Permit all access over the loopback interface. This could# be tightened as well, but to do so would effect some of# the administrative functions.restrict 127.0.0.1 restrict ::1# Hosts on local network are less restricted.#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap# Use public servers from the pool.ntp.org project.# Please consider joining the pool (http://www.pool.ntp.org/join.html).server 192.168.1.201 iburst# server 0.centos.pool.ntp.org iburst# server 1.centos.pool.ntp.org iburst# server 2.centos.pool.ntp.org iburst# server 3.centos.pool.ntp.org iburst#broadcast 192.168.1.255 autokey # broadcast server#broadcastclient # broadcast client#broadcast 224.0.1.1 autokey # multicast server#multicastclient 224.0.1.1 # multicast client#manycastserver 239.255.254.254 # manycast server#manycastclient 239.255.254.254 autokey # manycast client# Enable public key cryptography.#cryptoincludefile /etc/ntp/crypto/pw# Key file containing the keys and key identifiers used when operating# with symmetric key cryptography. keys /etc/ntp/keys# Specify the key identifiers which are trusted.#trustedkey 4 8 42# Specify the key identifier to use with the ntpdc utility.#requestkey 8# Specify the key identifier to use with the ntpq utility.#controlkey 8# Enable writing of statistics records.#statistics clockstats cryptostats loopstats peerstats# Disable the monitoring facility to prevent amplification attacks using ntpdc# monlist command when default restrict does not include the noquery flag. See# CVE-2013-5211 for more details.# Note: Monitoring will not be disabled with the limited restriction flag.disable monitor]]></content>
      <categories>
        <category>Linux服务</category>
      </categories>
      <tags>
        <tag>Linux服务</tag>
        <tag>文件共享服务</tag>
        <tag>nfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ceph-deploy安装ceph集群-nautilus版]]></title>
    <url>%2F2020%2F08%2F29%2FLinux%E6%9C%8D%E5%8A%A1%2Fceph_nautilus_install%2F</url>
    <content type="text"><![CDATA[ceph-deploy安装ceph集群准备主机设置 节点 系统 IP地址 安装软件 时间同步 ceph-admin CentOS 7 x64 2003 192.168.1.150192.168.2.150 ceph-deploy server ceph-node1 CentOS 7 x64 2003 192.168.1.151192.168.2.151 mon / osd client ceph-node2 CentOS 7 x64 2003 192.168.1.152192.168.2.152 osd client ceph-node3 CentOS 7 x64 2003 192.168.1.153192.168.2.153 osd client ceph-client CentOS 7 x64 2003 192.168.1.154192.168.2.154 client 准备工作0、配置aliyun的基础yum源（自认网速好的可以不设置） 1234567891011# 所有节点操作# 备份原有的配置文件mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup# 下载aliyun的CentOS 7的yum配置文件curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo# 或 (注：最小安装没有wget)wget -O /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo# 生成缓存yum makecache 1、安装vim（可选） 12# 所有节点操作yum install -y vim 2、修改hostname为节点名并相互解析 123456789101112# 所有节点操作# 根据预定的名称修改，以ceph-admin为例hostnamectl set-hostname ceph-admin# 配置hosts相互解析cat&gt;&gt;/etc/hosts&lt;&lt;EOF192.168.2.150 ceph-admin192.168.2.151 ceph-node1192.168.2.152 ceph-node2192.168.2.153 ceph-node3192.168.2.154 ceph-clientEOF 3、关闭防火墙以及selinux 12345678# 所有节点操作# 关闭防火墙并设置开启不启动systemctl stop firewalldsystemctl disable firewalld# 关闭selinux并设置开启不启动setenforce 0sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux 4、配置chrony时间同步 123456789101112131415161718192021222324252627# 所有节点设置时区timedatectl set-timezone Asia/Shanghai# ceph-admin节点操作,配置成chrony server# 注释原有的时间同步server[root@ceph-admin ~]# sed -i '/^server/ s/^\(.*\)$/# \1/g' /etc/chrony.conf# 新增以自己为server[root@ceph-admin ~]# sed -i '/^# Please / a\server 127.127.0.1 iburst' /etc/chrony.conf# 配置允许访问的client网段[root@ceph-admin ~]# sed -i '/#allow / a\allow 192.168.2.0/24' /etc/chrony.conf# 设置即使不同步其他时钟源，该server依然可以作为时钟源[root@ceph-admin ~]# sed -i '/^#local / s/^#\(.*\)$/\1/g' /etc/chrony.conf# 其他节点操作,配置成chrony client# 注释原有的时间同步serversed -i '/^server/ s/^\(.*\)$/# \1/g' /etc/chrony.conf# 新增以ceph-admin为serversed -i '/^# Please / a\server 192.168.2.150 iburst' /etc/chrony.conf# 所有节点重启chrony，使其生效systemctl restart chronyd# 检查时间同步是否正常，client端出现*号表示时间同步正常[root@ceph-node1 ~]# chronyc sources210 Number of sources = 1MS Name/IP address Stratum Poll Reach LastRx Last sample ===============================================================================^* 192.168.2.150 10 6 17 29 -3121ns[ -90us] +/- 100us 5、配epel源和ceph源 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# 所有节点操作,包括client# 配置aliyun的epel源# 备份(如有配置其他epel源)mv /etc/yum.repos.d/epel.repo /etc/yum.repos.d/epel.repo.backupmv /etc/yum.repos.d/epel-testing.repo /etc/yum.repos.d/epel-testing.repo.backup# 下载新repo 到/etc/yum.repos.d/curl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo# 或wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo# 配置aliyun的ceph源,一般只用[ceph-noarch]cat&gt;/etc/yum.repos.d/ceph.repo&lt;&lt;EOF[ceph-source]name=Ceph source packagesbaseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/SRPMS/enabled=1gpgcheck=0type=rpm-mdgpgkey=https://mirrors.aliyun.com/ceph/keys/release.ascpriority=1[ceph-aarch64]name=Ceph aarch64 packagesbaseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/aarch64/enabled=1gpgcheck=0type=rpm-mdgpgkey=https://mirrors.aliyun.com/ceph/keys/release.ascpriority=1[ceph-noarch]name=Ceph noarch packagesbaseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/noarch/enabled=1gpgcheck=0type=rpm-mdgpgkey=https://mirrors.aliyun.com/ceph/keys/release.ascpriority=1[ceph-x86_64]name=Ceph x86_64 packagesbaseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/x86_64/enabled=1gpgcheck=0type=rpm-mdgpgkey=https://mirrors.aliyun.com/ceph/keys/release.ascpriority=1EOF# 更新并查看配置的仓库yum updateyum repolist# 应出现epel和ceph仓库信息# 生成缓存yum makecache 6、设置ssh免密码登录 123456789# ceph-admin节点操作# 由于使用root用户安装，所以不创建新账号# 创建公钥，选项全部默认[root@ceph-admin ~]# ssh-keygen# 将公钥分发到各个node节点[root@ceph-admin ~]# ssh-copy-id -i /root/.ssh/id_rsa.pub ceph-node1[root@ceph-admin ~]# ssh-copy-id -i /root/.ssh/id_rsa.pub ceph-node2[root@ceph-admin ~]# ssh-copy-id -i /root/.ssh/id_rsa.pub ceph-node3[root@ceph-admin ~]# ssh-copy-id -i /root/.ssh/id_rsa.pub ceph-client 7、admin节点安装ceph-deploy 1234567891011[root@ceph-admin ~]# yum -y install ceph-deploy# 安装python的distrubute包，ceph-deploy运行需要该模块# python的distribute包网址https://pypi.org/project/distribute/，找到下载路径下载[root@ceph-admin ~]# yum install -y unzip# 下载解压，也可以用迅雷或其他工具下载后传上去，看自己网速[root@ceph-admin ~]# wget https://files.pythonhosted.org/packages/5f/ad/1fde06877a8d7d5c9b60eff7de2d452f639916ae1d48f0b8f97bf97e570a/distribute-0.7.3.zip[root@ceph-admin ~]# unzip distribute-0.7.3.zip [root@ceph-admin ~]# cd distribute-0.7.3# 安装distribute模块[root@ceph-admin distribute-0.7.3]# python setup.py install[root@ceph-admin distribute-0.7.3]# cd 部署集群创建集群1、admin节点创建集群 1234567# 因为部署会产生许多文件，所以创建一个文件[root@ceph-admin ~]# mkdir -p /root/my-cluster[root@ceph-admin ~]# cd ~/my-cluster# 创建一个集群,配置public-network用于对外服务，cluster-network用于集群内部同步，配置monitor节点为ceph-node1ceph-deploy new --public-network 192.168.1.0/24 --cluster-network 192.168.2.0/24 ceph-node1[root@ceph-admin my-cluster]# ceph-deploy new --public-network 192.168.1.0/24 --cluster-network 192.168.2.0/24 ceph-node1 2、node节点安装软件包 123# 3个node节点运行# 根据角色，node节点安装ceph软件包，此处全装yum install -y ceph ceph-mon ceph-mgr ceph-radosgw ceph-mds 3、admin节点初始化monitor 1234# admin节点运行，初始化monitor[root@ceph-admin my-cluster]# ceph-deploy mon create-initial# 将配置文件以管理员（admin）用推送到各个节点，注：此处的admin是代表管理员角色，与节点无关[root@ceph-admin my-cluster]# ceph-deploy admin ceph-node1 ceph-node2 ceph-node3 4、在monitor节点检查是否初始化完成 12345678910111213141516# node1节点（monitor节点）查看集群是否初始化成功，HEALTH_OK代表集群正常[root@ceph-node1 ~]# ceph -s cluster: id: 1f1dd9dd-355b-4224-a995-e2ea3da78a01 health: HEALTH_OK services: mon: 1 daemons, quorum ceph-node1 (age 5m) mgr: no daemons active osd: 0 osds: 0 up, 0 in data: pools: 0 pools, 0 pgs objects: 0 objects, 0 B usage: 0 B used, 0 B / 0 B avail pgs: 5、部署manager demon（mgr）用于监控 12345678910111213141516171819202122# admin节点运行# 部署mgr到node1节点[root@ceph-admin my-cluster]# ceph-deploy mgr create ceph-node1# node1节点运行，查看mgr是否添加到ceph集群# 此处的HEALTH_WARN代表还没添加OSD[root@ceph-node1 ~]# ceph -s cluster: id: 1f1dd9dd-355b-4224-a995-e2ea3da78a01 health: HEALTH_WARN OSD count 0 &lt; osd_pool_default_size 3 services: mon: 1 daemons, quorum ceph-node1 (age 13m) mgr: ceph-node1(active, since 2m) osd: 0 osds: 0 up, 0 in data: pools: 0 pools, 0 pgs objects: 0 objects, 0 B usage: 0 B used, 0 B / 0 B avail pgs: 6、添加OSD 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 每台主机上添加两块5G的硬盘# 如下/dev/sdb和/dev/sdc即为要添加为OSD的硬盘，无需格式化[root@ceph-node1 ~]# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 20G 0 disk ├─sda1 8:1 0 1G 0 part /boot└─sda2 8:2 0 19G 0 part ├─centos-root 253:0 0 17G 0 lvm / └─centos-swap 253:1 0 2G 0 lvm [SWAP]sdb 8:16 0 5G 0 disk sdc 8:32 0 5G 0 disk sr0 11:0 1 9.6G 0 rom # admin节点操作，生产中可以加上journal进行加速# 将三个节点的/dev/sdb加入OSD[root@ceph-admin my-cluster]# ceph-deploy osd create ceph-node1 --data /dev/sdb[root@ceph-admin my-cluster]# ceph-deploy osd create ceph-node2 --data /dev/sdb[root@ceph-admin my-cluster]# ceph-deploy osd create ceph-node2 --data /dev/sdb# 可以在monitor节点查看osd[root@ceph-node1 ~]# ceph osd treeID CLASS WEIGHT TYPE NAME STATUS REWEIGHT PRI-AFF -1 0.01469 root default -3 0.00490 host ceph-node1 0 hdd 0.00490 osd.0 up 1.00000 1.00000 -5 0.00490 host ceph-node2 1 hdd 0.00490 osd.1 up 1.00000 1.00000 -7 0.00490 host ceph-node3 2 hdd 0.00490 osd.2 up 1.00000 1.00000 # 至此，一个简易版的集群已经部署完毕，包含一个monitor、一个mgr、三个osd[root@ceph-node1 ~]# ceph -s cluster: id: 1f1dd9dd-355b-4224-a995-e2ea3da78a01 health: HEALTH_OK services: mon: 1 daemons, quorum ceph-node1 (age 39m) mgr: ceph-node1(active, since 39m) osd: 3 osds: 3 up (since 3m), 3 in (since 3m) data: pools: 0 pools, 0 pgs objects: 0 objects, 0 B usage: 3.0 GiB used, 12 GiB / 15 GiB avail pgs: 扩展集群扩展mon和mgr 123456789101112131415161718192021222324252627282930313233343536373839404142434445# mon是集群的核心，使用了paxos算法，所以一般会使用奇数个节点# admin节点操作，添加node2和node3为monitor[root@ceph-admin my-cluster]# ceph-deploy mon add ceph-node2 --address 192.168.2.152[root@ceph-admin my-cluster]# ceph-deploy mon add ceph-node3 --address 192.168.2.153# 查看仲裁状态[root@ceph-node1 ~]#ceph quorum_status --format json-pretty# 或查看mon状态[root@ceph-node1 ~]# ceph mon state3: 3 mons at &#123;ceph-node1=[v2:192.168.1.151:3300/0,v1:192.168.1.151:6789/0],ceph-node2=[v2:192.168.1.152:3300/0,v1:192.168.1.152:6789/0],ceph-node3=[v2:192.168.1.153:3300/0,v1:192.168.1.153:6789/0]&#125;, election epoch 14, leader 0 ceph-node1, quorum 0,1,2 ceph-node1,ceph-node2,ceph-node3# 查看mon详细状态[root@ceph-node1 ~]# ceph mon dump dumped monmap epoch 3epoch 3fsid 1f1dd9dd-355b-4224-a995-e2ea3da78a01last_changed 2020-08-25 12:37:16.468139created 2020-08-25 11:20:41.663956min_mon_release 14 (nautilus)0: [v2:192.168.1.151:3300/0,v1:192.168.1.151:6789/0] mon.ceph-node11: [v2:192.168.1.152:3300/0,v1:192.168.1.152:6789/0] mon.ceph-node22: [v2:192.168.1.153:3300/0,v1:192.168.1.153:6789/0] mon.ceph-node3# mgr默认是主备模式，同一时间只有一个是运行的# admin节点操作，扩容mgr[root@ceph-admin my-cluster]# ceph-deploy mgr create ceph-node2 ceph-node3# node1节点查看当前mgr[root@ceph-node1 ~]# ceph -s cluster: id: 1f1dd9dd-355b-4224-a995-e2ea3da78a01 health: HEALTH_OK services: mon: 3 daemons, quorum ceph-node1,ceph-node2,ceph-node3 (age 10m) mgr: ceph-node1(active, since 60m), standbys: ceph-node2, ceph-node3 osd: 3 osds: 3 up (since 24m), 3 in (since 24m) data: pools: 0 pools, 0 pgs objects: 0 objects, 0 B usage: 3.0 GiB used, 12 GiB / 15 GiB avail pgs: # 可以看到node1是主，运行状态，node2 node3是备用 # 至此，集群拥有三个monitor、三个mgr、三个OSD 使用ceph存储-rbd创建pool 123456789# monitor节点运行# 创建存储池，ceph-demo为pool name，默认三个副本[root@ceph-node1 ~]# ceph osd pool create ceph-demo 64 64pool 'ceph-demo' created# 查看所有pool[root@ceph-node1 ~]# ceph osd lspools1 ceph-demo#查看pool详细信息，pg数量，pgp数量，副本数，调度算法等；可以用set设置pool配置[root@ceph-node1 ~]# ceph osd pool get ceph-demo pg_num|pgp_num|size|crush_rule 客户端安装ceph 1234567[root@ceph-client ~]# yum -y install ceph ceph-radosgw# 查看是否安装成功[root@ceph-client ~]# ceph --versionceph version 14.2.11 (f7fdb2f52131f54b891a2ec99d8205561242cdaf) nautilus (stable)# admin节点赋于管理员权限给client[root@ceph-admin my-cluster]# ceph-deploy admin ceph-client RBD使用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475# client节点操作# 创建一个10G的rbd镜像，使用pool为ceph-demo，feature为layering# 关于feature，CentOS 7 2003内核为3.10.0-1127.el7.x86_64，只支持layering，需要其他feature请升级内核4.x以上[root@ceph-client ~]# rbd create -p ceph-demo --image rbd-demo.img --size 10G --image-feature layering# 或者[root@ceph-client ~]# rbd create ceph-demo/rbd-demo1.img --size 10G# 初始化rbd[root@ceph-client ~]# rbd pool init ceph-demo# 查看pool下的所有rbd[root@ceph-client ~]# rbd -p ceph-demo lsrbd-demo.imgrbd-demo1.img# 查看rbd详细信息[root@ceph-client ~]# rbd info ceph-demo/rbd-demo.imgrbd image 'rbd-demo.img': size 10 GiB in 2560 objects order 22 (4 MiB objects) snapshot_count: 0 id: 38346e95f989 block_name_prefix: rbd_data.38346e95f989 format: 2 features: layering op_features: flags: create_timestamp: Tue Aug 25 23:45:29 2020 access_timestamp: Tue Aug 25 23:45:29 2020 modify_timestamp: Tue Aug 25 23:45:29 2020# 删除rbd镜像[root@ceph-client ~]# rbd rm -p ceph-demo --image rbd-demo1.imgRemoving image: 100% complete...done.# 映射[root@ceph-client ~]# rbd map ceph-demo/rbd-demo.img/dev/rbd0# 查看rbd信息[root@ceph-client ~]# rbd device listid pool namespace image snap device 0 ceph-demo rbd-demo.img - /dev/rbd0 # 可以看到多出了一个裸设备/dev/rdb0[root@ceph-client ~]# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 20G 0 disk ├─sda1 8:1 0 1G 0 part /boot└─sda2 8:2 0 19G 0 part ├─centos-root 253:0 0 17G 0 lvm / └─centos-swap 253:1 0 2G 0 lvm [SWAP]sr0 11:0 1 1024M 0 rom rbd0 252:0 0 10G 0 disk # 格式化设备，挂载使用[root@ceph-client ~]# mkfs.ext4 /dev/rbd0# 挂载[root@ceph-client ~]# mkdir /mnt/rbd-demo[root@ceph-client ~]# mount /dev/rbd0 /mnt/rbd-demo[root@ceph-client ~]# df -hTFilesystem Type Size Used Avail Use% Mounted ondevtmpfs devtmpfs 475M 0 475M 0% /devtmpfs tmpfs 487M 0 487M 0% /dev/shmtmpfs tmpfs 487M 7.7M 479M 2% /runtmpfs tmpfs 487M 0 487M 0% /sys/fs/cgroup/dev/mapper/centos-root xfs 17G 2.0G 16G 12% //dev/sda1 xfs 1014M 168M 847M 17% /boottmpfs tmpfs 98M 0 98M 0% /run/user/0/dev/rbd0 ext4 9.8G 37M 9.2G 1% /mnt/rbd-demo# 至此，rbd挂载完成，可以正常使用 扩容rbd 12345678910111213141516171819202122# 扩容rbd[root@ceph-client ~]# rbd resize ceph-demo/rbd-demo.img --size 10GResizing image: 100% complete...done.#刷新文件系统[root@ceph-client ~]# resize2fs /dev/rbd0resize2fs 1.42.9 (28-Dec-2013)Filesystem at /dev/rbd0 is mounted on /mnt/rbd-demo; on-line resizing requiredold_desc_blocks = 1, new_desc_blocks = 2The filesystem on /dev/rbd0 is now 2621440 blocks long.# 查看是否扩容成功[root@ceph-client ~]# df -hFilesystem Size Used Avail Use% Mounted ondevtmpfs 475M 0 475M 0% /devtmpfs 487M 0 487M 0% /dev/shmtmpfs 487M 7.7M 479M 2% /runtmpfs 487M 0 487M 0% /sys/fs/cgroup/dev/mapper/centos-root 17G 2.0G 16G 12% //dev/sda1 1014M 168M 847M 17% /boot/dev/rbd0 9.8G 23M 9.3G 1% /mnt/rbd-demotmpfs 98M 0 98M 0% /run/user/0]]></content>
      <categories>
        <category>Linux服务</category>
      </categories>
      <tags>
        <tag>Linux服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables原理简介]]></title>
    <url>%2F2020%2F06%2F09%2FLinux%E6%9C%8D%E5%8A%A1%2Fiptables_theory%2F</url>
    <content type="text"><![CDATA[iptables和netfilteriptables其实不是真正的防火墙，我们可以把它理解成一个客户端代理，用户通过 iptables这个代理，将用户的安全设定执行到对应的安全框架”中，这个”安全框架”才是真正的防火墙，这个框架的名字叫 netfilter。netfilter才是防火墙真正的安全框架（ framework）， netfilter位于内核空间。iptables其实是个命令行工具，位于用户空间，我们用这个工具操作真正的框架 表、链和规则iptables结构iptables -&gt; 表 -&gt; 链 -&gt; 规则（ iptables -&gt; tables -&gt; chains -&gt; rules）. 简单地讲，表由链组成，而链又由规则组成。我们通过设置规则来完成过滤、重定向、修改数据包等功能 iptables的内建链和内建表链（chain）什么是链呢？当数据包从网络上来到主机，需要经过一些关卡，经过这些关卡的时候，则必须符合通过的条件，而且，关卡会根据检验条件来放行、拒绝或者丢弃数据等等；这里的关卡就是链，而条件就是规则；iptables默认有5个内建链，如下图所示： 每个内建链的功能如下： INPUT链 – 处理来自外部的数据 OUTPUT链 – 处理向外发送的数据 FORWARD链– 将数据转发到本机的其他网卡设备上 PREROUTING链 – 处理刚到达本机并在路由转发前的数据包。它可以转换数据包中的目标IP地址（destination ip address），通常用于DNAT(destination NAT) POSTROUTING链 – 处理即将离开本机的数据包。它可以转换数据包中的源IP地址（source ip address），通常用于SNAT（source NAT） 处理不同方向的数据，由不同内建链负责，系统内建链与数据流向可以由下图描述 根据上图，我们能够得知报文的流向 到本机某进程的报文： PREROUTING --&gt; INPUT 由本机转发的报文： PREROUTING --&gt; FORWARD --&gt; POSTROUTING 由本机的某进程发出报文： OUTPUT --&gt; POSTROUTING 表（table）我们对每个链上都放置了一串规则，但是有些规则负责的功能有些很相似，这个时候，我们把具有相同功能的规则的集合叫做表，所以说，不同功能的规则，我们可以放置在不同的表中进行管理，而 iptables已经为我们定义了4种表，每种表对应了不同的功能 filter表：负责过滤数据包，有以下三种内建链： INPUT OUTPUT FORWARD nat表：负责网络地址转换功能；有以下三种内建链： PREROUTING POSTROUTING OUTPUT INPUT链（CentOS6中不存在，CentOS7新增加） mangle表：拆解报文，做出修改，并重新封装数据包；能改变TCP头中的QoS位；有以下5个内建链： PREROUTING OUTPUT FORWARD INPUT POSTROUTING raw表：用于处理异常， 在整个防火墙体系优先级最高，如果启动用raw表，数据将会跳过conntrack（关闭nat表上启用的连接追踪机制；），有以下2个内建链： PREROUTING OUTPUT 加上表的描述，数据包经过防火墙的流程可以总结为下图： 优先级次序优先次序关系到规则对数据包的匹配 表间优先顺序raw -–&gt; mangle –-&gt; nat -–&gt; filter 链间优先顺序入站数据：PREROUTING、INPUT出站数据：OUTPUT、POSTROUTING转发数据：PREROUTING、FORWARD、POSTROUTING 链内规则匹配顺序自上向下按顺序依次进行检查，找到相匹配的规则即停止，若在该链内找不到的相匹配的规则，则按该链的默认策略处理（未修改的情况下，默认策略为允许ACCEPT） iptables的规则牢记以下三点式理解iptables规则的关键： Rules包括一个条件和一个目标(target) 如果满足条件，就执行目标(target)中的规则或者特定值。 如果不满足条件，就判断下一条Rules 目标值（Target Values） 下面是你可以在target里指定的特殊值： ACCEPT：允许数据包通过 DROP：直接丢弃数据包，不给任何回应信息，这时候客户端会感觉自己的请求泥牛入海了，过了超时时间才会有反应 REJECT：拒绝数据包通过，必要时会给数据发送端响应信息，客户端刚请求就会收到拒绝的信息 SNAT：源地址转换，解决内网用户用同一个公网地址上网的问题 MASQUERADE：是SNAT的种特殊形式，适用于动态的、临时会变的IP上 DNAT：目标地址转换 REDIRECT：在本机做端口映射 LOG：在文件中记录日志信息，然后将数据包传递给下一条规则，也就是说除了记录以外不对数据包做任何其他操作，仍然让下一条规则去匹配 举例1iptables -t filter -I INPUT -p tcp --dport 12345 -j REJECT 该命令表示在filter表的INPUT链上添加一条REJECT规则，由以上可知，INPUT链在数据流入的方向上，将tcp连接且目标端口为12345的数据包拒绝掉，即以tcp访问本机12345的数据都会被拒绝，达到防火墙的目的 本文为原理简介，关于更多iptables的操作将有另一篇文章说明]]></content>
      <categories>
        <category>Linux服务</category>
      </categories>
      <tags>
        <tag>Linux服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 安装Redis 6.x]]></title>
    <url>%2F2020%2F06%2F08%2FLinux%E6%9C%8D%E5%8A%A1%2Fcentos7_redis6_install%2F</url>
    <content type="text"><![CDATA[环境CentOS Linux release 7.7.1908 Minimal Install redis-6.0.4 Redis安装过程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[root@oliva ~]# yum -y install wget gcc[root@oliva ~]# yum -y install tcl# 获取安装包，解压[root@oliva ~]# wget http://download.redis.io/releases/redis-6.0.4.tar.gz[root@oliva ~]# tar -zxvf redis-6.0.4.tar.gz# 内存管理器jemalloc安装方式选择一种操作即可# 安装jemalloc方式一[root@oliva ~]# yum -y install bzip2[root@oliva ~]# wget https://github.com/jemalloc/jemalloc/releases/download/5.2.1/jemalloc-5.2.1.tar.bz2[root@oliva ~]# tar -xvf jemalloc-5.2.1.tar.bz2 [root@oliva jemalloc-5.2.1]# cd jemalloc-5.2.1[root@oliva jemalloc-5.2.1]# ./configure --prefix=/usr/local/jemalloc[root@oliva jemalloc-5.2.1]# make &amp;&amp; make install[root@oliva jemalloc-5.2.1]# cd ../# 安装jemalloc方式二# 安装epel源[root@oliva ~]# yum -y install epel-release[root@oliva ~]# yum clean all &amp;&amp; yum makecache[root@oliva ~]# yum -y install jemalloc# 由于redis编译时对gcc版本有要求，所以此处需要临时升级gcc,退出shell或重启失效[root@oliva ~]# yum -y install centos-release-scl[root@oliva ~]# yum -y install devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-binutils[root@oliva ~]# scl enable devtoolset-9 bash[root@oliva ~]# cd redis-6.0.4# 方式一安装jemalloc时，需要手动指定内存管理器MALLOC为jemalloc[root@oliva redis-6.0.4]# make MALLOC=/usr/local/jemalloc/lib/[root@oliva redis-6.0.4]# make install PREFIX=/usr/local/redis# 配置后台启动[root@oliva redis-6.0.4]# cp ./redis.conf /usr/local/redis/bin/[root@oliva redis-6.0.4]# vi /usr/local/redis/bin/redis.conf # 将daemonize由no改为yes# 启动redis[root@oliva redis-6.0.4]# cd /usr/local/redis/bin/[root@oliva bin]# ./redis-server redis.conf 6557:C 09 Jun 2020 07:16:44.327 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo6557:C 09 Jun 2020 07:16:44.327 # Redis version=6.0.4, bits=64, commit=00000000, modified=0, pid=6557, just started6557:C 09 Jun 2020 07:16:44.327 # Configuration loaded# 检查redis-server是否启动成功[root@oliva bin]# ps -ef | grep redisroot 6558 1 0 07:16 ? 00:00:00 ./redis-server 127.0.0.1:6379root 6563 5640 0 07:16 pts/0 00:00:00 grep --color=auto redis 设置开机启动1234567891011121314[root@oliva bin]# vi /etc/systemd/system/redis.service[Unit]Description=redis-serverAfter=network.target[Service]Type=forkingExecStart=/usr/local/redis/bin/redis-server /usr/local/redis/bin/redis.confPrivateTmp=true[Install]WantedBy=multi-user.target[root@oliva bin]# systemctl daemon-reload[root@oliva bin]# systemctl start redis.service[root@oliva bin]# systemctl enable redis.service]]></content>
      <categories>
        <category>Linux服务</category>
      </categories>
      <tags>
        <tag>Linux服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[华为交换机vlan配置（基于端口和子网方式）]]></title>
    <url>%2F2020%2F06%2F08%2F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%2Fhw_vlan_port_subnet%2F</url>
    <content type="text"><![CDATA[网络拓扑图 交换机SW1配置基于端口划分vlan，连接PC端口均为access口；SW2连接PC端口均为hybrid口，且配置基于子网划分vlan；vlan划分如下表所示； 交换机 端口 端口类型 VLAN设置 对端设备 SW1 0/0/1 access 2 192.168.1.1/24 SW1 0/0/2 access 3 192.168.2.1/24 SW1 0/0/3 access 4 192.168.3.1/24 SW1 0/0/24 trunk 2 3 4 SW2 SW2 0/0/1 hybrid 2 3 4 192.168.1.2/24 SW2 0/0/2 hybrid 2 3 4 192.168.2.2/24 SW2 0/0/3 hybrid 2 3 4 192.168.3.2/24 SW2 0/0/24 trunk 2 3 4 SW1 交换机SW1配置1234567891011121314151617181920&lt;Huawei&gt;sys[Huawei]vlan batch 2 4[Huawei]interface GigabitEthernet 0/0/1[Huawei-GigabitEthernet0/0/1]port link-type access [Huawei-GigabitEthernet0/0/1]port default vlan 2[Huawei-GigabitEthernet0/0/1]quit[Huawei]interface GigabitEthernet 0/0/2[Huawei-GigabitEthernet0/0/2]port link-type access [Huawei-GigabitEthernet0/0/2]port default vlan 3[Huawei-GigabitEthernet0/0/2]quit[Huawei]interface GigabitEthernet 0/0/3[Huawei-GigabitEthernet0/0/3]port link-type access [Huawei-GigabitEthernet0/0/3]port default vlan 4[Huawei-GigabitEthernet0/0/3]quit[Huawei]interface GigabitEthernet 0/0/24[Huawei-GigabitEthernet0/0/24]port link-type trunk [Huawei-GigabitEthernet0/0/24]port trunk allow-pass vlan 2 to 4[Huawei-GigabitEthernet0/0/24]quit[Huawei]quit&lt;Huawei&gt;save 交换机SW2配置12345678910111213141516171819202122232425262728293031323334&lt;Huawei&gt;sys[Huawei]vlan batch 2 4#配置端口类型并启用根据子网划分vlan功能[Huawei]interface GigabitEthernet 0/0/1[Huawei-GigabitEthernet0/0/1]port link-type hybrid [Huawei-GigabitEthernet0/0/1]port hybrid untagged vlan 2 to 4[Huawei-GigabitEthernet0/0/1]ip-subnet-vlan enable[Huawei-GigabitEthernet0/0/1]quit[Huawei]interface GigabitEthernet 0/0/2[Huawei-GigabitEthernet0/0/2]port link-type hybrid[Huawei-GigabitEthernet0/0/2]port hybrid untagged vlan 2 to 4[Huawei-GigabitEthernet0/0/2]ip-subnet-vlan enable[Huawei-GigabitEthernet0/0/2]quit[Huawei]interface GigabitEthernet 0/0/3[Huawei-GigabitEthernet0/0/3]port link-type hybrid[Huawei-GigabitEthernet0/0/3]port hybrid untagged vlan 2 to 4[Huawei-GigabitEthernet0/0/3]ip-subnet-vlan enable[Huawei-GigabitEthernet0/0/3]quit[Huawei]interface GigabitEthernet 0/0/24[Huawei-GigabitEthernet0/0/24]port link-type trunk [Huawei-GigabitEthernet0/0/24]port trunk allow-pass vlan 2 to 4[Huawei-GigabitEthernet0/0/24]quit# 配置根据子网划分vlan[Huawei]vlan 2[Huawei-vlan2]ip-subnet-vlan 2 ip 192.168.1.0 255.255.255.0[Huawei-vlan2]quit[Huawei]vlan 3[Huawei-vlan3]ip-subnet-vlan 3 ip 192.168.2.0 255.255.255.0[Huawei-vlan3]quit[Huawei]vlan 4[Huawei-vlan4]ip-subnet-vlan 4 ip 192.168.3.0 255.255.255.0[Huawei-vlan4]quit[Huawei]quit&lt;Huawei&gt;save 测试使用ip地址为192.168.1.1的PC测试ping地址为192.168.1.2的PC，能够ping通，测试通过 ensp拓扑下载百度网盘链接 链接：https://pan.baidu.com/s/1uTmnWrEhtDU2_nkFUjwyZQ提取码：5wv6]]></content>
      <categories>
        <category>网络基础</category>
      </categories>
      <tags>
        <tag>网络基础</tag>
        <tag>交换机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[华为交换机开启telnet远程配置]]></title>
    <url>%2F2020%2F05%2F30%2F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%2Fhw_remote_config%2F</url>
    <content type="text"><![CDATA[网络拓扑图 由于ensp上的PC不具有telnet客户端功能，所以此处使用Cloud桥接本机网卡，在本机上进行telnet测试 交换机SW配置1234567891011121314151617181920212223242526272829303132333435363738394041&lt;Huawei&gt;system-view# 配置vlan1的IP以及默认路由# 192.168.2.1为本机桥接网卡的IP,一般使用虚拟机的适配器进行桥接，不要使用以太网连接桥接[Huawei]interface vlanif1[Huawei-Vlanif1]ip address 192.168.2.254 24[Huawei]quit[Huawei]ip route-static 0.0.0.0 0.0.0.0 192.168.2.1# 定义允许同时建立的telnet会话数量0-4共5个# 进入用户界面视图[Huawei]user-interface vty 0 4# 启动终端服务[Huawei-ui-vty0-4]shell# 指定telnet为vty使用协议,[Huawei-ui-vty0-4]protocol inbond telnet###############口令鉴别方式和AAA鉴别方式二选一################################口令鉴别方式#################### 指定口令鉴别方式[Huawei-ui-vty0-4]authentication-mode password# 指定登录口令 cipher表示密文方式存储口令[Huawei-ui-vty0-4]set authentication password cipher 520123# 配置远程用户权限[Huawei-ui-vty0-4]user privilege level 15[Huawei-ui-vty0-4]quit################AAA鉴别方式#################### 指定AAA鉴别方式[Huawei-ui-vty0-4]authentication-mode aaa# 配置远程用户权限[Huawei-ui-vty0-4]user privilege level 15[Huawei-ui-vty0-4]quit# 进入aaa视图[Huawei]aaa# 建立一个用户名为huawei、密码为520123的授权用户[Huawei-aaa]local-user huawei password cipher 520123# 指定huawei用户为telnet用户类型[Huawei-aaa]local-user huawei service-type telnet[Huawei-aaa]quit 1234567# 配置连接PC的端口为vlan1(拓扑图中是连接cloud的端口)[Huawei]interface GigabitEthernet 0/0/1[Huawei-GigabitEthernet0/0/1]port link-type access [Huawei-GigabitEthernet0/0/1]port default vlan 1[Huawei-GigabitEthernet0/0/1]quit[Huawei]quit&lt;Huawei&gt;save Cloud配置 PC机上telnet登录验证 ensp拓扑下载百度网盘链接 链接：https://pan.baidu.com/s/1INqncPcvEYnGWaV6WjwoRQ提取码：9igf]]></content>
      <categories>
        <category>网络基础</category>
      </categories>
      <tags>
        <tag>网络基础</tag>
        <tag>交换机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 网络配置基础-IP和路由]]></title>
    <url>%2F2020%2F05%2F01%2FLinux%E5%9F%BA%E7%A1%80%2Fip-route-config%2F</url>
    <content type="text"><![CDATA[序言CentOS系统的网络管理有network和NetwokManager两种服务，建议关闭其中一种，目前笔者遇见过两个服务冲突时会出现网卡没法重启，提示：Failed to start LSB：Bring up/down networking错误 建议在生产服务器上关闭NetwokManager，而在家用、娱乐的系统上可以关闭network CentOS6默认的最小安装时只有network，没有NetwokManager，可以用以下命令检查是否安装了NetworkManager： 12345678910111213141516171819# 可以看到init3级别下，服务NetworkManager启动，而network关闭[root@Emma ~]# chkconfig --list | grep -i netwNetworkManager 0:off 1:off 2:on 3:on 4:on 5:on 6:offnetwork 0:off 1:off 2:off 3:off 4:off 5:off 6:off# 关闭NetworkManager服务[root@Emma ~]# service NetworkManager stop# 关闭NetworkManager开机启动[root@Emma ~]# chkconfig NetworkManager off# 开启network服务[root@Emma ~]# service network start# 关闭NetworkManager开机启动[root@Emma ~]# chkconfig network on# 可以使用以下命令（开启|停止|重启|查看）network服务[root@Emma ~]# /etc/init.d/network start|stop|reload|status# service控制network与以上相同效果，其实就是调用network命令[root@Emma ~]# service network start|stop|restart|status CentOS7最小安装时既有network，也有有NetwokManager；可以用以下命令关闭NetwokManager 12345678910# 将NetwokManager服务关闭[root@neil ~]# systemctl stop NetworkManager# 将NetworkManager 服务设置开机不启动[root@neil ~]# systemctl disable NetworkManagerRemoved symlink /etc/systemd/system/multi-user.target.wants/NetworkManager.service.Removed symlink /etc/systemd/system/dbus-org.freedesktop.nm-dispatcher.service.Removed symlink /etc/systemd/system/network-online.target.wants/NetworkManager-wait-online.service.# 查看是否开机开启[root@neil ~]# systemctl is-enabled NetworkManagerdisabled Centos6 下网络配置以下配置均是适用于network服务，关闭NetworkManager服务 静态IP配置以下仅列出常用配置 12345678910111213141516#添加或修改/etc/sysconfig/network-scripts/ifcfg-eth0[root@localhost ~]vi /etc/sysconfig/network-scripts/ifcfg-eth0DEVICE=eth1 #指出设备名称HWADDR=00:0C:29:D7:CE:D9 #Mac地址TYPE=Ethernet #网络类型UUID=8564ce31-d0bf-4d02-b455-36c9e69d91f7ONBOOT=yes #是否在系统启动时应用此配置NM_CONTROLLED=no #修改后无需要重启网卡立即生效，依赖于NetworkManager，不配置BOOTPROTO=static #启动类型 static，静态IPIPADDR=192.168.0.202 #IP地址NETMASK=255.255.255.0 #子网掩码NETWORK=192.168.0.0 #网络地址，可不配置，系统会自动计算BROADCAST=192.168.0.255 #广播地址，可不配置，系统会自动计算GATEWAY=192.168.0.1 #默认网关，可不配置，但生产环境推荐配置DNS=114.114.114.114 #DNS地址MTU=1452 #设置MTU值 生产环境常用最小配置如下： 123456789DEVICE=eth1 #指出设备名称HWADDR=00:0C:29:D7:CE:D9 #Mac地址TYPE=Ethernet #网络类型UUID=8564ce31-d0bf-4d02-b455-36c9e69d91f7ONBOOT=yes #是否在系统启动时应用此配置BOOTPROTO=static #启动类型 static，静态IPIPADDR=192.168.0.202 #IP地址NETMASK=255.255.255.0 #子网掩码GATEWAY=192.168.0.1 #默认网关，生产环境推荐配置 DHCP（待验证,生产环境不常用）1234567[root@localhost ~]# vi /etc/sysconfig/network-scripts/ifcfg-eth0DEVICE=eth1 #指出设备名称HWADDR=00:0C:29:D7:CE:D9 #Mac地址TYPE=Ethernet #网络类型UUID=8564ce31-d0bf-4d02-b455-36c9e69d91f7ONBOOT=yes #是否在系统启动时应用此配置BOOTPROTO=dhcp #启动类型 dhcp 单网卡配置多个静态IP方法一123456789101112131415161718[root@Emma ~]# more /etc/sysconfig/network-scripts/ifcfg-eth1 DEVICE=eth1HWADDR=00:0C:29:D7:CE:D9TYPE=EthernetUUID=8564ce31-d0bf-4d02-b455-36c9e69d91f7ONBOOT=yesNM_CONTROLLED=yesBOOTPROTO=staticIPADDR=192.168.0.202NETMASK=255.255.255.0GATEWAY=192.168.0.1MTU=1452DNS=114.114.114.114# 添加IP，设置多个IP同理增加 IPADDR_2 | IPADDR_3IPADDR1=192.168.0.242NETMASK1=255.255.255.0GATEWAY1=192.168.0.1 方法二1234567891011121314151617181920212223242526272829303132333435# 复制一个配置文件ifcfg-eth1:0[root@Emma ~]# cp /etc/sysconfig/network-scripts/ifcfg-eth1 /etc/sysconfig/network-scripts/ifcfg-eth1:0# 修改DEVICE和IP信息，保存[root@Emma ~]# vi /etc/sysconfig/network-scripts/ifcfg-eth1:0DEVICE=eth1:0 #修改为与配置文件对应的eth1:0 HWADDR=00:0C:29:D7:CE:D9TYPE=EthernetUUID=8564ce31-d0bf-4d02-b455-36c9e69d91f7ONBOOT=yesNM_CONTROLLED=yesBOOTPROTO=staticIPADDR=192.168.0.252NETMASK=255.255.255.0#GATEWAY=192.168.0.2 #生产环境尽量不要配置多个网关，会导致各种问题MTU=1452DNS=114.114.114.114# 重启network[root@Emma ~]# service network restart# 查看配置eth1:0已生效[root@Emma ~]# ifconfig -aeth1 Link encap:Ethernet HWaddr 00:0C:29:D7:CE:D9 inet addr:192.168.0.202 Bcast:192.168.0.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fed7:ced9/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1452 Metric:1 RX packets:56189 errors:0 dropped:0 overruns:0 frame:0 TX packets:9876 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:61006316 (58.1 MiB) TX bytes:1041327 (1016.9 KiB)eth1:0 Link encap:Ethernet HWaddr 00:0C:29:D7:CE:D9 inet addr:192.168.0.252 Bcast:192.168.0.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1452 Metric:1 静态路由配置(永久)目前路由如下： 123456[root@Emma network-scripts]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.1.0 0.0.0.0 255.255.255.0 U 0 0 0 eth2192.168.0.0 0.0.0.0 255.255.255.0 U 0 0 0 eth10.0.0.0 192.168.1.1 0.0.0.0 UG 0 0 0 eth2 方法一在/etc/sysconfig/network-scripts创建route-[interface]，格式为： 12$DST_NET via $GW_IP$DST_HOST via $GW_IP 123456789101112131415# 以eth1路由为例；创建route-eth1[root@Emma ~]# vi /etc/sysconfig/network-scripts/route-eth1192.168.2.0/24 via 192.168.0.1 # 到网段的路由192.168.3.1 via 192.168.0.1 # 到主机的路由# 重启network，查看路由表[root@Emma ~]# service network restart[root@Emma ~]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.3.1 192.168.0.1 255.255.255.255 UGH 0 0 0 eth1192.168.2.0 192.168.0.1 255.255.255.0 UG 0 0 0 eth1192.168.1.0 0.0.0.0 255.255.255.0 U 0 0 0 eth2192.168.0.0 0.0.0.0 255.255.255.0 U 0 0 0 eth10.0.0.0 192.168.1.1 0.0.0.0 UG 0 0 0 eth2 方法二在/etc/sysconfig/创建static-route，格式为： 12any net $DST_NET gw $GW_IPany host $DST_HOST gw $GW_IP 12345678910111213141516171819# [root@Emma ~]# vi /etc/sysconfig/static-routes any net 192.168.4.0/24 gw 192.168.1.254any net 192.168.5.0 netmask 255.255.255.0 gw 192.168.1.254any host 192.168.6.1 gw 192.168.0.254# 重启network，查看路由表[root@Emma ~]# service network restart[root@Emma ~]# route -n[root@Emma ~]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.3.1 192.168.0.1 255.255.255.255 UGH 0 0 0 eth1192.168.6.1 192.168.0.254 255.255.255.255 UGH 0 0 0 eth1192.168.5.0 192.168.1.254 255.255.255.0 UG 0 0 0 eth2192.168.4.0 192.168.1.254 255.255.255.0 UG 0 0 0 eth2192.168.2.0 192.168.0.1 255.255.255.0 UG 0 0 0 eth1169.254.0.0 0.0.0.0 255.255.0.0 U 1002 0 0 eth1169.254.0.0 0.0.0.0 255.255.0.0 U 1003 0 0 eth20.0.0.0 192.168.1.1 0.0.0.0 UG 0 0 0 eth2 静态路由配置(临时,不常用)123456789101112# 使用route 命令添加的路由，机器重启或者网卡重启后路由就失效了，方法：# 添加到主机的路由[root@Emma ~]# route add -host 192.168.100.0 dev eth1[root@Emma ~]# route add –host 192.168.100.10 gw 192.168.0.1# 添加到网络的路由[root@Emma ~]# route add –net 192.168.100.0 netmask 255.255.255.0 eth1[root@Emma ~]# route add –net 192.168.100.0 netmask 255.255.255.0 gw 192.168.0.1[root@Emma ~]# route add –net 192.168.100.0/24 eth1# 添加默认网关[root@Emma ~]# route add default gw 192.168.0.1# 删除路由[root@Emma ~]# route del –host 192.168.100.10 dev eth0 Centos7 下网络配置以下配置均是适用于network服务，关闭NetworkManager服务 静态IP配置123456789101112131415161718192021#添加或修改/etc/sysconfig/network-scripts/ifcfg-eth0[root@neil ~]# vi /etc/sysconfig/network-scripts/ifcfg-ens33 TYPE=Ethernet # 网络类型:以太网PROXY_METHOD=none # 代理方式:关闭状态BROWSER_ONLY=no # 只是浏览器:否BOOTPROTO=static # 网卡的引导协议:static,使用静态IPDEFROUTE=yes # 默认路由:是IPV4_FAILURE_FATAL=no # 是不开启IPV4致命错误检测:否IPV6INIT=yes # IPV6是否自动初始化: 是IPV6_AUTOCONF=yes # IPV6是否自动配置:是IPV6_DEFROUTE=yes # IPV6是否可以为默认路由:是IPV6_FAILURE_FATAL=no # 是否开启IPV6致命错误检测:否IPV6_ADDR_GEN_MODE=stable-privacy # IPV6地址生成模型:stable-privacyNAME=ens33 # 网卡物理设备名称UUID=1ac737f7-a9a7-4312-9be9-7677688d5345 # 通用唯一识别码DEVICE=ens33 # 网卡物理设备名称，必须和 `NAME` 值一样ONBOOT=yes # 是否开机启动IPADDR=192.168.0.212 # IP地址NETMASK=255.255.255.0 # 配置子网掩码GATEWAY=192.168.0.1 # 网关DNS1=114.114.114.114 # DNS 单网卡配置多个静态IP(与CentOS6相同)方法一1234567891011121314151617181920212223TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=staticDEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=ens33UUID=1ac737f7-a9a7-4312-9be9-7677688d5345DEVICE=ens33ONBOOT=yesIPADDR=192.168.0.212NETMASK=255.255.255.0GATEWAY=192.168.0.1DNS1=114.114.114.114# 添加IP地址，设置多个IP同理增加 IPADDR_2 | IPADDR_3IPADDR1=192.168.1.212NETMASK1=255.255.255.0GATEWAY1=192.168.1.1 方法二1234567891011121314151617181920212223242526# 复制一个配置文件ifcfg-ens33:0[root@neil ~]# cp /etc/sysconfig/network-scripts/ifcfg-ens33 /etc/sysconfig/network-scripts/ifcfg-ens33:0# 修改NAME、DEVICE和IP信息[root@neil ~]# vi /etc/sysconfig/network-scripts/ifcfg-ens33:0TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=staticDEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=ens33:0UUID=1ac737f7-a9a7-4312-9be9-7677688d5345DEVICE=ens33:0ONBOOT=yesIPADDR=192.168.0.253NETMASK=255.255.255.0GATEWAY=192.168.0.1DNS1=114.114.114.114# 重启network后生效 [root@neil ~]# systemctl restart network 静态路由配置(永久，与CentOS6相同)12345[root@neil ~]# ip route showdefault via 192.168.0.1 dev ens33 169.254.0.0/16 dev ens33 scope link metric 1002 192.168.0.0/24 dev ens33 proto kernel scope link src 192.168.0.212 192.168.1.0/24 dev ens33 proto kernel scope link src 192.168.1.212 在/etc/sysconfig/network-scripts创建route-[interface]，格式为： 12$DST_NET via $GW_IP dev $DEVICE$DST_HOST via $GW_IP dev $DEVICE 1234567891011121314# 以ens33路由为例；创建route-ens33[root@neil ~]# vi /etc/sysconfig/network-scripts/route-ens335.2.20.0/24 via 192.168.0.1 dev ens335.2.21.145 via 192.168.0.253# 重启network，验证[root@neil ~]# systemctl restart network[root@neil ~]# ip route showdefault via 192.168.0.1 dev ens33 5.2.20.0/24 via 192.168.0.1 dev ens33 5.2.21.145 via 192.168.0.253 dev ens33 169.254.0.0/16 dev ens33 scope link metric 1002 192.168.0.0/24 dev ens33 proto kernel scope link src 192.168.0.212 192.168.1.0/24 dev ens33 proto kernel scope link src 192.168.1.212 静态路由配置(临时,不常用)1234567891011121314151617181920212223242526添加路由：ip route add 192.168.2.0/24 via 192.168.150.253 dev ens33删除路由：ip route del 192.168.2.0/24 via 192.168.150.253 dev ens33查看指定网段的路由ip route list 192.168.2.0/24追加路由ip route append 192.168.2.0/24 via 192.168.1.12 #追加一个指定网络的路由，为了平滑切换网关使用修改路由ip route change 192.168.2.0/24 via 192.168.1.11ip route replace 192.168.2.0/24 via 192.168.1.111清空指定网络的路由ip route flush 192.168.2.0/24 #这个是清理所有192.168.2.0/24相关的所有路由，有时候设置错网关存在多条记录，就需要一次性清空相关路由再进行添加添加默认路由ip route add default via 192.168.1.1指定路由metircip route add 192.168.2.0/24 via 192.168.1.15 metric 10]]></content>
      <categories>
        <category>Linux基础</category>
      </categories>
      <tags>
        <tag>计算机基础</tag>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IP网络存储iSCSI概念与CentOS 6实现]]></title>
    <url>%2F2020%2F01%2F08%2F%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80%2FCentOS6-iSCSI-base%2F</url>
    <content type="text"><![CDATA[概念太长不看：iSCSI initiator就是iscsi的客户端，iSCSI target就是iscsi的server，lun在iscsi里lun就代表一个可以通过iscsi访问的存储设备 SCSI介绍SCSl是小型计算机系统接口（Small Computer System Interface）的简称，SCSI作为输入/输出接口，主要用于硬盘、光盘、磁带机、扫描仪、打印机等设备 SAN介绍存储区域网络（Storage Area Network）简称SAN，它是一种通过光纤交换机、光纤路由器、光纤集线器等设备将磁盘阵列、磁带等存储设备与相关服务器连接起来的高速专用子网SAN由3个部分组成，分别是连接设备（如路由器、光纤交换机和Hub）、接口（如SCSI、FC）、通信协议（如IP和SCSI）。这3个部分再加上存储设备和服务器就构成了一个SAN系统。SAN捉供了一个灵活的、高性能的和高扩展性的存储网络环境，它可以更加有效地传输海量的数据块 iSCSl即internet SCSI，是IETF制订的一项标准，用于将SCSI数据块映射为以太网数据包。该技术将存储行业广泛应用的SCSI接口技术与IP网络技术相结合，可以在IP网络上构建SAN。简单地说，iSCSI就是在IP网络上运行SCSI协议的一种网络存储技术 iSCSI InitiatoriSCSI Initiator是一个安装在计算机上的软件或硬件设备，它负责与iSCSI存储设备进行通信 软件方式，即iSCSI Initiator软件。在iSCSI服务器上安装lnitiator后，Initiator软件可以将以太网卡上虚拟iSCSl卡，进而接受和发送iSCSI数据报文，从而实现主机和iSCSI存储设备之间的iSCSI协议和TCP/IP协议传输功能。这种方式只需以太网卡和以太网交换机，无需其他设备，因此成本是最低的。但是iSCSI报文和TCP/IP报文转换需要消耗iSCSI服务器的一部分CPU资源，只有在低I/O和低带竞性能要求的应用环境中才能使用这种方式硬件iSCSI HBA（Host Bus Adapter）卡方式，即iSCSI Initiator硬件。这种方式需要先购买iSCSI的HBA卡，然后将其安装在iSCSI服务器上，从而实现iSCSI服务器与交换机之间、iSCSI服务器与存储设备之间的高效数据传输。与第一种方式相比，硬件iSCSIHBA卡方式不需要消耗iSCSI服务器的CPU资源，同时硬件设备是专用的，所以基于硬件的iSCSI Initiator可以提供更好的数据传输和存储性能。但是，iSCSI HBA卡的价格比较昂贵，因此用户要在性能和成本之间进行权衡 iSCSI Target一个可以用于存储数据的iSCSI磁盘阵列或者具有iSCSI功能的设备都可以被称为”iSCSI Target”，大多数操作系统都可以利用一些软件将系统转变为一个“iSCSI Target” 利用iSCSI Target软件，可以将服务器的存储空间分配给客户机使用，客户机可以像使用本地硬盘一样使用iSCSI磁盘，包括对其进行分区、格式化及读写等。而且每个客户端都可以向iSCSI磁盘写数据，互不干扰，并且不会破坏存储到服务器中的数据。同时，iSCSI Target软件对用户权限控制非常灵活，支持配置文件。对于iSCSI Target，应该为每个独立阵列中的两个独立端口配备交换机，最后将交换机连接起来，采用这种配置方式，即使两个交换机中的一个出现了故障，整个iSCSI存储系统仍然能够正常工作，这保证了存储系统的不间断运行 CentOS下的操作环境： 2台CentOS-6.10-x86_64，服务端IP：192.168.0.204，客户端IP：192.168.0.202 需要用到的软件为： 服务端：scsi-target-utils 客户端：iscsi-initiator-utils 服务端查看是否安装软件 1[root@Neil ~]# yum list installed | grep 'scsi-target-utils.x86_64' 安装软件 123456789#查找可安装的与scsi相关的软件[root@Neil ~]# yum list | grep 'scsi'iscsi-initiator-utils.x86_64 6.2.0.873-27.el6_9 base iscsi-initiator-utils-devel.x86_64 6.2.0.873-27.el6_9 base lsscsi.x86_64 0.23-3.el6 base scsi-target-utils.x86_64 1.0.24-18.el6 base #安装scsi-target-utils[root@Neil ~]# yum -y install scsi-target-utils.x86_64 划分要共享存储区域 1234567891011#此处将使用文章《CentOS 6软RAID配置》中已划分好的/dev/md0#查看/dev/md0信息[root@Neil ~]# fdisk -l | grep /dev/md0 -A10Disk /dev/md0: 3218 MB, 3218079744 bytes2 heads, 4 sectors/track, 785664 cylindersUnits = cylinders of 8 * 512 = 4096 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 262144 bytes / 786432 bytesDisk identifier: 0xfcac6c58 Device Boot Start End Blocks Id System 配置共享存储 1234567#修改/etc/tgt/targets.conf 文件[root@Neil ~]# vim /etc/tgt/targets.conf#增加以下配置&lt;target iqn.2020-01.com.example:server.target204&gt; backing-store /dev/md0 initiator-address 192.168.0.202&lt;/target&gt; 注： iqn.2020-01.com.example:server.target204 #共享名称 backing-store /dev/md0 #共享卷名及路径 initiator-address 192.168.0.202 #允许访问的地址 启动服务 12345678910111213141516171819202122232425262728293031323334353637383940414243#重启服务[root@Neil ~]# service tgtd restart#配置开机启动[root@Neil ~]# chkconfig tgtd on#查看允许状态 端口3260[root@Neil ~]# netstat -anp | grep '3260'tcp 0 0 0.0.0.0:3260 0.0.0.0:* LISTEN 1445/tgtd tcp 0 0 :::3260 :::* LISTEN 1445/tgtd#查看target状态[root@Neil ~]# tgt-admin -sTarget 1: iqn.2020-01.com.example:server.target204 System information: Driver: iscsi State: ready I_T nexus information: LUN information: LUN: 0 Type: controller SCSI ID: IET 00010000 SCSI SN: beaf10 Size: 0 MB, Block size: 1 Online: Yes Removable media: No Prevent removal: No Readonly: No Backing store type: null Backing store path: None Backing store flags: LUN: 1 Type: disk SCSI ID: IET 00010001 SCSI SN: beaf11 Size: 3218 MB, Block size: 512 Online: Yes Removable media: No Prevent removal: No Readonly: No Backing store type: rdwr Backing store path: /dev/md0 Backing store flags: Account information: ACL information: 192.168.0.202 客户端安装软件 1[root@Neil ~]# yum -y install iscsi-initiator-utils.x86_64 iscsiadm命令 iscsiadm是基于命令行的iscsi管理工具，提供了对iSCSI节点、会话、连接以及发现记录的操作。iscsiadm的使用说明可以运行man iscsiadm或iscsiadm –help 12345678910参数： -m &#123;discovery|node|session|iface&#125; #&#123;发现某服务器是否有target输出，以及输出了哪些target|管理跟某target的关联关系|会话管理 |接口管理&#125; -d &#123;0-8&#125; #打印调试信息，有0到8这9个等级 -t #这里可以使用的类型为sendtargets(可简写为st)、slp、fw和 isns，此选项仅用于discovery模式，且目前仅支持st、fw和isns；其中st表示允许每个iSCSItarget发送一个可用target列表给initiator； -T #用于指定target的名字 -p #指定target服务的IP和端口, -p 192.168.1.55:3260 -o #指定针对discoverydb数据库的操作，其仅能为new、delete、update、show和nonpersistent其中之一 -I #指定执行操作的iSCSI接口，这些接口定义在/var/lib/iscsi/ifaces中 -l #登录节点 -u #登出节点(服务器) 发现target 1234#端口为默认的3260可以不写[root@Neil ~]# iscsiadm -m discovery -t sendtargets -p 192.168.0.204Starting iscsid: [ OK ]192.168.0.204:3260,1 iqn.2020-01.com.example:server.target204 登录 123456[root@Neil ~]# iscsiadm -m node –T iqn.2020-01.com.example:server.target204 -p 192.168.0.204 -lLogging in to [iface: default, target: iqn.2020-01.com.example:server.target204, portal: 192.168.0.204,3260] (multiple)Login to [iface: default, target: iqn.2020-01.com.example:server.target204, portal: 192.168.0.204,3260] successful.#如果要系统启动时自动登入[root@Neil ~]# iscsiadm -m node –T iqn.2020-01.com.example:server.target204 -p 192.168.0.204 --op update -n node.startup -v automatic 分区 1234567891011121314151617181920212223242526272829303132#使用fdisk -l查看可以发现多出一块磁盘，我这边是/dev/sdb,对其分区[root@Neil ~]# fdisk /dev/sdb#####这里会显示一些警告信息Command (m for help): n Command action e extended p primary partition (1-4)pPartition number (1-4): 1First cylinder (1-1024, default 1): Using default value 1Last cylinder, +cylinders or +size&#123;K,M,G&#125; (1-1024, default 1024): Using default value 1024Command (m for help): wThe partition table has been altered!Calling ioctl() to re-read partition table.Syncing disks.##查看分区情况[root@Neil ~]# fdisk -l |grep -A10 '/dev/sdb' Disk /dev/sdb: 3218 MB, 3218079744 bytes99 heads, 62 sectors/track, 1024 cylindersUnits = cylinders of 6138 * 512 = 3142656 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0xfcac6c58 Device Boot Start End Blocks Id System/dev/sdb1 1 1024 3142625 83 Linux 挂载 1234567891011121314#创建文件系统[root@Neil ~]# mkfs.ext4 /dev/sdb#新建挂载点[root@Neil ~]# mkdir /root/iscsiTest#挂载[root@Neil ~]# mount /dev/sdb /root/iscsiTest#开机自动加载[root@Neil ~]# blkid /dev/sdb/dev/sdb: UUID="89023214-5338-4fa5-9ba0-9b80b26d8f3f" TYPE="ext4" [root@Neil ~]# vi /etc/fstab #添加下面这一行UUID=89023214-5338-4fa5-9ba0-9b80b26d8f3f /root/iscsiTest ext4 defaults 0 0 取消挂载和登出 12345678910[root@Neil ~]# umount /dev/sdb[root@Neil ~]# vi /etc/fstab #删除下面这一行UUID=89023214-5338-4fa5-9ba0-9b80b26d8f3f /root/iscsiTest ext4 defaults 0 0#取消开机自动登录[root@Neil ~]# iscsiadm -m node –T iqn.2020-01.com.example:server.target204 -p 192.168.0.204 --op update -n node.startup -v manual#登出[root@Neil ~]# iscsiadm -m node –T iqn.2020-01.com.example:server.target204 -p 192.168.0.204 –u]]></content>
      <categories>
        <category>存储基础</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 6软RAID配置]]></title>
    <url>%2F2020%2F01%2F01%2F%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80%2FCentOS6-RAID%2F</url>
    <content type="text"><![CDATA[Linux内核中有一个md(multiple devices)模块在底层管理RAID设备，它会在应用层给我们提供一个应用程序的工具mdadm（multiple devices admin），mdadm 是Linux下的一款标准的软件RAID 管理工具。其支持将任何块设备做成RAID，但需要注意的是为同一块磁盘的不同分区做RAID没有任何意义 mdadm命令的模式 模式 进入方法（参数） 创建模式（常用） -C 管理模式 -add 或者 –del 监控模式 -F 增长模式（常用） -G 装配模式 -A 实验环境 CentOS-6.10-x86_64，以创建raid5为例，使用4块硬盘，其中3块做raid5，1块热备 系统硬盘情况如下： 123456789101112[root@Neil ~]# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsr0 11:0 1 3.7G 0 rom sda 8:0 0 40G 0 disk ├─sda1 8:1 0 500M 0 part /boot└─sda2 8:2 0 39.5G 0 part ├─vg_neil-lv_root (dm-0) 253:0 0 35.6G 0 lvm / └─vg_neil-lv_swap (dm-1) 253:1 0 3.9G 0 lvm [SWAP]sdb 8:16 0 1G 0 disk sdc 8:32 0 1G 0 disk sdd 8:48 0 1G 0 disk sde 8:64 0 1G 0 disk 其中sdb，sdc，sdd，sde为本次实验所使用的的硬盘，尚未分区 硬盘分区分区使用fdisk或者gdisk对硬盘进行分区，以/dev/sdb为例 1234567891011121314[root@Neil ~]# fdisk /dev/sdb#####此处会显示一些提示信息#############可以使用m获取帮助，n为新建分区，根据交互创建分区即可，直接划成一个分区####Command (m for help): nCommand action e extended p primary partition (1-4)pPartition number (1-4): 1First cylinder (1-130, default 1): Using default value 1Last cylinder, +cylinders or +size&#123;K,M,G&#125; (1-130, default 130): Using default value 130 修改分区类型默认新建分区的类型是Linux，代号83，我们需要将其修改为raid 类型。输入”t” ，然后输入”L” 列出所有的文件格式，这里我们选择fd Linux raid auto, 输入fd，分区格式已经变更为Linux raid autodetect 1234567891011Command (m for help): tSelected partition 1Hex code (type L to list codes): L########此处显示支持的分区类型与id对应表，常用以下三种###############83 Linux8e Linux LVMfd Linux raid autoHex code (type L to list codes): fdChanged system type of partition 1 to fd (Linux raid autodetect) 保存分区12345Command (m for help): wThe partition table has been altered!Calling ioctl() to re-read partition table.Syncing disks. 对其他三块硬盘做同样操作，检查四个硬盘是否都分区完成 12345[root@Neil ~]# fdisk -l | grep -v 'Disk' | grep '/dev/sd[bcde]'/dev/sdb1 1 130 1044193+ fd Linux raid autodetect/dev/sdc1 1 130 1044193+ fd Linux raid autodetect/dev/sdd1 1 130 1044193+ fd Linux raid autodetect/dev/sde1 1 130 1044193+ fd Linux raid autodetect 配置RAID创建RAID512345[root@Neil ~]# mdadm -C /dev/md0 -a yes -l 5 -n 3 /dev/sd&#123;b,c,d,e&#125; -x 1 -c 256K########此处显示警告信息，已有分区是否继续创建raid#######Continue creating array? ymdadm: Defaulting to version 1.2 metadatamdadm: array /dev/md0 started. 参数说明： 参数 同义 含义 -C /dev/md0 --create 创建阵列，阵列设备/dev/md0 `-a {yes no}` --auto -l --level 阵列模式，常用阵列模式有 linear, raid0, raid1, raid4, raid5, raid6, raid10等 -n --raid-devices= 阵列中活动磁盘的数目，该数目加上备用磁盘的数目应该等于阵列中总的磁盘数目 -x --spare-devices= 指定热备盘的块数 -c 指明chunk块大小为256K 查看一下RAID状态使用mdadm -D /dev/md0查看详细信息，或者cat /proc/mdstat查看简略信息 12345678910111213141516171819202122232425262728293031[root@Neil ~]# mdadm -D /dev/md0/dev/md0: Version : 1.2 Creation Time : Sat Aug 9 12:49:57 2008 Raid Level : raid5 Array Size : 2095104 (2046.00 MiB 2145.39 MB) Used Dev Size : 1047552 (1023.00 MiB 1072.69 MB) Raid Devices : 3 Total Devices : 4 Persistence : Superblock is persistent Update Time : Sat Aug 9 12:50:03 2008 State : clean Active Devices : 3Working Devices : 4 Failed Devices : 0 Spare Devices : 1 Layout : left-symmetric Chunk Size : 256K Name : Neil.Emma:0 (local to host Neil.Emma) UUID : ddf710c0:08608d78:86a800e6:3eeb33f3 Events : 18 Number Major Minor RaidDevice State 0 8 16 0 active sync /dev/sdb 1 8 32 1 active sync /dev/sdc 4 8 48 2 active sync /dev/sdd 3 8 64 - spare /dev/sde 123456[root@Neil ~]# cat /proc/mdstatPersonalities : [raid6] [raid5] [raid4] md0 : active raid5 sdd[4] sde[3](S) sdc[1] sdb[0] 2095104 blocks super 1.2 level 5, 256k chunk, algorithm 2 [3/3] [UUU] unused devices: &lt;none&gt; 生成配置文件该配置文件的主要作用是系统启动的时候能够自动加载软RAID，同时也方便日后管理。但不是必须的，推荐对该文件进行配置。 12345[root@Neil ~]# mdadm -Ds /dev/md0 &gt;&gt; /etc/mdadm.conf[root@Neil ~]# cat /etc/mdadm.conf ARRAY /dev/md0 metadata=1.2 name=Neil.Emma:0 UUID=a07d0b5c:14ee15e3:b787794c:f2fe59e2ARRAY /dev/md0 metadata=1.2 spares=1 name=Neil.Emma:0 UUID=ddf710c0:08608d78:86a800e6:3eeb33f3 挂载创建文件系统1[root@Neil ~]# mkfs.ext4 /dev/md0 -L "RAID5-MD0" 建立挂载点并挂载123456789[root@Neil ~]# mkdir /raid5[root@Neil ~]# mount /dev/md0 /raid5[root@Neil ~]# df -hFilesystem Size Used Avail Use% Mounted on/dev/mapper/vg_neil-lv_root 35G 826M 33G 3% /tmpfs 931M 0 931M 0% /dev/shm/dev/sda1 477M 39M 413M 9% /boot/dev/md0 2.0G 3.0M 1.9G 1% /raid5 开机自动挂载将/dev/md0写入/etc/fstab 1234567891011121314151617[root@Neil ~]# cat /etc/fstab ## /etc/fstab# Created by anaconda on Sat Dec 7 03:32:26 2019## Accessible filesystems, by reference, are maintained under '/dev/disk'# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#/dev/mapper/vg_neil-lv_root / ext4 defaults 1 1UUID=169f024b-957c-4d4e-81a9-bb5cb94c1992 /boot ext4 defaults 1 2/dev/mapper/vg_neil-lv_swap swap swap defaults 0 0tmpfs /dev/shm tmpfs defaults 0 0devpts /dev/pts devpts gid=5,mode=620 0 0sysfs /sys sysfs defaults 0 0proc /proc proc defaults 0 0/dev/md0 /raid5 ext4 defaults 0 0 其他操作向RAID添加一个新的硬盘12[root@Neil ~]# mdadm -G /dev/md0 -n 4 -a /dev/sdfmdadm: added /dev/sdf 参数说明： 参数 同义 含义 -G --grow 改变阵型大小或形态 -n --raid-devices= 阵列中活动磁盘的数目 -a --add 添加设备到阵列 查看raid状态 123456[root@Neil ~]# cat /proc/mdstatPersonalities : [raid6] [raid5] [raid4] md0 : active raid5 sdf[5] sdc[1] sdb[0] sde[3](S) sdd[4] 3142656 blocks super 1.2 level 5, 256k chunk, algorithm 2 [4/4] [U unused devices: &lt;none&gt; 发现磁盘空间没有增加 123[root@Neil ~]# df -h /dev/md0Filesystem Size Used Avail Use% Mounted on/dev/md0 2.0G 3.0M 1.9G 1% /raid5 使用命令进行空间同步，ext文件系统 12345678910[root@Neil ~]# resize2fs /dev/md0resize2fs 1.41.12 (17-May-2010)Filesystem at /dev/md0 is mounted on /raid5; on-line resizing requiredold desc_blocks = 1, new_desc_blocks = 1Performing an on-line resize of /dev/md0 to 785664 (4k) blocks.The filesystem on /dev/md0 is now 785664 blocks long.[root@Neil ~]# df -h /dev/md0Filesystem Size Used Avail Use% Mounted on/dev/md0 3.0G 3.0M 2.8G 1% /raid5 移除RAID成员磁盘移除RAID成员磁盘，必须先将想要移除的磁盘标记为损坏，否则报错 123456789101112131415##未标记为损坏，报错[root@Neil ~]# mdadm /dev/md0 -r /dev/sddmdadm: hot remove failed for /dev/sdd: Device or resource busy##标记为损坏，正常移除[root@Neil ~]# mdadm /dev/md0 -f /dev/sddmdadm: set /dev/sdd faulty in /dev/md0[root@Neil ~]# mdadm /dev/md0 -r /dev/sddmdadm: hot removed /dev/sdd from /dev/md0##此时热备盘sdf已经启用[root@Neil ~]# cat /proc/mdstat Personalities : [raid6] [raid5] [raid4] md0 : active raid5 sdf[5] sdc[1] sdb[0] sde[3] 3142656 blocks super 1.2 level 5, 256k chunk, algorithm 2 [4/4] [UUUU] 参数说明： 参数 含义 -r 移除设备 -f 将设备状态定为故障 删除磁盘上的对应RAID信息,当退出的磁盘不再参与RAID阵列时，可以将此RAID信息删除。 1[root@Neil ~]# mdadm --zero-superblock /dev/sdd 将已清除raid信息的磁盘重新添加至此RAID（相当于新硬盘加入RAID），这样就会重建分区数据了，此时sdd为热备盘 123456[root@Neil ~]# mdadm /dev/md0 -a /dev/sddmdadm: added /dev/sdd[root@Neil ~]# cat /proc/mdstat Personalities : [raid6] [raid5] [raid4] md0 : active raid5 sdd[4](S) sdf[5] sdc[1] sdb[0] sde[3] 3142656 blocks super 1.2 level 5, 256k chunk, algorithm 2 [4/4] [UUUU] 停止并移除阵列 12[root@Neil ~]# mdadm -S /dev/md0[root@Neil ~]# mdadm -r /dev/md0]]></content>
      <categories>
        <category>存储基础</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大华研发技术支持笔试回顾]]></title>
    <url>%2F2019%2F12%2F25%2F%E5%AE%89%E9%98%B2%E5%9F%BA%E7%A1%80%2Fdahua-interview-2019-12-25%2F</url>
    <content type="text"><![CDATA[笔试分为三部分：网络常见问题处理；SQL基础；操作系统基础 都是简答题，网络和Linux开放性比较强，应该主要看答题逻辑；操作系统基础以Linux命令居多，没想到会笔试这样的内容，之前命令都是各种补全或者help，没有刻意去记，吃大亏了，以下是部分题目 网络PC机A可以ping通PC机B的IP，但PC机B不能ping通PC机A的IP，如何排查问题?目前能想到的就三个原因： 防火墙拦截了ICMP报文 取消您两台电脑上的防火墙设置（实际项目上该情况最多） APR病毒 APR病毒导致PC机A ping 的B不一定是真正的B，PC机B ping 的A也不一定是真正的A；通过arp -a 与ipconfig /all 来判断A确实是A，B确实是B 网络波动 判断网络里是否有大量的广播包在影响网络通信 最后尝试：PC机B tracert PC机IP，判断哪里出了问题 画出某个网络拓扑图（家庭，学校，某个项目的都行）这个网上找吧。。。 SQL前面都是基本的增删改查，较简单，最后一题如下： mysql备份还原的方式有哪些？命令方式： 备份： mysqldump备份单个数据库： 1mysqldump -u user -h host -p password dbname&gt;filename.sql mysqldump备份数据库中的指定表 1mysqldump -u user -h host -p password dbname[tbname,[tbname…]]&gt;filename.sql mysqldump备份多个数据库 1mysqldump -u user -h host -p password --databases[dbname,[dbname…]]&gt;filename.sql 备份系统中所有的数据库 1mysqldump -u user -h host -p password --all-databases&gt;filename.sql 还原： 1mysql -u username -p [dbname] &lt; filename.sql SQLyog 工具 可以用sqlyog等工具备份还原 操作系统Windows系统和Linux系统查看端口是否被占用用什么命令？Windows： 1234#查看端口被占用情况netstat -aon|findstr "80"#查看相关进程tasklist|findstr "80" Linux： 123netstat -nlp | grep 8080#或者lsof -i:8080 Linux疑似中毒，如何排查，写出命令？ top查看什么进程占用了资源 用lsof -p &lt;PID&gt;,查看疑似病毒进程 w查看当前都有谁在登录 history回顾命令历史 ps检查所有的系统进程 netstat查看异常的网络连接 cat /etc/rc.local查看是否有异常内容 tcpdump抓包查看是否有报文发送到异常IP 暂时想到就这些了。。。]]></content>
      <categories>
        <category>安防基础</category>
      </categories>
      <tags>
        <tag>安防基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GB/T28181协议业务流程基础]]></title>
    <url>%2F2019%2F12%2F12%2F%E5%AE%89%E9%98%B2%E5%9F%BA%E7%A1%80%2FGB28181-base%2F</url>
    <content type="text"><![CDATA[国标介绍GB/T28181规定了公共安全视频监控联网系统）的互联结构，传输、交换、控制的基本要求和安全性要求，以及控制、传输流程和协议接口等技术要求,适用于公共安全视频监控联网系统的方案设计、系统检测、验收以及与之相关的设备研发、生产等 编码规则：国标编码规则分为编码规则A和编码规则B。除特殊地区外，大部分地区采用的均是编码规则A，以下主要介绍编码规则A 编码规则A由中心编码（8位）、行业编码（2位）、类型编码（3位）和序号（7位）四个码段共20位十进制数字字符构成，即系统编码 =中心编码 + 行业编码 + 类型编码 + 序号 码段 码位 含义 取值说明 中心编码 1、2 省级编号 由监控中心所在地的行政区划代码确定， 符合GB/T 2260-2007的要求 3、4 市级编号 5、6 区级编号 7、8 基层接入单位编号 行业编码 9、10 行业编码 类型编码 11、12、13 111～130 表示类型为前端主设备 118-网络视频录像机（NVR）编码 131～199表示类型为前端外围设备 131-摄像机编码132-网络摄像机（IPC）编码 200～299表示类型为平台设备 200-中心信令控制服务器编码 网络标识 14 网络标识编码 0、1、2、3、4为监控报警专网，5为公安信息网，6为政务网，7为Internet网，8为社会资源接入网，9预留 序号 15～20 设备、用户序号 SIPSIP（Session Initiation Protocol，会话初始协议）是由IETF（Internet Engineering Task Force，因特网工程任务组）制定的多媒体通信协议 它是一个基于文本的应用层控制协议，用于创建、修改和释放一个或多个参与者的会话。其状态码类似于HTTP协议 国标的信令主要采用了SIP协议：其中注册设备采用REGISTER；实况采用INVITE；回放控制采用INFO；设备信息查询通知采用MESSAGE，订阅事件采用SUBSCRIBE，事件通知采用NOTIFY 主要业务流程注册和保活设备或系统进入联网系统时向SIP服务器进行注册登记的工作模式。 如果设备或系统注册不成功，宜延迟一定的随机时间后重新注册 流程如下： SIP代理向SIP服务器发送REGISTER请求 SIP服务器向SIP代理发送响应401（未鉴权），并在响应的消息头WWW_Authenticate字段中给出适合SIP代理的认证体制和参数规范 SIP代理重新向SIP服务器发送REGISTER请求，在请求的Authorization字段给出鉴权认证信息； SIP服务器对请求进行验证，如果检查SIP代理身份合法，向SIP代理发送成功响应200 OK，如果身份不合法则发送拒绝服务应答 SIP代理默认每30秒发送发送一次保活报文，保活信息于MESSAGE BODY描述，超过3次未保活成功，则SIP服务器会认为SIP代理已离线 REGISTER中Expires字段描述了注册过期时间，再过期之前，SIP代理会刷新注册（CallID会一致） 实况实时视音频点播采用SIP协议（IETF RFC 3261）中的INVITE方法实现会话连接，采用RTP/RTCP协议（IETF RFC 3550）实现媒体传输 流程描述如下： 媒体流接收者向SIP服务器发送Invite消息，消息头域中携带Subject字段，表明点播的视频源ID、发送方媒体流序列号、媒体流接收者ID、接收端媒体流序列号等参数，SDP（为区别，图中为SDP1）消息体中s字段为“Play”代表实时点播 SIP服务器收到Invite请求后，通过三方呼叫控制建立媒体服务器和媒体流发送者之间的媒体连接。向媒体服务器发送Invite消息，此消息不携带SDP消息体； 媒体服务器收到SIP服务器的Invite请求后，回复200 OK响应，携带SDP（图中为SDP2）消息体，消息体中描述了媒体服务器接收媒体流的IP、端口、媒体格式等内容； SIP服务器收到媒体服务器返回的200 OK响应后，向媒体流发送者发送Invite请求，请求中携带消息3中媒体服务器回复的200 OK响应消息体，s字段为“Play”代表实时点播 媒体流发送者收到SIP服务器的Invite请求后，回复200 OK响应，携带SDP（图中为SDP3）消息体，消息体中描述了媒体流发送者发送媒体流的IP、端口、媒体格式、SSRC字段等内容； SIP服务器收到媒体流发送者返回的200 OK响应后，向媒体服务器发送ACK请求，请求中携带消息5中媒体流发送者回复的200 OK响应消息体，完成与媒体服务器的Invite会话建立过程 SIP服务器收到媒体流发送者返回的200 OK响应后，向媒体流发送者发送ACK请求，请求中不携带消息体，完成与媒体流发送者的Invite会话建立过程 完成三方呼叫控制后，SIP服务器建立了媒体流接收者和媒体服务器之间的媒体连接。在消息1中增加SSRC值，转发给媒体服务器 媒体服务器收到Invite请求，回复200 OK响应，携带SDP（图中为SDP4）消息体，消息体中描述了媒体服务器发送媒体流的IP、端口、媒体格式、SSRC值等内容 SIP服务器将消息9转发给媒体流接收者 媒体流接收者收到200 OK响应后，回复ACK消息，完成与SIP服务器的Invite会话建立过程 SIP服务器将消息11转发给媒体服务器，完成与媒体服务器的Invite会话建立过程 媒体流接收者向SIP服务器发送BYE消息，断开消息1、10、11建立的同媒体流接收者的Invite会话； SIP服务器收到BYE消息后回复200 OK响应，会话断开； SIP服务器收到BYE消息后向媒体服务器发送BYE消息，断开消息8、9、12建立的同媒体服务器的Invite会话； 媒体服务器收到BYE消息后回复200 OK响应，会话断开 SIP服务器向媒体服务器发送BYE消息，断开消息2、3、6建立的同媒体服务器的Invite会话； 媒体服务器收到BYE消息后回复200 OK响应，会话断开 SIP服务器向媒体流发送者发送BYE消息，断开消息4、5、7建立的同媒体流发送者的Invite会话； 媒体流发送者收到BYE消息后回复200 OK响应，会话断开 录像检索与回放检索 流程大致如下： 录像检索方向录像拥有方发送目录查询请求Message消息，消息体中包含视音频文件检索条件，包括查询的设备编码，查询时间段等，其中，消息体的CmdType字段为RecordInfo代表是录像检索 录像拥有方向录像检索方发送200 OK，无消息体； 录像拥有方以Message向录像检索方发送查询结果，消息体中含文件目录，当一条Message消息无法传送完所有查询结果时，采用多条消息传送； 录像检索方向录像拥有方发送200 OK，无消息体。 回放采用SIP协议中的INVITE方法实现会话连接，采用SIP扩展协议INFO方法的消息体携带视音频回放控制命令，采用RTP/RTCP协议实现媒体传输。媒体回放控制命令引用MANSRTSP协议中的PLAY，PAUSE，TEARDOWN 的请求消息和应答消息 回放总体可以分为三个部分，分别是会话连接，回放控制和资源释放，其中会话连接和资源释放与实况流程基本一致，消息体中的字段会区别回放还是实况 会话建立 回放控制 资源释放 流程描述如下： （会话建立）媒体流接收者向SIP服务器发送Invite消息，消息头域中携带Subject字段，表明点播的视频源ID、发送方媒体流序列号、媒体流接收者ID、接收端媒体流序列号标识等参数，SDP（图中为SDP1）消息体中s字段为“Playback”代表历史回放，u字段代表回放通道ID和回放类型，t字段代表回放时间段； SIP服务器收到Invite请求后，通过三方呼叫控制建立媒体服务器和媒体流发送者之间的媒体连接。向媒体服务器发送Invite消息，此消息不携带SDP消息体； 媒体服务器收到SIP服务器的Invite请求后，回复200 OK响应，携带SDP消息体，消息体中描述了媒体服务器接收媒体流的IP、端口、媒体格式等内容； SIP服务器收到媒体服务器返回的200 OK响应后，向媒体流发送者发送Invite请求，请求中携带消息3中媒体服务器回复的200 OK响应消息体，s字段为“Playback”代表历史回放，u字段代表回放通道ID和回放类型，t字段代表回放时间段，增加y字段描述SSRC值，f字段描述媒体参数； 媒体流发送者收到SIP服务器的Invite请求后，回复200 OK响应，携带SDP消息体，消息体中描述了媒体流发送者发送媒体流的IP、端口、媒体格式、SSRC字段等内容； SIP服务器收到媒体流发送者返回的200 OK响应后，向媒体服务器发送ACK请求，请求中携带消息5中媒体流发送者回复的200 OK响应消息体，完成与媒体服务器的Invite会话建立过程； SIP服务器收到媒体流发送者返回的200 OK响应后，向媒体流发送者发送ACK请求，请求中不携带消息体，完成与媒体流发送者的Invite会话建立过程； 完成三方呼叫控制后，SIP服务器建立媒体流接收者和媒体服务器之间的媒体连接。在消息1中增加SSRC值，转发给媒体服务器； 媒体服务器收到Invite请求，回复200 OK响应，携带SDP消息体，消息体中描述了媒体服务器发送媒体流的IP、端口、媒体格式、SSRC值等内容； SIP服务器将消息9转发给媒体流接收者； 媒体流接收者收到200 OK响应后，回复ACK消息，完成与SIP服务器的Invite会话建立过程； SIP服务器将消息11转发给媒体服务器，完成与媒体服务器的Invite会话建立过程； （控制）在回放过程中，媒体流接收者通过向SIP服务器发送会话内Info消息进行回放控制，包括视频的暂停、播放、快放、慢放、随机拖放播放等操作 SIP服务器收到消息13后转发给媒体流发送者 媒体流发送者收到消息14后回复200 OK响应； SIP服务器将消息15转发给媒体流接收者 媒体流发送者在文件回放结束后发送会话内Message消息，通知SIP服务器回放已结束 SIP服务器收到消息17后转发给媒体流接收者 媒体流接收者收到消息18后回复200 OK响应，进行链路断开过程； SIP服务器将消息19转发给媒体流发送者 （释放会话）媒体流接收者向SIP服务器发送BYE消息，断开消息1、10、11建立的同媒体流接收者的Invite会话 SIP服务器收到BYE消息后回复200 OK响应，会话断开 IP服务器收到BYE消息后向媒体服务器发送BYE消息，断开消息8、9、12建立的同媒体服务器的Invite会话 媒体服务器收到BYE消息后回复200 OK响应，会话断开 SIP服务器向媒体服务器发送BYE消息，断开消息2、3、6建立的同媒体服务器的Invite会话； 媒体服务器收到BYE消息后回复200 OK响应，会话断开 SIP服务器向媒体流发送者发送BYE消息，断开消息4、5、7建立的同媒体流发送者的Invite会话； 媒体流发送者收到BYE消息后回复200 OK响应，会话断开 设备信息查询设备信息查询包括目录查询、前端设备信息查询、前端设备状态查询、设备配置查询、预置位查询等，查询的范围包括本地SIP域或者跨SIP域。网络设备信息查询命令和响应均采用方法MESSAGE实现 源设备包括SIP客户端、网关或联网系统，目标设备包括SIP设备、网关或联网系统 源设备向SIP服务器发送设备查询命令，设备查询命令采用MESSAGE方法携带 SIP服务器收到命令后返回200 OK SIP服务器向目标设备转发设备查询命令，设备查询命令采用MESSAGE方法携带 目标设备收到命令后返回200 OK 目标设备向SIP服务器发送设备查询响应命令，设备查询响应命令采用MESSAGE方法携带 SIP服务器收到命令后返回200 OK SIP服务器向源设备转发查询响应命令，设备查询响应命令采用MESSAGE方法携带 目标设备收到命令后返回200 OK 订阅与通知订阅事件订阅使用SUBSCRIBE方法，事件源接受事件订阅时，事件源向事件观察者发送确认消息。 订阅流程如下： 事件观察者向事件源发送SUBSCRIBE请求，请求消息体携带订阅参数 事件源应将订阅成功与否的响应消息返回给该事件观察者 通知 在订阅事件触发后事件源向事件观察者发送NOTIFY消息，NOTIFY的消息体应携带通知参数； 事件源应将通知的响应消息返回给该事件观察者 总结常见问题以设备注册问题、实况问题、回放问题为主，遇到有争议的问题时，最好对照下国标文档。 附GB28181-2011和GB28181-2016规范文档下载链接： https://skynemo-1258540788.cos.ap-chengdu.myqcloud.com/SkyNemo-Blog/security/protocol/GB28181-base/11-GB28181-Standard-Document.zip]]></content>
      <categories>
        <category>安防基础</category>
      </categories>
      <tags>
        <tag>安防基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[独立冗余磁盘阵列-RAID基础]]></title>
    <url>%2F2019%2F12%2F12%2F%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80%2FRAID-base%2F</url>
    <content type="text"><![CDATA[太长不看系列： RAID级别 有无容错 硬盘数 可用容量 允许故障硬盘数 使用场景 RAID0 无 $N\geq 2$ 100% 0 对性能要求高，但对数据安全性和可靠性要求低的场合，如临时数据缓存空间等 RAID1 有 $N\geq 2$且N为2的倍数 50% $\frac{N}{2}$ 对性能要求低，但对数据安全性和可靠性要求高的场合 RAID3 有 $N\geq 3$ $\frac{N-1}{N}$ 1 适用大容量数据的顺序访问应用，使用较少，被RAID5替代 RAID5 有 $N\geq 3$ $\frac{N-1}{N}$ 1 满足大部分的存储应用需求，数据中心数据存储、安防行业的音视频存储最常用的RAID级别 RAID6 有 $N\geq 4$ $\frac{N-2}{N}$ 2 对数据安全等级要求较高的场合，替代 RAID10 方案的经济性选择 RAID10 有 $N\geq 4$ 50% $\frac{N}{2}$ 对性能要求高，且对数据安全性和可靠性要求高的场合 RAID50 有 $N\geq 6$ $\frac{N-RAID5的组数}{N}$ 每组RAID5允许一块硬盘故障 对数据安全等级要求较高的场合，替代 RAID10 方案的经济性选择 RAID介绍后续增加。。。 RAID作用RAID相关技术RAID级别总结]]></content>
      <categories>
        <category>存储基础</category>
      </categories>
      <tags>
        <tag>存储基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机系统中的时间]]></title>
    <url>%2F2019%2F12%2F06%2FLinux%E5%9F%BA%E7%A1%80%2Fsystem-time%2F</url>
    <content type="text"><![CDATA[常见的时间缩写太长不看系列：UTC = GMT , CST = UTC + 时区 ，CST（国内） = 北京时间 UTC(英：Coordinated Universal Time ，法：Temps Universel Coordonné)：协调世界时 英国格林威治皇家天文台所在地的标准时间，UTC基于国际原子时间，是全世界统一的世界标准时间。也是表示地球自转速率的一种形式，需要不规则地加入闰秒。 GMT(Greenwich Mean Tim)：格林威治标准时间 一般认为UTC和GMT是相等的，但是会存在0.9秒以内的误差，这是由于地球不规则自转引起的。 CST(Central Standard Time)：中央标准时间 四大时区的时间，CST = UTC + 时区。东正西负。比如北京时间在东八区就是 UTC+(+0800)，在国内，一般认为CST就代表北京时间即可。 1234Central Standard Time (USA) UT-6:00（美国cst时间：零区时减6个小时）Central Standard Time (Australia) UT+9:30（澳大利亚cst：加9个半小时）China Standard Time UT+8:00（中国cst:加8个小时）Cuba Standard Time UT-4:00 （古巴cst:减4个小时） DST(Daylight Saving Time)，夏日节约时间，即夏令时 是指夏天太阳升起比较早，将时钟拨快一个小时来提早日光的使用。欧美主要国家都引用了这个做法。如果在夏令时时区内 DST=UTC+时区+1，中国已经废止。 CET(Central European Time)，欧洲中部时间 冬季时间为UTC+1，夏季欧洲夏令时为UTC+1+1。 Unix时间戳（Unix epoch, Unix time, POSIX time 或 Unix timestam） Unix时间戳是从1970年1月1日（UTC/GMT的午夜）开始所经过的秒数，不考虑闰秒。 计算机系统时钟 Hardware clock 硬件时钟 即BIOS时间，就是我们进行CMOS设置时看到的时间，计算机硬件有个电池供电的实时时钟(Real-time Clock, RTC)也叫(CMOS时钟，BIOS时间，三者同一)。使用的时间标准由操作系统设置。硬件时钟默认使用UTC时间，建议使用UTC全球时间标准，因为硬件时钟不能保存时区和夏令时调整，修改后就无法从硬件时钟中读取出准确标准时间，因此不建议修改为其他时间格式 Software clock 软件时钟 计算机系统运行时的时钟(Syetem clock)。 计算机系统时钟运行过程 关机状态：硬件时钟有电池供电，始终在主板上默默运行着。通电进入BIOS: 主板BIOS系统界面能够看到并设置硬件时间。电脑开机： 开机引导时：使用硬件时钟设置系统时钟。Arch Linux系统开机时间会更新到/etc/adjtime 系统运行时：系统正常运行后，由系统内核独自运行系统时钟。 时钟同步服务：需要联网，大部分操作系统都带有联网后能够和网络上的NTP服务器同步系统时钟，修正系统时间的准确性 系统关机时：会使用系统时钟设置硬件时钟，更新硬件时钟。 注：服务器系统开机后会连续运行数月，甚至数年。硬件时间与软件时间会出现差异，一般以系统时间为准 CentOS下时钟查看与维护*注：以下命令运行于系统版本：CentOS-6.10-x86_64 系统时钟查看系统时间1234# dateTue Jan 21 01:54:17 CST 2020# date -RTue, 21 Jan 2020 01:54:27 +0800 *注：+0800表示东八区（北京时间） 设置系统时间设置日期 123456# date -s 20200119Sun Jan 19 00:00:00 CST 2020# date -s 2020-01-20Mon Jan 20 00:00:00 CST 2020# date -s 2020/01/21Tue Jan 21 00:00:00 CST 2020 设置时间 12# date -s 01:40:00Tue Jan 21 01:40:00 CST 2020 设置日期和时间 12[root@Neil ~]# date -s "20080808 15:00:00"Fri Aug 8 15:00:00 CST 2008 更多时间显示方式或参数设置，请使用date --help查看 时区设置所有时区的信息存在/usr/share/zoneinfo/下面，本机的时区信息存在/etc/localtime，可以用复制（cp）或者创建链接（ln）的方式设置时区，以下以设置亚洲上海时区为例，其他时区形式可参考/usr/share/zoneinfo/路径或tzselect命令 123cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 硬件时钟hwclock可以打印/设定硬件时钟，cat /proc/driver/rtc可以查看RTC存储的时间 读硬件时钟 12# hwclockSun 08 Dec 2019 12:06:14 AM CST -0.954251 seconds 查看开机引导时更新的系统时刻 1234# cat /etc/adjtime0.000000 1575721137 0.0000001575721137UTC 1575721137 表示最近一次开机引导时，硬件时间与1970-01-01 00:00:00间隔的秒数，UTC表示硬件时间以UTC存储 设置硬件时钟 123# hwclock --set --date="20080808 14:55"# hwclockFri 08 Aug 2008 02:55:07 PM CST -0.876395 seconds 硬件时钟和系统时钟之间的同步硬件时钟与系统时钟同步将系统时间更新到硬件时钟，使用hwclock --systohc或者hwclock –w 1234567# dateFri Aug 8 14:57:28 CST 2008# hwclockFri 08 Aug 2008 12:00:21 AM CST -0.548385 seconds# hwclock -w# hwclockFri 08 Aug 2008 02:57:59 PM CST -0.469971 seconds 系统时钟与硬件时钟同步将硬件时间更新到系统时间，使用hwclock --hctosys或者hwclock –s 1234567# hwclockFri 08 Aug 2008 03:10:05 PM CST -0.157034 seconds# dateFri Aug 8 15:17:08 CST 2008# hwclock --hctosys# dateFri Aug 8 15:17:28 CST 2008 关于hwclock与硬件时钟(RTC)RTC查看硬件时钟cat /proc/driver/rtc: 1234567891011121314# cat /proc/driver/rtcrtc_time : 07:21:41rtc_date : 2008-08-08alrm_time : 00:00:00alrm_date : ****-**-**alarm_IRQ : noalrm_pending : no24hr : yesperiodic_IRQ : noupdate_IRQ : noHPET_emulated : yesDST_enable : noperiodic_freq : 1024batt_status : okay 这里的时间是“真正“的硬件时间，看下此时RTC与hwclock和hwclock --localtime的区别: 1234567891011121314151617181920# cat /proc/driver/rtcrtc_time : 07:21:41rtc_date : 2008-08-08alrm_time : 00:00:00alrm_date : ****-**-**alarm_IRQ : noalrm_pending : no24hr : yesperiodic_IRQ : noupdate_IRQ : noHPET_emulated : yesDST_enable : noperiodic_freq : 1024batt_status : okay[root@Neil ~]# hwclockFri 08 Aug 2008 03:21:49 PM CST -0.344394 seconds[root@Neil ~]# hwclock --localtimeFri 08 Aug 2008 07:22:00 AM CST -0.813282 seconds 可见hwclock --localtime和hwclock --utc的作用： 12hwclock --localtime #硬件被设定的时间hwclock --utc #显示的是当硬件时间为utc时，的真“本地时间” 注：当硬件时间存储为LOCAL时，hwclock --utc无意义 分析hwclock通过strace我们可以跟踪hwclock执行时打开的文件，分析hwclock。先安装strace: 1# yum -y install strace 追踪hwclock -r（同hwclock）: 12345678910111213141516171819# strace -e trace=open hwclock -r open("/etc/ld.so.cache", O_RDONLY) = 3open("/lib64/libaudit.so.1", O_RDONLY) = 3open("/lib64/libc.so.6", O_RDONLY) = 3open("/usr/lib/locale/locale-archive", O_RDONLY) = 4open("/dev/rtc", O_RDONLY) = 4open("/etc/adjtime", O_RDONLY) = 5open("/usr/share/zoneinfo/Universal", O_RDONLY) = 5open("/etc/localtime", O_RDONLY) = 5open("/usr/share/locale/locale.alias", O_RDONLY|O_CLOEXEC) = 5open("/usr/share/locale/en_US.UTF-8/LC_MESSAGES/util-linux-ng.mo", O_RDONLY) = -1 ENOENT (No such file or directory)open("/usr/share/locale/en_US.utf8/LC_MESSAGES/util-linux-ng.mo", O_RDONLY) = -1 ENOENT (No such file or directory)open("/usr/share/locale/en_US/LC_MESSAGES/util-linux-ng.mo", O_RDONLY) = -1 ENOENT (No such file or directory)open("/usr/share/locale/en.UTF-8/LC_MESSAGES/util-linux-ng.mo", O_RDONLY) = -1 ENOENT (No such file or directory)open("/usr/share/locale/en.utf8/LC_MESSAGES/util-linux-ng.mo", O_RDONLY) = -1 ENOENT (No such file or directory)open("/usr/share/locale/en/LC_MESSAGES/util-linux-ng.mo", O_RDONLY) = -1 ENOENT (No such file or directory)Sun 08 Dec 2019 10:16:29 PM CST -0.565908 seconds+++ exited with 0 +++ 可以看到： hwclock首先打开了/dev/rtc,读取硬件时钟； 打开/etc/adjtime文件，通过先前的记录来估算硬件时钟的偏差，读取并用来校正目前的时间，读取硬件时间标准（UTC或者LOCAL）； 打开/etc/localtime时区文件，若硬件时间为UTC，则将硬件时间转换为当前时区对映的时间。 更改硬件时间标准更改硬件时间标准为本地时间，不建议（LOCAL）: 12345# hwclock --systohc --localtime# cat /etc/adjtime0.000000 1575742061 0.0000001575742061LOCAL 更改硬件时间标准为UTC: 12345# hwclock --systohc --utc# cat /etc/adjtime0.000000 1575742277 0.0000001575742277UTC 其他时间操作查看最近一次开机时刻who -b： 12# who -b system boot 2019-12-08 23:11 查看系统连续运行时间uptime 12# uptime 15:55:06 up 2:29, 1 user, load average: 0.00, 0.00, 0.00 连续运行秒数cat /proc/uptime 12cat /proc/uptime8996.88 8968.96 CentOS 7的timedatectl*注：以下命令运行于系统版本：CentOS-7-x86_64-1908 关于timedatectl太长不看系列：一个比date更好用的命令 （官文翻译）timedatectl可用于查询和更改系统时钟及其设置，以及启用或禁用时间同步服务。使用systemd初始化已装载（但未引导）系统映像的系统时区。使用timedatectl可用于显示时间同步服务的当前状态 使用timedatectl查询系统时间/查看当前设置 123456789# timedatectl Local time: Mon 2019-12-09 02:03:45 CST Universal time: Sun 2019-12-08 18:03:45 UTC RTC time: Sun 2019-12-08 18:03:45 Time zone: Asia/Shanghai (CST, +0800) NTP enabled: n/aNTP synchronized: no RTC in local TZ: no DST active: n/a Local time：本地时间（系统时间） Universal time：全球时间 RTC time：硬件时间 Time zone：时区 NTP enabled：时间同步 NTP synchronized：NTP网络同步服务 RTC in local TZ：硬件时钟时间标准 DST active：夏令时 由上可以看到大部分常用的时间设置，值得注意的时，因为本机硬件时间为UTC标准，所以RTC时间（RTC time）与全球时间（Universal time）一致，与本地时间（Local time，东八区）相差8小时；如果硬件时间设置为LOCAL，则此处RTC时间与本地时间会相近（系统运行长时间后，硬件时间与系统时间不一定会相等；通常以系统时间为准） 设置系统时间 12# timedatectl set-time "2019-12-30 00:01:02"# timedatectl set-time "01:02:03" 列出所有时区 1# timedatectl list-timezones 巧用grep过滤下，timedatectl list-timezones | grep Asia列出所有亚洲时区 设置时区 1# timedatectl set-timezone Asia/Shanghai 更改硬件时间标准 12# timedatectl set-local-rtc 1# timedatectl set-local-rtc 0 0表示使用UTC作为硬件时间标准； 1表示使用本地时间作为硬件时间标准（不建议），执意使用，查询时间时（timedatectl）会出现警告： 123456Warning: The system is configured to read the RTC time in the local time zone. This mode can not be fully supported. It will create various problems with time zone changes and daylight saving time adjustments. The RTC time is never updated, it relies on external facilities to maintain it. If at all possible, use RTC in UTC by calling 'timedatectl set-local-rtc 0'. 是否开启NTP服务器同步** 12# timedatectl set-ntp yes# timedatectl set-ntp no 由于时间同步服务比较复杂，决定另开一篇介绍。]]></content>
      <categories>
        <category>计算机基础</category>
      </categories>
      <tags>
        <tag>计算机基础</tag>
        <tag>Linux基础</tag>
        <tag>时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode-11：盛最多水的容器]]></title>
    <url>%2F2019%2F07%2F29%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%2FLeetCode-11%2F</url>
    <content type="text"><![CDATA[示例: 12输入: [1,8,6,2,5,4,8,3,7]输出: 49 分析如题意，垂直的两条线段将会与坐标轴构成一个矩形区域，较短线段的长度将会作为矩形区域的宽度，两线间距将会作为矩形区域的长度，而我们必须最大化该矩形区域的面积。 矩阵的面积与两个因素有关： 矩阵的长度：两条垂直线的距离。 矩阵的宽度：两条垂直线其中较短一条的长度因此。 要矩阵面积最大化，两条垂直线的距离越远越好，两条垂直线的最短长度也要越长越好。矩形面积可以表示为：$S_{ij} = (i - j) \times min( a[i] , a[j] ) $，其中$(0\leq j&lt;i\leq n-1)$，$n$为数组长度。 解决方案方法一：暴力法算法这是最容易想到的方法，考虑每对可能出现的线段组合，使用变量maxarea来持续存储到目前为止所获得的最大面积。代码如下（C++，LeetCode运行直接超时）： 12345678910111213141516int maxArea_bruteForce(vector&lt;int&gt;&amp; height) &#123; int maxarea = 0; // 两层循环，外层循环遍历所有线段，内层遍历每条线段与在其之前线段组成的所有可能性，找到最大值 for (int i = 1; i &lt; height.size(); i++) &#123; for (int j = 0; j &lt; i; j++) &#123; int capcity = height.at(i) &lt; height.at(j) ? (i - j) * height.at(i) : (i - j) * height.at(j); if (maxarea &lt; capcity) &#123; maxarea = capcity; &#125; &#125; &#125; return maxarea;&#125; Java代码如下(执行用时：402 ms)： 1234567public int maxArea_bruteForce(int[] height) &#123; int maxarea = 0; for (int i = 0; i &lt; height.length; i++) for (int j = i + 1; j &lt; height.length; j++) maxarea = Math.max(maxarea, Math.min(height[i], height[j]) * (j - i)); return maxarea;&#125; 复杂度分析 时间复杂度：$O(n^2)$，计算所有种$O(\frac{n \times (n-1)}{2})$高度组合的面积。 空间复杂度：$O(1)$，使用恒定的额外空间。 方法二：双指针法算法这种方法背后的思路在于，两线段之间形成的区域总是会受到其中较短那条高度的限制。此外，两线段距离越远，宽度越大，得到的面积就越大。我们在由线段长度构成的数组中使用两个指针，一个放在开始，一个置于末尾。此外，我们会使用变量maxarea来持续存储到目前为止所获得的最大面积。$p$ 指针由开始向末尾移动，$q$ 指针由末尾向开始移动，当 $p = q$ 时，停止遍历。在每一步中，我们会找出指针所指向的两条线段形成的区域，更新maxarea，并将指向较短线段的指针向较长线段那端移动一步。 为什么是指向较短线段的指针向较长线段那端移动一步？最初我们考虑由最外围两条线段构成的区域。现在，为了使面积最大化，我们需要考虑更长的两条线段之间的区域。如果我们试图将指向较长线段的指针向内侧移动，矩形区域的面积将受限于较短的线段而不会获得任何增加。但是，在同样的条件下，移动指向较短线段的指针尽管造成了矩形宽度的减小，但却可能会有助于面积的增大。因为移动较短线段的指针会得到一条相对较长的线段，这可以克服由宽度减小而引起的面积减小。 如果两个指针指向的值相等，该移动哪一个呢？ 我们假设 $a[1]$ 和 $a[8]$ 高度是相等的。如果它们之间只有1个元素比它俩高或者没有比它俩高的，那么最大面积就一定选取是 $i = 1$ 和 $j = 8$ 了，所以 $i$ 接着变大，或者 $j$ 接着减小都是无所谓的，因为答案已经确定了。 假设$a[1]$和$a[8]$之间有2个元素比它俩高，假设是 $a[4]$ 和 $a[6]$ 两个元素。$i = 1$会变到 $i = 2$、$i = 3$，最终为 $i = 4$； $j = 8$ 会变到 $j = 7 $， $j = 6$，而在这个过程中产生的面积一定不会比 $i = 1$ 和 $j = 8$ 产生的面积大，因为变换过程中的高度都比$a[1]$和$a[8]$低。所以是先变 $i = 1$ 还是先变 $j = 8$ 是无所谓的，无非是谁先到达更长的柱子而已。 代码如下（C++，执行时间：24 ms）： 12345678910111213141516171819202122232425262728293031323334int maxArea_twoPointer(vector&lt;int&gt;&amp; height) &#123; int p = 0, q = height.size() - 1; // 前指针p，后指针q int maxarea = 0; // 变量area存储每次指针推进（p++或q--）后的矩形区域大小 int area = 0; // 变量maxarea存储当前出现最大的矩形区域 int width = q - p; // 变量width用于表示矩阵宽度，每次推进width-1 int heightP = 0; // 变量heightP存储a[p]的高度 int heightQ = 0; // 变量heightQ存储a[q]的高度 int maxHP = 0; // 变量maxHP存储当前出现的，p方向上最大高度max&#123;a[p]&#125; int maxHQ = 0; // 变量maxHQ存储当前出现的，q方向上最大高度max&#123;a[q]&#125; // 两边指针向中间推进 while (p &lt; q) &#123; heightP = height.at(p); heightQ = height.at(q); // 矩形面积为 S = 宽度 * 两边较小高度 if (heightP &lt; heightQ) &#123; area = weight * heightP; p++; &#125; else &#123; area = weight * heightQ; q--; &#125; if (maxarea &lt; area) &#123; maxarea = area; &#125; weight--; &#125; return maxarea;&#125; Java代码如下（执行用时：6 ms）： 123456789101112public int maxArea(int[] height) &#123; int maxArea = 0, l = 0, r = height.length - 1; while (l &lt; r) &#123; maxArea = Math.max(maxArea, Math.min(height[l], height[r]) * (r - l)); if (height[l] &lt; height[r]) l++; else r--; &#125; return maxArea;&#125; 优化如果移动后当前线段高度小于移动前线段的高度，因为移动后 $weidth$ 等于移动前 $weidth - 1 $，宽度高度均减小，最大矩形区域maxarea一定不会在该情况下出现，可以不用计算当前区域的面积，直接进行下一次指针移动。 再扩展一下，如果当前线段高度小于之前出现的最大高度，因为 $weidth$ 减小，所以最大矩形区域maxarea一定不会在该情况下出现，可以不用计算当前区域的面积，直接进行下一次指针移动。所以需要两个变量（maxHP、maxHQ）来记录左右指针遍历过的线段中的最大高度。这样不用每移动一次就要计算面积并与最大面积比较，减少计算次数。 代码如下（C++，执行时间：16 ms）： 1234567891011121314151617181920212223242526272829303132333435363738394041int maxArea_twoPointer(vector&lt;int&gt;&amp; height) &#123; int p = 0, q = height.size() - 1; // 前指针p，后指针q int maxarea = 0; // 变量area存储每次指针推进（p++或q--）后的矩形区域大小 int area = 0; // 变量maxarea存储当前出现最大的矩形区域 int width = q - p; // 变量width用于表示矩阵宽度，每次推进width-1 int heightP = 0; // 变量heightP存储a[p]的高度 int heightQ = 0; // 变量heightQ存储a[q]的高度 int maxHP = 0; // 变量maxHP存储当前出现的，p方向上最大高度max&#123;a[p]&#125; int maxHQ = 0; // 变量maxHQ存储当前出现的，q方向上最大高度max&#123;a[q]&#125; // 两边指针向中间推进 while (p &lt; q) &#123; heightP = height.at(p); heightQ = height.at(q); // 若当前高度a[p或q]小于当前方向上出现的最大高度，maxarea不会出现 if (heightP &lt; maxHP) &#123; p++; &#125; else if ( heightQ &lt; maxHQ) &#123; q++; &#125; else &#123; // 矩形面积为 S = 宽度 * 两边较小高度 if (heightP &lt; heightQ) &#123; area = width * heightP; p++; &#125; else &#123; area = width * heightQ; q--; &#125; if (maxarea &lt; area) &#123; maxarea = area; &#125; &#125; width--; &#125; return maxarea;&#125; 复杂度分析 时间复杂度：$O(n)$，一次扫描。 空间复杂度：$O(1)$，使用恒定的空间。]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>数组</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数组</tag>
        <tag>双指针</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法-3：桶排序、计数排序、基数排序]]></title>
    <url>%2F2019%2F07%2F17%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%2Falgo-sort-3%2F</url>
    <content type="text"><![CDATA[前两篇文章分析了几种常用排序算法的原理、时间复杂度、空间复杂度、稳定性等；本篇文章会讲三种时间复杂度为$O(n)$的排序算法：桶排序、计数排序、基数排序等。也因为其时间复杂度线性的，我们也称这类排序算法为线性排序（Linear sort）。之所以能够做到线性复杂度，主要原因是，这三个算法不是基于比较的排序算法，都不涉及元素之间的比较操作。 这几种排序算法理解起来都不难，时间、空间复杂度分析起来也很简单，但是对要排序的数据要求很苛刻，所以、学习重点的是掌握这些排序算法的适用场景。 桶排序（Bucket sort）桶排序，，核心思想是将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。 桶排序的时间复杂度为什么是$O(n)$呢？假设排序的数据有n个，我们把它们均匀地划分到m个桶内，每个桶里就有$k = \frac{n}{m}$个元素。每个桶内部使用快速排序，时间复杂度为$O(n\log(n))$。m个桶排序的时间复杂度就是$O(m \cdot k\cdot \log(k))$，因为$k = \frac{n}{m}$，所以整个桶排序的时间复杂度就是$O(n\cdot\log(\frac{n}{m}))$。当桶的个数m接近数据个数n时，$\log(\frac{n}{m})$就是一个非常小的常量，这个时候桶排序的时间复杂度接近$O(n)$。 桶排序是不是可以替代我们之前讲的排序算法呢？答案当然是否定的。刚才做了很多假设。实际上，桶排序对要排序数据的要求是非常苛刻的。首先，要排序的数据需要很容易就能划分成m个桶，并且，桶与桶之间有着天然的大小顺序。 这样每个桶内的数据都排序完之后，桶与桶之间的数据不需要再进行排序。其次，数据在各个桶之间的分布是比较均匀的。如果数据经过桶的划分之后，有些桶里的数据非常多，有些非常少，很不平均，那桶内数据排序的时间复杂度就不是常量级了。在极端情况下，如果数据都被划分到一个桶里，那就退化为$O(n\log(n))$的排序算法了。 桶排序比较适合用在外部排序中所谓的外部排序就是数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。 比如说我们有10GB的订单数据，我们希望按订单金额（假设金额都是正整数）进行排序，但是我们的内存有限，只有几百MB，没办法一次性把10GB的数据都加载到内存中。这个时候该怎么办呢？现在我来讲一下，如何借助桶排序的处理思想来解决这个问题。我们可以先扫描一遍文件，看订单金额所处的数据范围。假设经过扫描之后我们得到，订单金额最小是1元，最大是10万元。我们将所有订单根据金额划分到100个桶里，第一个桶我们存储金额在1元到1000元之内的订单，第二桶存储金额在1001元到2000元之内的订单，以此类推。每一个桶对应一个文件，并且按照金额范围的大小顺序编号命名（00，01，02..99）。理想的情况下，如果订单金额在1到10万之间均匀分布，那订单会被均匀划分到100个文件中，每个小文件中存储大约100MB的订单数据，我们就可以将这100个小文件依次放到内存中，用快排来排序。等所有文件都排好序之后，我们只需要按照文件编号，从小到大依次读取每个小文件中的订单数据，并将其写入到一个文件中，那这个文件中存储的就是按照金额从小到大排序的订单数据了。不过，你可能也发现了，订单按照金额在1元到10万元之间并不一定是均匀分布的，所以10GB订单数据是无法均匀地被划分到100个文件中的。有可能某个金额区间的数据特别多，划分之后对应的文件就会很大，没法一次性读入内存。这又该怎么办呢？ 针对这些划分之后还是比较大的文件，我们可以继续划分，比如，订单金额在1元到1000元之间的比较多，我们就将这个区间继续划分为10个小区间，1元到100元，101元到200元，201元到300元..901元到1000元。如果划分之后，101元到200元之间的订单还是太多，无法一次性读入内存，那就继续再划分，直到所有的文件都能读入内存为止。 计数排序（Counting sort）计数排序与桶排序十分类似。当要排序的n个数据，所处的范围并不大的时候，比如最大值是k，我们就可以把数据划分成k个桶。每个桶内的数据值都是相同的，省掉了桶内排序的时间。我们都经历过高考，高考查分数系统你还记得吗？我们查分数的时候，系统会显示我们的成绩以及所在省的排名。如果你所在的省有50万考生，如何通过成绩快速排序得出名次呢？考生的满分是750分，最小是0分，这个数据的范围很小，所以我们可以分成751个桶，对应分数从0分到750分。根据考生的成绩，我们将这50万考生划分到这750个桶里。桶内的数据都是分数相同的考生，所以并不需要再进行排序。我们只需要依次扫描每个桶，将桶内的考生依次输出到一个数组中，就实现了50万考生的排序。因为只涉及扫描遍历操作，所以时间复杂度是$O(n)$。 计数排序的算法思想就是这么简单，跟桶排序非常类似，只是桶的大小粒度不一样。不过，为什么这个排序算法叫“计数”排序呢？“计数”的含义来自哪里呢？ 想弄明白这个问题，我们就要来看计数排序算法的实现方法。我还拿考生那个例子来解释。为了方便说明，我对数据规模做了简化。 假设只有8个考生，分数在0到5分之间。我们使用数组A[8]存储这8个考生的成绩，它们分别是：{ 2，5，3，0，2，3，0，3 }。 考生的成绩从0到5分，我们使用大小为6的数组C[6]表示桶，其中下标对应分数。不过，C[6]内存储的并不是考生，而是某个分数对应的考生个数。像我刚刚举的那个例子，我们只需要遍历一遍考生分数，就可以得到C[6]的值，{ 2, 0, 2, 3 ,0, 1 }。 假设排序后的有序数组为R[8]，即成绩为3的考生，在R[8]中存储在下标为4，5，6三个位置。那么，我们需要如何快速计算出，每个分数的考生在有序数组R[8]中的位置？ 思路是这样的：我们对C[6]数组顺序求和，C[6]存储的数据就变成了{ 2, 2, 4, 7, 7, 8 }。即C[k]里存储小于等于分数k的考生个数。 我们从后到前依次扫描数组A。当扫描到3时，我们可以从数组C中取出下标为3的值7（ $c[3] = 7$ ），也就是说，到目前为止，包括自己在内，分数小于等于3的考生有7个，也就是说3是数组R中的第7个元素（也就是数组R中下标为6的位置）。当3放入到数组R中后，小于等于3的元素就只剩下了6个了，所以相应的C[3]要减1，变成6。以此类推，当我们扫描到第2个分数为3的考生的时候，就会把它放入数组R中的第6个元素的位置（也就是下标为5的位置）。当我们扫描完整个数组A后，数组R内的数据就是按照分数从小到大有序排列的了。 这种利用另外一个数组来计数的实现方式是不是很巧妙呢？这也是为什么这种排序算法叫计数排序的原因。不过，你千万不要死记硬背上面的排序过程，重要的是理解和会用。我总结一下，计数排序只能用在数据范围不大的场景中，如果数据范围k比要排序的数据n大很多，就不适合用计数排序了。而且，计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数。比如，还是拿考生这个例子。如果考生成绩精确到小数后一位，我们就需要将所有的分数都先乘以10，转化成整数，然后再放到9010个桶内。再比如，如果要排序的数据中有负数，数据的范围是[-1000，1000]，那我们就需要先对每个数据都加1000，转化成非负整数。]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法-2：归并、快速]]></title>
    <url>%2F2019%2F06%2F27%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%2Falgo-sort-2%2F</url>
    <content type="text"><![CDATA[上一篇文章讲了冒泡排序、插入排序、选择排序这三种排序算法，它们的时间复杂度都是$O(n^2)$，比较高，适合小规模数据的排序。而归并排序和快速排序时间复杂度均为$O(n\log(n))$。适合大规模的数据排序。归并排序和快速排序有一个共同点，它们都用到了分治思想。 归并排序（Merge Sort）归并排序的核心思想还是蛮简单的。如果要排序一个数组，我们先把数组从中间分成前后两部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起，这样整个数组就都有序了 这就是分治思想。将一个大问题分解成小的子问题来解决。小的子问题解决了，大问题也就解决了。 分治思想与递归思想很像。分治是一种解决问题的处理思想，递归是一种编程技巧，分治算法一般都是用递归来实现的。 回顾：递归代码两要素：1.递推公式，2.终止条件。然后将递推公式翻译成递归代码。 所以，要想写出归并排序的代码，我们先写出归并排序的递推公式。 12345递推公式：merge_sort(p…r) = merge(merge_sort(p…q), merge_sort(q+1…r))终止条件：p &gt;= r 不用再继续分解 merge_sort(p..r)表示，给下标从p到r之间的数组排序。我们将这个排序问题转化为了两个子问题，merge_sort(p..q)和merge_sort(q+1..r)，其中下标q等于p和r的中间位置，也就是$\frac{(\ p\ +\ r\ )}{2}$。当下标从p到q和从q+1到r这两个子数组都排好序之后，我们再将两个有序的子数组合并在一起，这样下标从p到r之间的数据就也排好序了。当p &gt;= r时，表示数组中只有一个元素。 将递推公式转化成代码（C） 123456789void __merge_sort(int* arr, int p, int r) &#123; int q; if (p &gt;= r) return; q = (p + r) / 2; __merge_sort(arr, p, q); __merge_sort(arr, q + 1, r); __merge(arr, p, q, r);&#125; 你可能已经发现了， __merge()这个函数的作用就是，将已经有序的arr[p..q]和arr[q+1..r]合并成一个有序的数组。那这个过程具体该如何做呢？我们可以申请一个临时数组tmp，大小与arr[p..r]相同。我们用两个游标 i 和 j ，分别指向arr[p..q]和arr[q+1..r]的第一个元素。比较这两个元素arr[i]和arr[j]，如果arr[i]&lt;=arr[j]，我们就把arr[i]放入到临时数组tmp，并且 i 后移一位，否则将arr[j]放入到数组tmp， j 后移一位。继续上述比较过程，直到其中一个子数组中的所有数据都放入临时数组中，再把另一个数组中的数据依次加入到临时数组的未尾，这个时候，临时数组中存储的就是两个子数组合并之后的结果了。最后再把临时数组tmp中的数据拷贝到原数组arr[p..r]中。 代码如下（C）： 1234567891011121314151617181920212223242526272829303132// 合并两个有序数组arr[p]-arr[q]、arr[q+1]-arr[r]，p为下标起点，q为下标中点，r为下标终点void __merge(int* arr, int p, int q, int r) &#123; int* tmp; int i, j, k; // 申请一个临时数组，大小与arr[p...r]相同 tmp = (int*)malloc((r - p + 1) * sizeof(int)); if (!tmp) &#123; abort(); &#125; // 循环判断两个数组中较小的数据，拷贝至临时数组 for (i = p, j = q + 1, k = 0; i &lt;= q &amp;&amp; j &lt;= r;) &#123; if (arr[i] &lt;= arr[j]) &#123; tmp[k++] = arr[i++]; &#125; else &#123; tmp[k++] = arr[j++]; &#125; &#125; // 判断哪个子数组有剩余数据 ，拷贝至临时数组中 if (i == q + 1) &#123; for (; j &lt;= r;) tmp[k++] = arr[j++]; &#125; else &#123; for (; i &lt;= q;) tmp[k++] = arr[i++]; &#125; // 将tmp数组在内存区直接复制到原数组中 memcpy(arr + p, tmp, (r - p + 1) * sizeof(int)); free(tmp);&#125; 归并排序的性能分析还记得分析排序算法的三个问题吗？接下来，我们来看归并排序的三个问题。 归并排序是稳定的排序算法吗？ 是。我们可以很明显看出，归并排序稳不稳定关键要看__merge()函数，也就是两个有序子数组合并成一个大的有序数组的那部分代码。在合并的过程中，如果arr[p..q]和arr[q+1..r]之间有值相同的元素，我们可以先把arr[p..q]中的元素（前部分中的元素）放入tmp数组。这样就保证了值相同的元素，在合并前后的先后顺序不变。所以，归并排序是一个稳定的排序算法。 归并排序的时间复杂度是多少？ 情况 时间复杂度 最好、最坏、平均情况 $O(n\log(n))$ 递归时间复杂度分析较复杂，初学者可以跳过。 回顾：递归的适用场景是，一个问题a可以分解为多个子问题b、c，那求解问题a就可以分解为求解问题b、c。问题b、c解决之后，我们再把b、c的结果合并成a的结果。 如果我们定义求解问题a的时间是T(a)，求解问题b、c的时间分别是T(b)和T(c)，那我们就可以得到这样的递推关系式： 1T(a) = T(b) + T(c) + K 其中K等于将两个子问题b、c的结果合并成问题a的结果所消耗的时间。 套用这个公式，我们来分析一下归并排序的时间复杂度。 我们假设对n个元素进行归并排序需要的时间是T(n)，那分解成两个子数组排序的时间都是T($\frac{n}{2}$)。我们知道，merge0函数合并两个有序子数组的时间复杂度是$O(n)$。所以，套用前面的公式，归并排序的时间复杂度的计算公式就是: 12T(1) = C； n=1 时，只需要常量级的执行时间，所以表示为 C。T(n) = 2*T(n/2) + n； n&gt;1 继续分解： 1234567T(n) = 2*T(n/2) + n = 2*(2*T(n/4) + n/2) + n = 4*T(n/4) + 2*n = 4*(2*T(n/8) + n/4) + 2*n = 8*T(n/8) + 3*n = 8*(2*T(n/16) + n/8) + 3*n = 16*T(n/16) + 4*n ...... = 2^k * T(n/2^k) + k * n ...... 通过这样一步一步分解推导，我们可以得到 ：$$T(n) = 2\cdot k \cdot T(\frac{n}{2^k}) + k\cdot n$$当 $T(\frac{n}{2^k}) = T(1)$时，也就是$\frac{n}{2^k} = 1$，我们得到 $k = log_2(n)$。们将k值代入上面的公式，得到 $T(n) = c \cdot n + n \cdot \log_2(n)$ 。如果我们用大O标记法来表示的话，T(n)就等于$O(n\log(n))$。所以归并排序的时间复杂度是$O(n\log(n))$。 归并排序的空间复杂度是多少？ 归并排序的空间复杂度$O(n)$。不是原地排序算法。 因为归并排序的合并函数，在合并两个有序数组为一个有序数组时，需要借助额外的存储空间。合并完成之后，临时开辟的内存空间就被释放掉了。临时内存空间最大也不会超过n个数据的大小，所以空间复杂度是$O(n)$。 快速排序（Quick Sort）快速排序算法（Quicksort），简称为“快排”。快排利用的也是分治思想。 快排的思想是这样的：如果要排序数组中下标从p到r之间的一组数据arr[p..r]，我们选择p到r之间的任意一个数据作为pivot（分区点）。遍历p到r之间的数据，将小于pivot的放到左边，将大于pivot的放到右边，将pivot放到中间。经过这一步骤之后，数组p到r之间的数据就被分成了三个部分，前面p到q-1之间都是小于pivot的（arr[p..q-1] &lt; pivot），中间是pivot，后面的q+1到r之间是大于pivot的（arr[p..q-1] &gt;= pivot）。 根据分治、递归的处理思想，我们可以用递归排序下标从p到q-1之间的数据和下标从q+1到r之间的数据，直到区间缩小为1，就说明所有的数据都有序了。如果我们用递推公式来将上面的过程写出来的话，就是这样： 12345递推公式：quick_sort(p…r) = quick_sort(p…q-1) + quick_sort(q+1, r)终止条件：p &gt;= r 翻译成代码(C)就是 : 12345678910111213// 快速排序递归函数，p，r为下标void _quick_sort(int* arr, int p, int r) &#123; // q为分区点下标 int q; if (p &gt;= r) &#123; return; &#125; // 获取分区点,对两个分区再快排 q = _quick_partition(arr, p, r); _quick_sort(arr, p, q - 1); _quick_sort(arr, q + 1, r);&#125; 归并排序中有一个 __merge()合并函数，我们这里有一个_quick_partition()分区函数。_quick_partition()分区函数实际上我们前面已经讲过了，就是随机选择一个元素作为pivot（一般情况下，可以选择p到r区间的最后一个元素），然后对arr[p..r]分区，函数返回pivot的下标。如果我们不考虑空间消耗的话，_quick_partition()分区函数可以写得非常简单。我们申请两个临时数组X和Y，遍历arr[p..r]，将小于pivot的元素都拷贝到临时数组X，将大于pivot的元素都拷贝到临时数组Y，最后再将数组X和数组Y中数据顺序拷贝到arr[p..r]。 但是，如果按照这种思路实现的话，_quick_partition()函数就需要很多额外的内存空间，所以快排就不是原地排序算法了。如果我们希望快排是原地排序算法，那它的空间复杂度得是$O(1)$，那_quick_partition()分区函数就不能占用太多额外的内存空间，我们就需要在arr[p..r]的原地完成分区操作。 这里先给出伪代码 123456789101112partition(A, p, r) &#123; pivot := A[r] i := p for j := p to r-1 do &#123; if A[j] &lt; pivot &#123; swap A[i] with A[j] i := i+1 &#125; &#125; swap A[i] with A[r] return i&#125; 这里的思想类似于选择排序。我们通过游标 i把arr[p..r-1]分成两部分。arr[p..i-1]的元素都是小于pivot的，我们暂且叫它“已处理区间“，arr[i..r-1]是“未处理区间“。我们每次都从未处理的区间arr[i..r-1]中取一个元素arr[j]，与pivot对比，如果小于pivot，则将其加入到已处理区间的尾部，也就是A[i]的位置。数组的插入操作还记得吗？在数组某个位置插入元素，需要搬移数据，非常耗时。当时我们也讲了一种处理技巧，就是交换，在$O(1)$的时间复杂度内完成插入操作。这里我们也借助这个思想，只需要将arr[i]与arr[j]交换，就可以在$O(n)$时间复杂度内将arr[j]放到下标为i的位置。 翻译成代码（C）： 12345678910111213141516171819202122232425262728// 交换元素void swap(int* a, int* b) &#123; int tmp = *a; *a = *b; *b = tmp;&#125;// 分区函数，返回分区点下标,取a[r]为pivotint _quick_partition(int* a, int p, int r) &#123; // i将数组分成已处理区间（arr[p]--arr[i-1]）和 // 未处理区间(arr[i]--arr[r-1]) // j遍历arr[p]--arr[r-1] int i,j; i = j = p; for (; j &lt; r ; j++) &#123; // 为方便起见，取a[r]为pivot if (a[j] &lt; a[r]) &#123; if (i != j) &#123; swap(a + i, a + j); &#125; i++; &#125; &#125; swap(a + r, a + i); return i;&#125; 快速排序的性能分析 快速排序是稳定的排序算法吗？ 不是，分区函数采用交换的方式，不是稳定的排序算法。 快速排序的空间复杂度是多少？ 空间复杂度$O(1)$，分区函数采用交换的方式，不需要额外的空间。 快速排序的时间复杂度是多少？ 情况 数组 时间复杂度 最坏情况 已有序 $O(n^2)$ 最好情况、平均情况 $O(n\log(n))$ 快排也是用递归来实现的。对于递归代码的时间复杂度，可以用之前的公式来分析。 12T(1) = C； n=1 时，只需要常量级的执行时间，所以表示为 C。T(n) = 2*T(n/2) + n； n&gt;1 但是，公式成立的前提是每次分区操作，我们选择的pivot都很合适，正好能将大区间对等地一分为二。但实际上这种情况是很难实现的。我举一个比较极端的例子。如果数组中的元素原来已经是有序的了，比如1，3，5，6，8。如果我们每次选择最后一个元素作为pivot，那每次分区得到的两个区间都是不均等的。我们需要进行大约n次分区操作，才能完成快排的整个过程。每次分区我们平均要扫描大约n/2个元素，这种情况下，快排的时间复杂度就从$O(n\log(n))$退化成了$O(n^2)$。我们刚刚讲了两个极端情况下的时间复杂度，一个是分区极其均衡，一个是分区极其不均衡。它们分别对应快排的最好情况时间复杂度和最坏情况时间复杂度。那快排的平均情况时间复杂度是多少呢？我们可以继续套用递归时间复杂度的公式进行求解。因为这边平均情况下的递推过程非常复杂，这里直接给出结论:T(n)在大部分情况下的时间复杂度都可以做到$O(n\log(n))$，只有在极端情况下，才会退化到$O(n^2)$。 解答开篇回到开篇的问题：如何用快排思想在$O(n)$内查找第K大元素？比如，4，2，5，12，3这样一组数据，第3大元素就是4，如何快速地找到它。 快排核心思想就是分治和分区，我们可以利用分区的思想，来解答开篇的问题。我们选择数组区间arr[0..n-1]的最后一个元素arr[n-1]作为pivot，对数组arr[0..n-1]原地分区，这样数组就分成了三部分，arr[0.…p-1]、arr[p]以及arr[p+1..n-1]。 如果p + 1 = K，那arr[p]就是要求解的元素；如果K &gt; p + 1，说明第K大元素出现在arr[p+1..n-1]区间，我们再按照上面的思路递归地在arr[p+1..n-1]这个区间内查找。同理，如果K &lt; p + 1，那我们就在arr[0..p-1]区间查找。 我们再来分析下这样查找的时间复杂度。 第一次分区查找，我们需要对大小为n的数组执行分区操作，需要遍历n个元素；第二次分区查找，我们只需要对大小为 $\frac{n}{2}$ 的数组执行分区操作，需要遍历$\frac{n}{2}$个元素。依次类推，分区遍历元素的个数分别为、$\frac{n}{2}$、$\frac{n}{4}$、$\frac{n}{8}$、$\frac{n}{16}$…..直到区间缩小为1。如果我们把每次分区遍历的元素个数加起来，就是：$$n + \frac{n}{2} + \frac{n}{4} + \frac{n}{8} + .. + 1$$这是一个等比数列求和，最后的和等于$2n-1$ 。所以，上述解决思路的时间复杂度就为$O(n)$。你可能会说，我有个很笨的办法，每次取数组中的最小值，将其移动到数组的最前面，然后在剩下的数组中继续找最小值，以此类推，执行K次，找到的数据不就是第K大元素了吗？不过，时间复杂度就并不是$O(n)$了，而是 $O(K \cdot n)$ 。你可能会说，时间复杂度前面的系数不是可以忽略吗？$O(K \cdot n)$ 不就等于$O(n)$吗？这个可不能这么简单地划等号。当K是比较小的常量时，比如1、2，那最好时间复杂度确实是 $O(n)$ ；但当K等于n/2或者n时，这种最坏情况下的时间复杂度就是 $O(n^2)$ 了。 小结归并排序和快速排序是两种稍微复杂的排序算法，它们用的都是分治的思想，代码都通过递归来实现，过程非常相似。理解归并排序的重点是理解递推公式和merge0合并函数。同理，理解快排的重点也是理解递推公式，还有 partition0分区函数。 归并排序算法是一种在任何情况下时间复杂度都比较稳定的排序算法，这也使它存在致命的缺点，即归并排序不是原地排序算法，空间复杂度比较高，是$O(n)$。正因为此，它也没有快排应用广泛。快速排序算法虽然最坏情况下的时间复杂度是$O(n^2)$ ，但是平均情况下时间复杂度都是$O(n\log(n))$。不仅如此，快速排序算法时间复杂度退化到$O(n^2)$的概率非常小，我们可以通过合理地选择pivot来避免这种情况。 归并排序和快速排序的区别，归并排序的处理过程是由下到上的，先处理子问题，然后再合并。而快排正好相反，它的处理过程是由上到下的，先分区，然后再处理子问题。 思考题现在你有10个接口访问日志文件，每个日志文件大小约300MB，每个文件里的日志都是按照时间戳从小到大排序的。你希望将这10个较小的日志文件，合并为1个日志文件，合并之后的日志仍然按照时间戳从小到大排列。如果处理上述排序任务的机器内存只有1GB，你有什么好的解决思路，能“快速”地将这10个日志文件合并吗？]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法-1：插入、冒泡、选择]]></title>
    <url>%2F2019%2F06%2F17%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%2Falgo-sort-1%2F</url>
    <content type="text"><![CDATA[排序算法可以说是一项基本功，也是大部分程序员学习的第一个算法，一个优秀的算法可以节省大量的资源。目前大部分编程语言都提供了排序函数，但分析理解各种排序算法的特性，结合各个领域中考虑到数据的各种限制和规范，往往能够分析推理一个符合实际的优秀算法。 排序算法太多了，我们将其按照时间复杂度分为3类，分3篇文章进行分析。 注：以下排序均以升序为例 排序算法 时间复杂度 是否基于比较 冒泡、插入、选择 $O(n^2)$ √ 快排、归并 $O(nlogn)$ √ 桶、计数、基数 $O(n)$ × 如何分析一个“排序算法”排序算法的执行效率 最好情况、最坏情况、平均情况的时间复杂度我们在分析算法时，往往需要对最好情况、最坏情况、平均情况进行区分，并且分析对应情况下的时间复杂度。 时间复杂度的系数、常数、低阶时间复杂度反应的是n极大情况下的时间增长趋势，而实际软件开发中，我们需要排序的往往只有10个、20个、100个这种数据。在小规模数据排序情况下，时间复杂度同阶的算法进行对比时，系数、常数、低阶的影响还是比较大的，往往需要进行分析。 比较次数和交换（移动）次数基于比较的排序算法，在执行过程中会涉及到两种操作：一是比较元素的大小，二是元素交换和移动。所以分析排序算法执行效率时，需要考虑元素的比较以及移动次数。 排序算法的内存消耗算法的内存消耗可以通过空间复杂度衡量。针对排序算法，有一个原地排序（Sorted in place）的概念。原地排序，即空间复杂度为$O(1)$的排序算法。本篇的冒泡、插入、选择排序皆为原地排序。 排序算法的稳定性针对排序算法，还有一个重要的指标：稳定性。指的是：待排列的序列（数组）中存在值相等的元素，而这些相等元素经过排序后，相等元素之间原有的顺序是否改变，若不变，则称排序算法稳定，若改变了，不稳定。 冒泡排序（Buddle Sort）冒泡排序只操作相邻的两个元素，每次冒泡操作都会对相邻的两个元素进行比较，根据大小关系，决定是否互换两个元素。一次冒泡操作会至少让一个元素放到正确的位置上，重复n-1次冒泡操作，就完成了n个元素的排序。 以升序为例，假设有一个整型数组a[] = {5，4，6，3，2，1}，第一次冒泡会先对a[0]和a[1]进行比较，即对5和4比较，5比4大，互换元素，此时a[] = {4,5,6,3,2,1}；紧接着再对a[1]和a[2]进行比较，即5和6比较，5比6小，不互换a不变；再对a[2]和a[3]进行比较，6比3大，互换…以此类推，第一次冒泡完成后，数组为a[] = {4,5,3,2,1,6}，其中最大的元素6已经放到了正确的位置上。我们只需要重复n-1次冒泡操作（外层循环次数n-1）即可完成排序。而第二次冒泡时，因为最后一个元素已经正确，我们无需理会，只需要比较前n-1个元素即可，同理，第k次循环只需比较前n-k个元素（内层循环次数n-k）。 代码如下（C++）： 1234567891011121314151617// 冒泡排序，a为数组，n表示数组大小void bubbleSort(int* a, int n) &#123; if (n &lt;= 1) &#123; return; &#125; // 长度为n的数组，需执行n-1次冒泡循环（0到n-2，为方便数组操作，下标从0开始） for (int i = 0; i &lt; n - 1; i++) &#123; // 第k次循环需比较前n-k个元素（k=i+1） for (int j = 0; j &lt; n - i - 1; j++) &#123; if (a[j] &gt;a[j+1]) &#123; // 交换操作 int tmp = a[j]; a[j] = a[j + 1]; a[j + 1] = tmp; &#125; &#125; &#125;&#125; 优化：当某次冒泡操作时，已经没有数据交换，说明序列已经有序，不需要继续执行后续的冒泡操作，可以设置一个标志位提前退出冒泡循环。 代码如下（C++）： 1234567891011121314151617181920212223// 冒泡排序，a为数组，n表示数组大小void bubbleSort(int* a, int n) &#123; if (n &lt;= 1) &#123; return; &#125; // 长度为n的数组，需执行n-1次冒泡循环（0到n-2，为方便数组操作，下标从0开始） for (int i = 0; i &lt; n - 1; i++) &#123; // 提前退出循环的标志位 bool flag = false; // 第k次循环需比较前n-k个元素（k=i+1） for (int j = 0; j &lt; n - i - 1; j++) &#123; if (a[j] &gt;a[j+1]) &#123; // 交换操作 int tmp = a[j]; a[j] = a[j + 1]; a[j + 1] = tmp; flag = true; // 表示存在元素交换 &#125; &#125; if (!flag) &#123; // 不存在元素交换，提前退出 break; &#125; &#125;&#125; 现在，结合排序算法的分析，有三个问题 三个问题 是原地排序吗？ 是，冒泡排序仅涉及相邻元素交换操作，只需常量级临时空间，所以空间复杂度为$O(1)$。 是稳定的排序吗？ 是，冒泡排序时交换元素改变顺序，在元素相同的情况下，可以不做交换，所以冒泡排序是稳定的排序算法。 时间复杂度是多少？ 情况 原始数据展示 时间复杂度 最好情况 {1,2,3,4,5,6} $O(n)$ 最坏情况 {6,5,4,3,2,1} $O(n^2)$ 平均情况 {6,3,2,1,4,5} $O(n^2)$ 最好情况下，需要排序的原序列已经有序，只需进行一次冒泡操作就可以结束，所以时间复杂度为：$O(n)$。 最坏情况下，需要排序的原序列是倒序，需要进行n次冒泡操作，所以时间复杂度为为：$O(n^2)$。 平均情况下，我们可以采用 逆序度 的方式进行分析。 冒泡排序包含两个操作：比较和交换，每交换一次，逆序度减一，所以逆序度表示了原序列到有序序列需要交换的次数，最好情况下逆序度为0，最坏情况下逆序度为$\frac{n \times (n - 1) }{2}$。平均情况我们可以取一个中间值$\frac{n \times (n+1) }{4}$。比较操作肯定比交换操作要多，而复杂度上限为$O(n^2)$，所以平均情况下的时间复杂度就是$O(n^2)$。 插入排序（Insertion Sort）假设已经有一个有序序列，现在需要往其中添加一个新元素，要求添加后仍然有序，该如何操作呢？只需要遍历原有的有序数组，找到新元素应该插入的位置插入即可，插入排序就是这么来的。 首先，我们将序列中的元素分成两个区间：已排序区间以及未排序区间，当然，初始状态下，已排序区间只有一个元素，即第一个元素，插入排序的思维就是取一个未排序区间的数，在已排序区间内找到合适的位置插入，并且保证已排序区间一直有序，直到未排序区间内没有元素，此时排序完成。 插入排序也包含两种操作：元素的比较和元素的交换。对于不同的查找插入点的方法（从头到尾、从尾到头），元素的比较次数是不一样的，而元素的移动次数都是相同的，等于序列的逆序度。 代码如下（C++） 1234567891011121314151617181920// 插入排序 a 表示数组，n 表示数组大小void insertionSort(int* a, int n) &#123; if (n &lt;= 1) &#123; return; &#125; // 先将a[0]看成已排序区间，所以未排序区间从a[1]开始 for (int i = 1; i &lt; n; i++) &#123; int value = a[i]; // j表示需元素需插入的位置，范围[0,i],a[i]为元素原位置，所以从a[i-1]开始比较 int j = i - 1; for (; j &gt;= 0; j--) &#123; if (a[j] &gt; value) &#123; // 若a[j]&gt;a[i],a[j]元素后移一位 a[j + 1] = a[j]; &#125; else &#123; // 若a[j]&lt;=a[i],即a[j+1]为元素需要插入位置 break; &#125; &#125; a[j + 1] = value; &#125;&#125; 还是三个问题 是原地排序吗？ 是，插入排序不需要额外的存储空间（可以将代码中value直接替换成a[i]，增加value是为了代码更容易看懂），所以空间复杂度为$O(1)$，即，插入排序是原地排序算法。 是稳定的排序吗？ 是，插入排序不需要额外的存储空间（可以将代码中value直接替换成a[i]，增加value是为了代码更容易看懂），所以空间复杂度为$O(1)$，即，插入排序是原地排序算法。 时间复杂度是多少？ 情况 原始数据 时间复杂度 最好情况 已有序 $O(n)$ 最坏情况 倒序 $O(n^2)$ 平均情况 $O(n^2)$ 最好情况下，因为采用的是从尾到头遍历有序数据，所以在第一次比较时就会跳出内层循环。因此不需要搬移任何数据，每次比较一个数据就能确定插入位置。所以最好情况下的时间复杂度为$O(n)$。 最坏情况下，序列倒序，相当于每次插入都需要移动大量元素（i个元素）。所以最坏情况的时间复杂度为$O(n^2)$。 平均情况下，因为我们在数组中插入一个元素的平均时间复杂度为$O(n)$，插入排序每次插入都相当于在数组中插入一个元素，重复了n次插入的过程，所以时间复杂度为$O(n^2)$。 选择排序（Selection Sort）选择排序的思想类似于插入排序，将序列分为已排序区间和未排序区间。但选择排序每次都会从未排序区间内寻找最小的元素，放到已排序区间的末尾（交换操作）。所以重复n-1次操作后，序列即有序。 代码如下： 123456789101112131415161718192021// 选择排序 a 表示数组，n 表示数组大小void selectionSort(int* a, int n) &#123; if (n &lt;= 1) &#123; return; &#125; for (int i = 0; i &lt; n - 1; i++) &#123; // 先默认第i个元素为当前最小元素 int minPos = i; int minValue = a[i]; // 因为默认最小为a[i],所以从a[i+1]开始比较寻找最小元素 int j = i + 1; for (; j &lt; n; j++) &#123; if (a[j] &lt; minValue) &#123; // 若a[j]元素比当前最小元素小，则标记a[j]为当前最小元素 minValue = a[j]; minPos = j; &#125; &#125; a[minPos] = a[i]; a[i] = minValue; &#125;&#125; 依旧三个问题 是原地排序吗？ 是，选择排序空间复杂度为 O(1)，是一种原地排序算法。 是稳定的排序吗？ 否，选择排序每次都要找剩余未排序元素中的最小值，并和前面的元素交换，这样破坏了稳定性。 举例：{5,2,3,4,5,1} 第一次操作会将第一个元素5和最后一个元素1交换，这样，两个5的顺序就变了，所以就不稳定。 时间复杂度是多少？ 情况 时间复杂度 最好、最坏、平均情况 $O(n^2)$ 所有情况下，选择排序的时间复杂度均为$O(n^2)$，因为选择排序在任何情况下，遍历的次数都是固定的，第一次循环对n-1个元素执行比较操作；第k次循环，对n-k个元素执行比较操作，总共需要比较(n-1) + (n-2) + ... + 2，即$\frac{(n - 2) \times (n + 1) }{2}$次，所以选择排序时间复杂度恒为$O(n^2)$。 解答开篇回到开篇的问题：冒泡排序和插入排序的时间复杂度都是$O(n^2)$，都是原地排序算法，都稳定，为什么插入排序比冒泡排序更受欢迎呢？ 前面我们分析到：冒泡排序不管怎么买优化，元素交换的次数都是固定值，等于原始序列的逆序度；同样的，插入排序不管怎么优化，元素移动的次数也是原始序列的逆序度。 但是，从代码实现上来看，冒泡排序的元素交换要比插入排序的元素移动复杂，冒泡排序需要3个赋值操作，而插入排序只需要一个。 代码如下： 1234567891011121314冒泡排序中数据的交换操作：if (a[j] &gt; a[j+1]) &#123; // 交换 int tmp = a[j]; a[j] = a[j+1]; a[j+1] = tmp; flag = true;&#125;插入排序中数据的移动操作：if (a[j] &gt; value) &#123; a[j+1] = a[j]; // 数据移动&#125; else &#123; break;&#125; 因此，虽然两者的时间复杂度一致，但如果追求极致的性能优化，肯定首选插入排序。而且，插入排序的算法思想有很大的优化空间，比如希尔排序。 小结分析排序算法三个方面 执行效率、内存消耗、稳定性 排序算法总结 排序算法 是否原地排序 是否稳定 最好 最坏 平均 冒泡排序 是 是 $O(n)$ $O(n^2)$ $O(n^2)$ 插入排序 是 是 $O(n)$ $O(n^2)$ $O(n^2)$ 选择排序 是 否 $O(n^2)$ $O(n^2)$ $O(n^2)$ 冒泡排序、选择排序实际开发应用并不多，但插入排序还是很有用的，有些编程语言的排序函数的实现原理就用到了插入排序算法。 思考题这三种排序算法数据如果存储在链表中，排序算法还能工作吗，如果能，那时间复杂度、空间复杂度又是多少？]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序算法</tag>
      </tags>
  </entry>
</search>
