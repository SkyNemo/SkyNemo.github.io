<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[iptables 常用操作-基础]]></title>
    <url>%2F2021%2F03%2F22%2FLinux%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2Fiptables_common_operations%2F</url>
    <content type="text"><![CDATA[简介拓扑 表iptables为我们预定义了4张表，它们分别是raw表、mangle表、nat表、filter表，不同的表拥有不同的功能 filter表 : 负责过滤功能，防火墙；内核模块：iptables_filter nat表 : network address translation，网络地址转换功能；内核模块：iptable_nat mangle表 : 拆解报文，做出修改，并重新封装 的功能；iptable_mangle raw表 : 关闭nat表上启用的连接追踪机制；iptable_raw 也就是说，我们自定义的所有规则，都是这四种分类中的规则，或者说，所有规则都存在于这4张”表”中。 链 本文主要涉及filter表，INPUT、OUTPUT链 raw 表中的规则可以被哪些链使用：PREROUTING，OUTPUT mangle 表中的规则可以被哪些链使用：PREROUTING，INPUT，FORWARD，OUTPUT，POSTROUTING nat 表中的规则可以被哪些链使用：PREROUTING，OUTPUT，POSTROUTING（centos7中还有INPUT，centos6中没有） filter 表中的规则可以被哪些链使用：INPUT，FORWARD，OUTPUT 匹配和处理我们在实际的使用过程中，往往是通过”表”作为操作入口，对链的规则进行定义，规则包含 匹配条件 和 处理动作 两个部分，其中匹配条件用于筛选数据包，处理动作决定数据包走向或者对数据包信息进行变更，常用处理动作如下： 本文主要涉及：ACCEPT、DROP、REJECT三个动作 ACCEPT : 允许数据包通过 DROP : 直接丢弃数据包，不给任何回应信息，这时候客户端会感觉自己的请求泥牛入海了，过了超时时间才会有反应 REJECT : 拒绝数据包通过，必要时会给数据发送端一个响应的信息，客户端刚请求就会收到拒绝的信息 SNAT: 源地址转换，解决内网用户用同一个公网地址上网的问题 MASQUERADE : 是SNAT的一种特殊形式，适用于动态的、临时会变的ip上 DNAT : 目标地址转换 REDIRECT : 在本机做端口映射 LOG : 在/var/log/messages文件中记录日志信息，然后将数据包传递给下一条规则，也就是说除了记录以外不对数据包做任何其他操作，仍然让下一条规则去匹配 查看规则配置1234567891011121314151617181920212223# 查看filter表的规则iptables -t filter -L# -t默认为filteriptables -L# 显示详细信息: -viptables -vL INPUT# 使用IP而非域名: -niptables -vnL INPUT# 详细信息使用精确值: -xiptables -vnxL INPUT###### 推荐使用 ####### 显示行号: --lineiptables --line -vnL INPUT # 同理，查看raw、magle、nat表的规则如下iptables -t raw -Liptables -t mangle -Liptables -t nat -L 规则管理设置默认规则12345# 语法：iptables -t 表名 -P 链名 动作(策略)# -P 链名 动作: 设置该链默认策略# 示例，将filter表中的INPUT链默认策略设置为DROPiptables -t filter -P FORWARD DROP 添加规则12345678910# 语法: iptables -t 表名 -A 链名 匹配条件 -j 动作# -A: 在指定表指定链 尾部 添加规则iptables -t filter -A INPUT -s 192.168.1.146 -j DROP# -I: 在指定表指定链 首部 添加规则iptables -t filter -I INPUT -s 192.168.1.147 -j ACCEPT# -I 链名 序号: 在指定表指定链 指定序号位置 添加规则iptables -t filter -I 2 INPUT -s 192.168.1.148 -j REJECT 删除规则删除指定规则12345# 语法: iptables -t 表名 -D 链名 规则序号# -D 链名 序号: 删除指定序号位置的规则# 示例: 删除filter表中INPUT链中序号为3的规则iptables -t filter -D INPUT 3 清空所有规则12345# 语法: iptables -t 表名 -F 链名# -F 链名: 清空对应链下所有规则# 示例: 清空INPUT链下所有规则iptables -t filter -F INPUT 保存规则12345# centos 6service iptables save# 上述命令无法使用时iptables-save &gt; /etc/sysconfig/iptables 匹配条件条件一：匹配源地址 : -s1234567891011# 匹配多个IP地址，中间使用逗号隔开# 示例: 对源地址为 192.168.1.111 和 192.168.1.119 报文执行丢弃策略iptables -t filter -I INPUT -s 192.168.1.111,192.168.1.119 -j DROP # 匹配IP地址段# 示例: 对源地址属于 192.168.2.0/24 网段的报文执行拒绝策略iptables -t filter -I INPUT -s 192.168.2.0/24 -j REJECT# 匹配条件取反# 示例: 对源地址不是 192.168.1.0/24 网段的报文执行丢弃操作iptables -t filter -I INPUT ! -s 192.168.1.0/24 -j DROP 条件二：匹配目的地址 : -d1234567891011# 匹配多个IP地址，中间使用逗号隔开# 示例: 对目的地址为 192.168.1.121 和 192.168.1.129 报文执行丢弃策略iptables -t filter -I INPUT -s 192.168.1.121,192.168.1.129 -j DROP # 匹配IP地址段# 示例: 对目的地址属于 192.168.3.0/24 网段的报文执行拒绝策略iptables -t filter -I INPUT -s 192.168.3.0/24 -j REJECT# 匹配条件取反# 示例: 对目的地址不是 192.168.1.0/24 网段的报文执行丢弃策略iptables -t filter -I INPUT ! -s 192.168.1.0/24 -j DROP 条件三：匹配协议类型 : -p123456789# 示例: 对源地址为 192.168.1.150 的 tcp 报文执行接收策略iptables -t filter -I INPUT -p tcp -s 192.168.1.150 -j ACCEPT# 示例: 对源地址不是 192.168.1.150 的 udp 报文执行接收策略iptables -t filter -I INPUT -p udp -s 192.168.1.150 -j ACCEPT# 可选匹配类型 # centos6: tcp、udp、udplite、icmp、esp、ah、sctp# centos7新增: icmpv6、mh 条件四：匹配网卡接口 : -i 和 -o1234567891011121314# -i: 匹配报文是从哪个网卡接口流入本机# 示例: 对从 eth0 网络接口 进入 的 icmp 报文执行丢弃策略iptables -t filter -I INPUT -p icmp -i eth0 -j DROP# 示例: 对不是从 eth0 网络接口 进入 的 icmp 报文执行丢弃策略iptables -t filter -I INPUT -p icmp ! -i eth0 -j DROP# -o: 匹配报文是从哪个网卡接口流出本机# 示例: 对从 eth0 网络接口 流出 的 icmp 报文执行丢弃策略iptables -t filter -I INPUT -p icmp -o eth0 -j DROP# 示例: 对不是从 eth0 网络接口 流出 的 icmp 报文执行丢弃策略iptables -t filter -I INPUT -p icmp ! -o eth0 -j DROP 扩展匹配模块 扩展模块由 -m 指定 tcp扩展模块 : 匹配连续端口1234567891011121314# -p tcp -m tcp --dport num1:num2 : 匹配tcp协议报文，并且目的端口在 num1 到 num2 一段连续的端口范围的报文# 示例: 匹配源地址为 192.168.1.150 发起的，目的端口为22到80端口范围的报文，执行拒绝策略iptables -t filter -I INPUT -s 192.168.1.150 -p tcp -m tcp --dport 22:80 -j REJECT# 示例: 匹配源地址为 192.168.1.150 发起的，目的端口不在22到80端口范围的报文，执行拒绝策略iptables -t filter -I INPUT -s 192.168.1.150 -p tcp -m tcp ! --dport 22:80 -j REJECT# -p tcp -m tcp --sport num1:num2 : 匹配tcp协议报文，并且源端口在 num1 到 num2 一段连续的端口范围的报文# 示例: 匹配源地址为 192.168.1.150 发起的，源端口为22到80的端口范围的报文，执行拒绝策略iptables -t filter -I INPUT -s 192.168.1.150 -p tcp -m tcp --sport 22:80 -j REJECT# 示例: 匹配源地址为 192.168.1.150 发起的，源端口不在22到80范围的报文，执行拒绝策略iptables -t filter -I INPUT -s 192.168.1.150 -p tcp -m tcp ! --sport 22:80 -j REJECT multiport模块 : 匹配多个端口（离散或连续） multiport可用于tcp和udp 123456789# -p tcp -m multiport --dports port1,port2:port3 : 用于匹配报文的目的端口，可以匹配离散和连续的多个端口# 示例: 匹配源地址为192.168.1.150，并且目的端口为22,80到8080的tcp报文，执行拒绝策略iptables -t filter -I INPUT -s 192.168.1.150 -p tcp -m multiport --dport 22,80:8080 -j REJECT# -p udp -m multiport --sports port1,port2:port3 : 用于匹配报文的源端口，可以匹配离散和连续的多个端口# 示例: 匹配源地址为192.168.1.150，并且源端口为53,900到1000的udp报文，执行拒绝策略iptables -t filter -I INPUT -s 192.168.1.150 -p udp -m multiport --sport 53,900:1000 -j REJECT iprange模块 : 匹配连续的IP地址123456789# -m iprange --src-range ip1-ip2 : 匹配源地址IP范围# 示例: 匹配源地址在192.168.1.140至192.168.1.150范围内的报文，执行丢弃策略iptables -t filter -I INPUT -m iprange --src-range 192.168.1.140-192.168.1.150 -j DROP# -m iprange --dst-range ip1-ip2 : 匹配目的地址IP范围#示例: 匹配目的地址不在192.168.1.140至192.168.1.150范围内的报文，执行丢弃策略iptables -t filter -I INPUT -m iprange ! --dst-range ! 192.168.1.140-192.168.1.150 -j DROP string模块 : 匹配字符串123# -m string --algo bm/kmp --string "OOXX" : 匹配报文中含有 "OOXX" 字符串，算法bm/kmp选一即可# 示例 : 匹配目的端口为5060的tcp报文，并且报文中包含字符串 "OOXX" ，执行拒绝操作iptables -t filter -I INPUT -p tcp --dport 5060 -m string --algo bm --string "OOXX" -j REJECT time模块 : 匹配时间123456789101112131415# -m time --timestart 09:00:00 --timestop 19:00:00 : 匹配从 09:00:00 到 19::00:00 时间范围内的报文，不可取反# 示例: 每天 09:00:00 到 19::00:00，80端口不对外发报文iptables -t filter -I OUTPUT -p tcp --dport 80 -m time --timestart 09:00:00 --timestop 19:00:00 -j REJECT# -m time --datestart 2021-03-21 --datestop 2021-04-20 : 匹配从 2021-03-21 到 2021-04-20 日期范围内的报文，不可取反# 示例: 从 2021-03-21 到 2021-04-20，端口80不对外发报文iptables -t filter -I OUTPUT -p tcp --dport 443 -m time --datestart 2021-03-21 --datestop 2021-04-20 -j REJECT# -m time --weekdays 6,7 : 匹配星期六、星期天的报文；可取反# 示例: 每周六、周天不接受来自192.168.1.150的报文iptables -t filter -I INPUT -s 192.168.1.150 -m time --weekdays 6,7 -j DROP# -m time --monthdays 2,3,5,7 : 匹配每个月的2、3、5、7日；可取反# 每个月非 2,3,5,7 日，80端口丢弃tcp报文iptables -t filter -I INPUT -p tcp --dport 80 -m time ! --monthdays 2,3,5,7 -j DROP limit模块 : 限制报文速率12345# -m limit --limit-burst 3 --limit 10/minute : 每分钟放行10个icmp报文，即每6秒放行一个，空闲时最多同时放行三个icmp报文# 时间单位: /second /minute /hour /day# 示例 : 每分钟放行10个icmp报文，即每6秒放行一个，空闲时最多同时放行三个icmp报文iptables -t filter -I INPUT -p icmp -m limit --limit-burst 3 --limit 10/minute -j ACCEPTiptables -t filter -A INPUT -p icmp -j REJECT 常用操作1234# 放行192.168.1.0/24网段访问端口22（ssh服务，tcp端口），拒绝其他地址访问22端口iptables -t filter -I INPUT -s 192.168.1.0/24 -p tcp --dport 22 -j ACCEPTiptables -t filter -A INPUT -p tcp --dport 22 -j REJECTservice iptables save]]></content>
      <categories>
        <category>Linux系统管理</category>
      </categories>
      <tags>
        <tag>Linux系统管理</tag>
        <tag>Linux防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 网络接口bond配置]]></title>
    <url>%2F2021%2F03%2F21%2FLinux%E5%9F%BA%E7%A1%80%2Fcentos_network_bonding%2F</url>
    <content type="text"><![CDATA[简介bond 7种模式简介bonding是一种Linux系统下的网卡绑定技术，可以把服务器上n个物理网卡在系统内部抽象（绑定）成一个逻辑上的网卡，能够提升网络吞吐量、实现网络冗余、负载等功能；bond支持7种模式，如下 mode=0，(balance-rr) Round-robin policy（平衡轮循环策略） 传输的数据包按顺序依次送达各个网络接口 mode=1，(active-backup) Active -backup policy（主-备份策略） 提高了网络可靠性，但资源利用率较低，同时只有一个网络接口在工作中 mode=2，(balance-xor) XOR policy（平衡策略） 基于指定的传输HASH策略传输数据包，缺省策略为：(源MAC地址 XOR 目标MAC地址) % slave数量；提供可靠性同时提高了网络带宽 mode=3，(broadcast)（广播策略） 在每个slave接口上传输每个数据包，此模式提供可靠性 mode=4，(802.3ad) IEEE 802.3ad Dynamic link aggregation（IEEE 802.3ad 动态链接聚合） 根据802.3ad协议策略分发流量，即LACP模式 mode=5，(balance-tlb) Adaptive transmit load balancing（适配器传输负载均衡） 在每个slave上根据当前的负载（根据速度计算）分配外出流量。如果正在接受数据的slave出故障了，另一个slave接管失败的slave的MAC地址 mode=6，(balance-alb) Adaptive load balancing（适配器适应性负载均衡） 根据ARP对流量分发，与mode=0区别在于，mode=0的所有网口流量较均衡，而mode=6通常一个流量很高，其余流量很低 模式与交换机配置对应关系 网卡绑定模式 网卡绑定对应策略 可靠性 是否增加带宽 交换机对接方式 mode=0 balance-rr 无 是，均衡 配置手工模式链路聚合 mode=1 active-backup 有 无 配置对接接口属于同一个VLAN mode=2 balance-xor 有 是，由策略决定 配置手工模式链路聚合 mode=3 broadcast 有 无 建议每个端口分别连接一个交换机，且属于不同VLAN mode=4 802.3ad 有 是，由策略决定 配置LACP模式链路聚合 mode=5 balance-tlb 有 是，均衡 无需配置，建议每个端口分别连接一个交换机 mode=6 balance-alb 有 是，不均衡 无需配置，建议每个端口分别连接一个交换机 CentOS 6 配置bond123456789101112131415161718192021# 创建bond0接口配置文件[root@sophia ~]# vi /etc/sysconfig/network-scripts/ifcfg-bond0DEVICE=bond0TYPE=EthernetONBOOT=yesNM_CONTROLLED=noBOOTPROTO=staticUSERCTL=noIPADDR=192.168.1.161PREFIX=24GATEWAY=192.168.1.1DNS1=114.114.114.114BONDING_OPTS="mode=0 miimon=100"# USERCTL=no:普通用户无法控制网络接口# BONDING_OPTS="mode=0 miimon=100":配置bond模式为0，每100毫秒检测一次状态# 配置bond模式也可以在/etc/modprobe.d/bond0.conf配置# vi /etc/modprobe.d/bond0.conf# alias bond0 bonding# options bond0 miimon=100 mode=0 1234567891011121314151617181920212223242526272829# 创建或修改需要加入bond的网络接口配置文件[root@sophia ~]# vi /etc/sysconfig/network-scripts/ifcfg-eth0DEVICE=eth0HWADDR=00:0C:29:9F:B2:E9TYPE=EthernetUUID=bfe0eb65-6f66-45d6-adf7-37f1bfcfbeb2ONBOOT=yesNM_CONTROLLED=noBOOTPROTO=noneUSERCTL=noMASTER=bond0SLAVE=yes[root@sophia ~]# vi /etc/sysconfig/network-scripts/ifcfg-eth1DEVICE=eth1HWADDR=00:0C:29:9F:B2:F3TYPE=EthernetUUID=ec03f9e5-1c95-487c-9104-5e7238091c97ONBOOT=yesNM_CONTROLLED=noBOOTPROTO=noneUSERCTL=noMASTER=bond0SLAVE=yes# BOOTPROTO=none:不指定IP地址获取形式# MASTER=bond0:指定加入bond0# SLAVE=yes:指定该网络接口为bond的子接口 1234567891011121314151617181920212223242526272829# 重启网络[root@sophia ~]# service network restart# 查看bond状态[root@sophia ~]# cat /proc/net/bonding/bond0Ethernet Channel Bonding Driver: v3.7.1 (April 27, 2011)Bonding Mode: load balancing (round-robin)MII Status: upMII Polling Interval (ms): 100Up Delay (ms): 0Down Delay (ms): 0Slave Interface: eth0MII Status: upSpeed: 1000 MbpsDuplex: fullLink Failure Count: 0Permanent HW addr: 00:0c:29:9f:b2:e9Slave queue ID: 0Slave Interface: eth1MII Status: upSpeed: 1000 MbpsDuplex: fullLink Failure Count: 0Permanent HW addr: 00:0c:29:9f:b2:f3Slave queue ID: 0 CentOS 7 配置bond（手动）12345678910111213141516# 配置bond接口[root@alita ~]# vi /etc/sysconfig/network-scripts/ifcfg-bond0DEVICE=bond0TYPE=EthernetONBOOT=yesNM_CONTROLLED=noBOOTPROTO=staticUSERCTL=noIPADDR=192.168.1.171PREFIX=24GATEWAY=192.168.1.1DNS1=114.114.114.114BONDING_MASTER=yesBONDING_OPTS="mode=0 miimon=100"# TYPE=Ethernet 或者 TYPE=bond 均可 1234567891011121314151617# 配置两个slave接口[root@alita ~]# vi /etc/sysconfig/network-scripts/ifcfg-ens33TYPE="Ethernet"NAME="ens33"DEVICE="ens33"ONBOOT="yes"MASTER=bond0SLAVE=yes[root@alita ~]# vi /etc/sysconfig/network-scripts/ifcfg-ens37TYPE="Ethernet"NAME="ens37"DEVICE="ens37"ONBOOT="yes"MASTER=bond0SLAVE=yes 12345678910111213141516171819202122232425262728# 重启网卡[root@alita ~]# systemctl restart network# 查看bond状态[root@alita ~]# cat /proc/net/bonding/bond0Ethernet Channel Bonding Driver: v3.7.1 (April 27, 2011)Bonding Mode: load balancing (round-robin)MII Status: upMII Polling Interval (ms): 100Up Delay (ms): 0Down Delay (ms): 0Slave Interface: ens33MII Status: upSpeed: 1000 MbpsDuplex: fullLink Failure Count: 0Permanent HW addr: 00:0c:29:25:1f:98Slave queue ID: 0Slave Interface: ens37MII Status: upSpeed: 1000 MbpsDuplex: fullLink Failure Count: 0Permanent HW addr: 00:0c:29:25:1f:a2Slave queue ID: 0 CentOS 7 配置bond（nmcli）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091# 确认NetworkManager已经开启[root@alita ~]# systemctl status NetworkManager# 查看网络接口[root@alita ~]# nmcli c showNAME UUID TYPE DEVICE ens33 79fdf747-7a81-4dc4-b2e9-007a8e66aaf2 ethernet ens33 Wired connection 1 b48ea077-7ba0-3f66-9147-9fcca6caab5b ethernet ens37 # 使用nmcli创建bond接口[root@alita ~]# nmcli c add type bond ifname bond0 mode 0# 使用nmcli创建slave接口[root@alita ~]# nmcli con add type bond-slave ifname ens33 master bond0[root@alita ~]# nmcli con add type bond-slave ifname ens37 master bond0# 查看网络接口[root@alita ~]# nmcli c showNAME UUID TYPE DEVICE bond-bond0 41d50ded-1839-43aa-a4c2-9886fb642a35 bond bond0 ens33 79fdf747-7a81-4dc4-b2e9-007a8e66aaf2 ethernet ens33 Wired connection 1 b48ea077-7ba0-3f66-9147-9fcca6caab5b ethernet ens37 bond-slave-ens33 df3b0a66-421a-4418-84cc-f53a546271a9 ethernet -- bond-slave-ens37 1a55748e-5024-4541-b413-8acf98e7c63f ethernet -- # 删除原来的接口[root@alita network-scripts]# nmcli c delete 79fdf747-7a81-4dc4-b2e9-007a8e66aaf2[root@alita network-scripts]# nmcli c delete b48ea077-7ba0-3f66-9147-9fcca6caab5b# 配置ip地址[root@alita ~]# nmcli c modify bond0 ipv4.addresses 192.168.1.171/24 ipv4.method manual connection.autoconnect yes ipv4.dns 114.114.114.114 ipv4.gateway 192.168.1.1 ipv4.ignore-auto-dns yes# 重启网络[root@alita ~]# systemctl restart network# 查看bond0的IP地址[root@alita ~]# nmcli c show bond-bond0 | grep ipv4ipv4.method: manualipv4.dns: 114.114.114.114ipv4.dns-search: --ipv4.dns-options: ""ipv4.dns-priority: 0ipv4.addresses: 192.168.1.171/24ipv4.gateway: 192.168.1.1ipv4.routes: --ipv4.route-metric: -1ipv4.route-table: 0 (unspec)ipv4.routing-rules: --ipv4.ignore-auto-routes: noipv4.ignore-auto-dns: yesipv4.dhcp-client-id: --ipv4.dhcp-timeout: 0 (default)ipv4.dhcp-send-hostname: yesipv4.dhcp-hostname: --ipv4.dhcp-fqdn: --ipv4.never-default: noipv4.may-fail: yesipv4.dad-timeout: -1 (default)# 查看当前bond0配置[root@alita ~]# cat /proc/net/bonding/bond0 Ethernet Channel Bonding Driver: v3.7.1 (April 27, 2011)Bonding Mode: load balancing (round-robin)MII Status: upMII Polling Interval (ms): 100Up Delay (ms): 0Down Delay (ms): 0Slave Interface: ens33MII Status: upSpeed: 1000 MbpsDuplex: fullLink Failure Count: 0Permanent HW addr: 00:0c:29:25:1f:98Slave queue ID: 0Slave Interface: ens37MII Status: upSpeed: 1000 MbpsDuplex: fullLink Failure Count: 0Permanent HW addr: 00:0c:29:25:1f:a2Slave queue ID: 0 CentOS 7 配置team（nmcli）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283# 确认NetworkManager已经开启[root@alita ~]# systemctl status NetworkManager# 查看网络接口[root@alita ~]# nmcli c showNAME UUID TYPE DEVICE ens33 79fdf747-7a81-4dc4-b2e9-007a8e66aaf2 ethernet ens33 Wired connection 1 b48ea077-7ba0-3f66-9147-9fcca6caab5b ethernet ens37 # 使用nmcli创建team接口[root@alita ~]# nmcli c add type team con-name team0 ifname team0 config '&#123;"runner":&#123;"name":"roundrobin"&#125;&#125;'# 其中，模式可以为以下几种方式# broadcast# roundrobin# activebackup# loadbalance# lacp# 使用nmcli创建slave接口[root@alita ~]# nmcli c add type team-slave con-name team0-port1 ifname ens33 master team0[root@alita ~]# nmcli c add type team-slave con-name team0-port2 ifname ens37 master team0# 删除原端口[root@alita ~]# nmcli c delete 79fdf747-7a81-4dc4-b2e9-007a8e66aaf2 [root@alita ~]# nmcli c delete b48ea077-7ba0-3f66-9147-9fcca6caab5b# 配置ip地址[root@alita ~]# nmcli con modify team0 ipv4.address 192.168.1.171/24# 配置网关[root@alita ~]# nmcli con modify team0 ipv4.gateway 192.168.1.1# 配置dns[root@alita ~]# nmcli con modify team0 ipv4.dns 114.114.114.114,8.8.8.8# 配置ip地址设置方式[root@alita ~]# nmcli con modify team0 ipv4.method manual/auto/ignore# manual: 手动配置# auto: DHCP# ignore: 忽略# 激活成员端口[root@alita ~]# nmcli c up team0-port1[root@alita ~]# nmcli c up team0-port2# 重启网络[root@alita ~]# systemctl restart network# 查看team0状态[root@alita ~]# teamdctl team0 statesetup: runner: roundrobinports: ens33 link watches: link summary: up instance[link_watch_0]: name: ethtool link: up down count: 0 ens37 link watches: link summary: up instance[link_watch_0]: name: ethtool link: up down count: 0# 修改team模式nmcli con modify team0 team.config [configJSON]# configJSON可以在/usr/share/d o c/teamd -*/example_configs下的文件中找到]]></content>
      <categories>
        <category>Linux基础</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
        <tag>Linux系统管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 上使用kubeadm搭建k8s集群]]></title>
    <url>%2F2021%2F02%2F18%2F%E5%AE%B9%E5%99%A8%E5%8F%8A%E8%99%9A%E6%8B%9F%E5%8C%96%2Fk8s_install_with_kubeadm%2F</url>
    <content type="text"><![CDATA[准备 硬件允许的话建议所有节点 CPU2核、内存2G、硬盘40G以上 主机 系统 硬件配置 IP k8s-master1 CentOS 7.9.2009 CPU2核/内存2G 192.168.1.171 k8s-node1 CentOS 7.9.2009 CPU1核/内存1G 192.168.1.172 k8s-node2 CentOS 7.9.2009 CPU1核/内存1G 192.168.1.173 关闭防火墙 123456[root@localhost ~]# systemctl stop firewalld[root@localhost ~]# systemctl disable firewalld# 关闭selinux[root@localhost ~]# setenforce 0[root@localhost ~]# sed -i 's/=enforcing/=disabled/g' /etc/selinux/config 修改主机名 123# 分别修改主机名为k8s-master1、k8s-node1、k8s-node2[root@localhost ~]# hostnamectl set-hostname k8s-master1[root@localhost ~]# bash 配置阿里云yum源 123456# 备份[root@k8s-master1 ~]# mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup# 配置[root@k8s-master1 ~]# curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo# 生成缓存[root@k8s-master1 ~]# yum makecache 配置主机名解析 12345[root@k8s-master1 ~]# cat&gt;&gt;/etc/hosts&lt;&lt;EOF192.168.1.171 k8s-master1192.168.1.172 k8s-node1192.168.1.173 k8s-node2EOF 安装常用工具 1[root@k8s-master1 ~]# yum -y install wget vim 配置时间同步 123456789101112131415161718192021222324252627282930313233# 安装chrony，若没有的话[root@k8s-master1 ~]# yum -y install chrony# 注释原有的服务端配置[root@k8s-master1 ~]# sed -i '/server / s/^/# /g' /etc/chrony.conf # 时间同步服务端配置[root@k8s-master1 ~]# cat&gt;&gt;/etc/chrony.conf&lt;&lt;EOF### k8s time sync server config ###server 192.168.1.171 iburstallow 192.168.1.0/24local stratum 10EOF# 时间同步客户端配置[root@k8s-node1 ~]# cat&gt;&gt;/etc/chrony.conf&lt;&lt;EOF### k8s time sync client config ###server k8s-master1 iburstEOF# 重启chrony，配置开机自启动[root@k8s-master1 ~]# systemctl restart chronyd[root@k8s-master1 ~]# systemctl enable chronyd# 查看时间同步是否正常，*为正常，？则表示有问题[root@k8s-node1 ~]# chronyc sources210 Number of sources = 1MS Name/IP address Stratum Poll Reach LastRx Last sample ===============================================================================^* k8s-master1 3 6 17 43 +32us[ +86us] +/- 138ms 关闭swap 12345678[root@k8s-master1 ~]# swapoff -a [root@k8s-master1 ~]# sed -ie '/swap/ s/^/# /' /etc/fstab [root@k8s-master1 ~]# free -m total used free shared buff/cache availableMem: 1819 155 1375 9 289 1513Swap: 0 0 0 配置桥接流量 1234[root@k8s-master1 ~]# cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOFnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOF 安装docker/kubeadm/kubeletKubernetes默认CRI（容器运行时）为Docker，因此先安装Docker。 所有节点安装docker1234567891011121314151617181920212223242526272829# 安装必要的一些系统工具[root@k8s-master1 ~]# yum install -y yum-utils device-mapper-persistent-data lvm2# 添加软件源信息[root@k8s-master1 ~]# yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# 替换下载源为阿里源[root@k8s-master1 ~]# sed -i 's+download.docker.com+mirrors.aliyun.com/docker-ce+' /etc/yum.repos.d/docker-ce.repo# 更新并安装Docker-CE[root@k8s-master1 ~]# yum makecache fast# 查看可安装版本[root@k8s-master1 ~]# yum list docker-ce --showduplicates | sort -r# 选择版本安装[root@k8s-master1 ~]# yum -y install docker-ce-19.03.9[root@k8s-master1 ~]# systemctl enable docker &amp;&amp; systemctl start docker# 配置镜像下载加速，需注册登录：https://cr.console.aliyun.com[root@k8s-master1 ~]# cat &gt; /etc/docker/daemon.json &lt;&lt; EOF&#123; "registry-mirrors": ["https://sqr9a2ic.mirror.aliyuncs.com"]&#125;EOF#重启生效[root@k8s-master1 ~]# systemctl restart docker[root@k8s-master1 ~]# docker info | grep 'Server Version' Server Version: 19.03.9 安装kubeadm/kubelet和kubectl1234567891011121314151617# 配置镜像源[root@k8s-master1 ~]# cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt;EOF[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF# 由于版本更新频繁，这里指定版本号部署# 所有节点安装kubeadm，，kubeadm依赖中有kubectl、kubelet，所以不用单独安装kubectl[root@k8s-master1 ~]# yum install kubeadm-1.20.2 -y# 设置开机启动[root@k8s-master1 ~]# systemctl enable kubelet 创建master123456789101112131415# master上执行[root@k8s-master1 ~]# kubeadm init \ --apiserver-advertise-address=192.168.1.171 \ --image-repository registry.aliyuncs.com/google_containers \ --kubernetes-version v1.20.2 \ --service-cidr=10.96.0.0/12 \ --pod-network-cidr=10.244.0.0/16 \ --ignore-preflight-errors=all # 说明--apiserver-advertise-address 集群通告地址--image-repository 由于默认拉取镜像地址k8s.gcr.io国内无法访问，这里指定阿里云镜像仓库地址--kubernetes-version K8s版本，与上面安装的一致--service-cidr 集群内部虚拟网络，Pod统一访问入口--pod-network-cidr Pod网络，与下面部署的CNI网络组件yaml中保持一致 或者使用配置文件引导 12345678910$ vi kubeadm.confapiVersion: kubeadm.k8s.io/v1beta2kind: ClusterConfigurationkubernetesVersion: v1.18.0imageRepository: registry.aliyuncs.com/google_containers networking: podSubnet: 10.244.0.0/16 serviceSubnet: 10.96.0.0/12 $ kubeadm init --config kubeadm.conf --ignore-preflight-errors=all 拷贝认证文件 12345678# 拷贝kubectl使用的连接k8s认证文件到默认路径[root@k8s-master1 ~]# mkdir -p $HOME/.kube[root@k8s-master1 ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config[root@k8s-master1 ~]# chown $(id -u):$(id -g) $HOME/.kube/config[root@k8s-master1 ~]# kubectl get nodesNAME STATUS ROLES AGE VERSIONk8s-master1 NotReady control-plane,master 2m15s v1.20.2 node加入集群node上运行 123# 向集群添加新节点，执行在kubeadm init输出的kubeadm join命令[root@k8s-node1 ~]# kubeadm join 192.168.1.171:6443 --token w2mfe2.3pwfhv6nm9yueb4d \ --discovery-token-ca-cert-hash sha256:88b9219498210b9ac2f394e32b06a21ae58af887ff6566fa53f30fc9a9dd1ef3 --v=6 默认token有效期为24小时，当过期之后，该token就不可用了。这时就需要重新创建token，操作如下 12345678910$ kubeadm token create$ kubeadm token list$ openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //'63bca849e0e01691ae14eab449570284f0c3ddeea590f8da988c07fe2729e92463bca849e0e01691ae14eab449570284f0c3ddeea590f8da988c07fe2729e924$ kubeadm join 192.168.31.61:6443 --token nuja6n.o3jrhsffiqs9swnu --discovery-token-ca-cert-hash sha256:63bca849e0e01691ae14eab449570284f0c3ddeea590f8da988c07fe2729e924或者直接命令快捷生成：kubeadm token create --print-join-command 部署容器网络（CNI）CNI容器网络介绍：https://kubernetes.io/docs/concepts/cluster-administration/networking/#how-to-implement-the-kubernetes-networking-model 此处使用Calico作为容器网络中间件 Calico是一个纯三层的数据中心网络方案，Calico支持广泛的平台，包括Kubernetes、OpenStack等 Calico 在每一个计算节点利用 Linux Kernel 实现了一个高效的虚拟路由器（ vRouter） 来负责数据转发，而每个 vRouter 通过 BGP 协议负责把自己上运行的 workload 的路由信息向整个 Calico 网络内传播 k8s安装Calico：https://docs.projectcalico.org/getting-started/kubernetes/quickstart 1234567891011121314151617181920212223242526[root@k8s-master1 ~]# wget https://docs.projectcalico.org/manifests/calico.yaml# 修改Pod网络（CALICO_IPV4POOL_CIDR），与前面kubeadm init指定的一样[root@k8s-master1 ~]# vim calico.yaml - name: CALICO_IPV4POOL_CIDR value: "10.244.0.0/16"[root@k8s-master1 ~]# kubectl apply -f calico.yaml# 等待一段时间后，查看pod状态[root@k8s-master1 ~]# kubectl get pods -n kube-systemNAME READY STATUS RESTARTS AGEcalico-kube-controllers-86bddfcff-rfthx 1/1 Running 0 12mcalico-node-9vg5t 1/1 Running 0 12mcalico-node-dv5cq 1/1 Running 0 12mcalico-node-rmj7w 1/1 Running 0 12mcoredns-7f89b7bc75-bccgp 1/1 Running 0 33mcoredns-7f89b7bc75-pb7v6 1/1 Running 0 33metcd-k8s-master1 1/1 Running 0 33mkube-apiserver-k8s-master1 1/1 Running 0 33mkube-controller-manager-k8s-master1 1/1 Running 0 33mkube-proxy-22fb2 1/1 Running 0 31mkube-proxy-gf88l 1/1 Running 0 33mkube-proxy-wh6tq 1/1 Running 0 31mkube-scheduler-k8s-master1 1/1 Running 0 33m 测试kubernetes集群12345678910111213141516# 在Kubernetes集群中创建一个pod，验证是否正常运行[root@k8s-master1 ~]# kubectl create deployment nginx --image=nginxdeployment.apps/nginx created[root@k8s-master1 ~]# kubectl expose deployment nginx --port=80 --type=NodePortservice/nginx exposed[root@k8s-master1 ~]# kubectl get pod,svcNAME READY STATUS RESTARTS AGEpod/nginx-6799fc88d8-cptr2 1/1 Running 0 42sNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 38mservice/nginx NodePort 10.102.16.99 &lt;none&gt; 80:30580/TCP 18s# 浏览器访问http://NodeIP:port,出现nginx页面 部署web UI（Dashboard）1234567891011121314151617181920212223242526272829303132333435# 由于Dashboard配置需访问raw.githubusercontent.com，在国内没有解析，所以先通过域名查询ip，将其加入/etc/hosts中# 域名查询网址 https://site.ip138.com/raw.githubusercontent.com/[root@k8s-master1 ~]# cat &gt;&gt; /etc/hosts &lt;&lt; EOF&gt; 185.199.109.133 raw.githubusercontent.com&gt; EOF# dashboard 网址：https://github.com/kubernetes/dashboard/releases# 根据kubenetes版本选择dashboard版本，此处为v2.1.0[root@k8s-master1 ~]# wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.1.0/aio/deploy/recommended.yaml -O dashboard.yaml# 默认Dashboard只能集群内部访问，修改Service为NodePort类型，暴露到外部[root@k8s-master1 ~]# vim dashboard.yaml kind: ServiceapiVersion: v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboardspec: type: NodePort ports: - port: 443 targetPort: 8443 nodePort: 30001 selector: k8s-app: kubernetes-dashboard[root@k8s-master1 ~]# kubectl apply -f dashboard.yaml[root@k8s-master1 ~]# kubectl get pods -n kubernetes-dashboardNAME READY STATUS RESTARTS AGEdashboard-metrics-scraper-79c5968bdc-xlj6j 1/1 Running 0 2m19skubernetes-dashboard-7448ffc97b-zzxkp 1/1 Running 0 2m19s 访问地址：https://NodeIP:30001 123456789101112131415161718192021222324252627# 创建service account并绑定默认cluster-admin管理员集群角色# 创建用户[root@k8s-master1 ~]# kubectl create serviceaccount dashboard-admin -n kube-systemserviceaccount/dashboard-admin created# 用户授权[root@k8s-master1 ~]# kubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-adminclusterrolebinding.rbac.authorization.k8s.io/dashboard-admin created# 获取用户token[root@k8s-master1 ~]# kubectl describe secrets -n kube-system $(kubectl -n kube-system get secret | awk '/dashboard-admin/&#123;print $1&#125;')Name: dashboard-admin-token-bbsrbNamespace: kube-systemLabels: &lt;none&gt;Annotations: kubernetes.io/service-account.name: dashboard-admin kubernetes.io/service-account.uid: 9a01a52d-04a5-4ea6-b4f8-afdc22b1b9c6Type: kubernetes.io/service-account-tokenData====ca.crt: 1066 bytesnamespace: 11 bytestoken: eyJhbGciOiJSUzI1NiIsImtpZCI6Inpvc2Y0dmREN3p1SU5GWUhuWWVNek92NDJzX2JFQm94N09Dd1Nwa1lWUnMifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdG9rZW4tYmJzcmIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkLWFkbWluIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiOWEwMWE1MmQtMDRhNS00ZWE2LWI0ZjgtYWZkYzIyYjFiOWM2Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRhc2hib2FyZC1hZG1pbiJ9.oAN9GWZlj6_HKdG_2KOLzjfysXpVBl6lcfarQThZYs-TaEtVzOfKqvAPe4e7yE93uunV-4ddr1fdyGDV3iwPPwpGF9B65IDn6XlM268agEwb2efNjlbwYku4NZt8RCgH_tf-IdvuwEiuYolaGvfYLGw1sQ6-Hphi4kw-G9KZgCAUYwcqhijGSwcZwP7GwMEsthqXLJE84mUHpqRj6QZoRV_vx3G54PyIplLrp04gkuLZArqcxxkY7Y9gibafbhKKbNbxY1v32lYIzG1VjwHb3vmLx_FABEilztYtU1alXfgtdvuiGBpfuzgXgOCgLyElRqUK04dWRCSIRHM3Ai9aRg 使用获取到的token登录dashboard]]></content>
      <categories>
        <category>容器及虚拟化</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>容器编排</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 上Redis 哨兵简介以及配置]]></title>
    <url>%2F2021%2F01%2F20%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%2FRedis6_sentinel%2F</url>
    <content type="text"><![CDATA[简介问题redis主从虽然解决了单点导致的数据丢失问题，但是在主库宕机后，从库无法自动切换为主库，需要手工去切换，在这一瞬间会对后端数据库造成极大的负载，可能直接导致后端数据宕机，所以需要哨兵对主从系统进行优化 哨兵的工作原理哨兵（Sentinel） 是一个分布式系统，可以在一个架构中运行多个哨兵（Sentinel）进程，这些进程使用流言协议（gossipprotocols）来接收关于master是否下线的信息，并使用投票协议（agreement protocols） 来决定是否执行自动故障迁移，并选择某个slave作为新的master 每个哨兵（Sentinel） 会向其它哨兵（Sentinel）、master、slave定时发送消息，以确认对方是否上线，如果发现对方在指定时间内未回应，则暂时认为对方宕机了，这就是所谓的主观宕机（Subjective Down，简称sdown）。 若哨兵集群中的多数Sentinel，都报告某一master没响应，系统才认为该master真正宕机，即客观宕机，（Objective Down，简称odown），通过一定的vote算法，从剩下的slave节点中，选一台提升为 master，然后自动修改相关配置 哨兵的主要作用 监控：监控redis主库及从库运行状态 通知：如果redis发生故障转移，可以通过自动运行脚本以通知管理员 自动故障转移：：一旦发现主库宕机，则在从库中通过选举新的master进行故障转移 官方建议基础的哨兵系统至少部署三个Sentinel实例，才能保证系统的健壮性，这三个Sentinel实例应该被放置到独立的计算机或虚拟机中，这些计算机或虚拟机以独立的方式发生故障 准备整体结构如下图 redis 主机 IP 服务 角色 node1 192.168.1.171 redis 6.0.5 master node2 192.168.1.172 redis 6.0.5 slave node3 192.168.1.173 redis 6.0.5 slave Sentinel Sentinel系统中有三台sentinel节点 主机 IP 角色 node1 192.167.1.171 sentinel node2 192.168.1.172 sentinel node3 192.168.1.173 sentinel 三台主机均安装redis完成，安装redis详见：CentOS 7 安装Redis 6.x 配置主从master（node1）配置12345678910111213[root@node1 ~]# vim /redis/conf/redis_6379.conf # 绑定地址bind 192.168.1.171 127.0.0.1 # 绑定端口port 6379# 配置密码requirepass master123..# 由于slave配置了密码，发生故障转移重连后需要进行认证，所以此处也需要配置连接master的密码masterauth master123..# 重启服务[root@node1 ~]# systemctl restart redis slave（node2、node3）配置123456789101112131415[root@node2 ~]# vim /redis/conf/redis_6379.conf # 绑定主机对应的IP地址bind 192.168.1.172 127.0.0.1# 绑定端口port 6379# 配置密码requirepass master123..# 配置master网络信息replicaof 192.168.1.171 6379# 配置master密码masterauth master123..[root@node2 ~]# systemctl restart redis 检查主从状态1234567891011121314151617[root@node1 ~]# redis-cli127.0.0.1:6379&gt; auth master123..OK127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:2slave0:ip=192.168.1.172,port=6379,state=online,offset=658,lag=0slave1:ip=192.168.1.173,port=6379,state=online,offset=658,lag=0master_replid:3ed47ad32a3466041ac62eeac70c39f5f05589e6master_replid2:0000000000000000000000000000000000000000master_repl_offset:658second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:658 配置哨兵 三台主机均操作，配置除绑定IP外均相同 配置哨兵12345678910111213141516171819202122232425262728293031323334353637# 创建sentinel工作目录[root@node1 ~]# mkdir -p /redis/sentinel/26379# 将安装时的哨兵配置文件复制到相应目录[root@node1 ~]# cp redis-stable/sentinel.conf /redis/conf/sentinel_26379.conf# 配置哨兵[root@node1 ~]# vim /redis/conf/sentinel_26379.conf # 绑定IP，建议直接配成0.0.0.0# 如果sentinel配置了bind参数，sentinel将获取第一个ip去检测主节点状态, # 由于127.0.0.1是个回环地址，所以当bind第一个ip配置成127.0.0.1时无法连接其他机器的ip，# 所以配置时第一个ip不能配置为回环地址，建议redis相关的ip绑定都先写私网ip再写回环ipbind 192.168.1.171 127.0.0.1# 配置后台运行daemonize yes# 日志路径logfile "/redis/log/sentinel_26379.log"# 配置工作目录dir /redis/sentinel/26379# 配置redis的master名称、ip和端口；若需要监视多个master-slave组，则配置多条master信息# 2代表只有两个或两个以上的哨兵认为主服务器不可用的时候，才会进行failover操作# 建议将其设置为 Sentinel 节点的一半加1sentinel monitor redis_master 192.168.1.171 6379 2# 配置master密码sentinel auth-pass redis_master master123..# 配置sentinel监控master回复时间，默认30秒，30秒内没有回复，则认为下线了sentinel down-after-milliseconds redis_master 30000# 指定在故障转移期间，多少个slave向新的master同步得数量，如果slave是提供查询服务，则应该设置小一点sentinel parallel-syncs redis_master 1# 指定故障转移超时时间，默认为3分钟sentinel failover-timeout redis_master 180000# 设置通知脚本，发生故障转移可以向管理员发送通知（可选）sentinel notification-script redis_master /redis/sentinel/notify.sh# 禁止修改脚本，避免脚本重置sentinel deny-scripts-reconfig yes 配置通知脚本（可选）1234567891011121314151617181920212223[root@node1 ~]# vim /redis/sentinel/notify.sh#!/bin/bashMAIL_TO="sky.nemo@outlook.com"SUBJECT="redis 发生故障转移"CONTEXT="redis 发生故障转移"echo -e "$CONTEXT"|mailx -s "$SUBJECT" "$MAIL_TO"# 给脚本赋执行权限[root@node1 ~]# chmod 755 /redis/sentinel/notify.sh# 安装邮件通知[root@node1 ~]# yum install mailx -y# 配置发件人信息，发件人邮箱需开启SMTP服务[root@node1 ~]# vim /etc/mail.rc # mail infoset from="operation_smtp@163.com"set smtp=smtp.163.comset smtp-auth-user=operation_smtp# 开启SMTP服务时得到的授权码set smtp-auth-password=set smtp-auth=login 配置systemd管理1234567891011121314[root@node1 ~]# vim /etc/systemd/system/redis_sentinel.service[Unit]Description=redis-sentinelAfter=network.target[Service]Type=forkingExecStart=/redis/app/bin/redis-sentinel /redis/conf/sentinel_26379.conf[Install]WantedBy=multi-user.target# 重载systemd配置[root@node1 ~]# systemctl daemon-reload# 启动哨兵[root@node1 ~]# systemctl start redis_sentinel 检查哨兵状态12345678910111213141516# 连接sentinel[root@node1 ~]# redis-cli -p 26379 -h 192.168.1.171# 查看sentinel信息192.168.1.171:26379&gt; info sentinel# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0sentinel_simulate_failure_flags:0# 可以看到当前监控的master在线状态，IP信息，slave数量、sentinel数量等master0:name=redis_master,status=ok,address=192.168.1.171:6379,slaves=2,sentinels=3# 查看除当前节点外其他sentinel节点详细信息192.168.1.171:26379&gt; sentinel sentinels redis_master 验证故障转移当前状态123456789101112131415161718192021222324252627282930# 启动时可以看到如下日志[root@node2 ~]# tail -f /redis/log/sentinel_26379.log 20572:X 19 Jan 2021 13:09:46.156 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo20572:X 19 Jan 2021 13:09:46.157 # Redis version=6.0.5, bits=64, commit=00000000, modified=0, pid=20572, just started20572:X 19 Jan 2021 13:09:46.157 # Configuration loaded20573:X 19 Jan 2021 13:09:46.171 * Increased maximum number of open files to 10032 (it was originally set to 1024).20573:X 19 Jan 2021 13:09:46.173 * Running mode=sentinel, port=26379.20573:X 19 Jan 2021 13:09:46.173 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.20573:X 19 Jan 2021 13:09:46.174 # Sentinel ID is 692bfddd9b7bfb87a6920588e1851a967a2d2839# 检测到主机20573:X 19 Jan 2021 13:09:46.174 # +monitor master redis_master 192.168.1.171 6379 quorum 2# 检测到主机的两台从机20573:X 19 Jan 2021 13:09:46.180 * +slave slave 192.168.1.172:6379 192.168.1.172 6379 @ redis_master 192.168.1.171 637920573:X 19 Jan 2021 13:09:46.189 * +slave slave 192.168.1.173:6379 192.168.1.173 6379 @ redis_master 192.168.1.171 6379# 检测到其他两台哨兵上线20573:X 19 Jan 2021 13:13:35.581 * +sentinel sentinel a19143eabf9605d7a8d6276fe9f1f02adf8c744f 192.168.1.171 26379 @ redis_master 192.168.1.171 637920573:X 19 Jan 2021 13:13:56.377 * +sentinel sentinel bcc5b607e7b7fef3be5691065a5d6665201a44fd 192.168.1.173 26379 @ redis_master 192.168.1.171 6379# 检查当前主节点信息，可以看到，此时主节点是node1（192.168.1.171），从节点有两个[root@node2 ~]# redis-cli -p 26379 -h 192.168.1.172192.168.1.172:26379&gt; info sentinel# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0sentinel_simulate_failure_flags:0master0:name=redis_master,status=ok,address=192.168.1.171:6379,slaves=2,sentinels=3 断开node1（master）网络12345678910111213141516171819202122232425262728293031323334353637383940414243# 查看日志[root@node2 ~]# tail -f /redis/log/sentinel_26379.log # 检测到master主观下线20573:X 19 Jan 2021 13:25:43.203 # +sdown sentinel a19143eabf9605d7a8d6276fe9f1f02adf8c744f 192.168.1.171 26379 @ redis_master 192.168.1.171 637920573:X 19 Jan 2021 13:25:43.289 # +sdown master redis_master 192.168.1.171 6379# 检测到master客观下线20573:X 19 Jan 2021 13:25:43.382 # +odown master redis_master 192.168.1.171 6379 #quorum 2/2# 开始重新选举master20573:X 19 Jan 2021 13:25:43.382 # +new-epoch 120573:X 19 Jan 2021 13:25:43.382 # +try-failover master redis_master 192.168.1.171 637920573:X 19 Jan 2021 13:25:43.384 # +vote-for-leader 692bfddd9b7bfb87a6920588e1851a967a2d2839 120573:X 19 Jan 2021 13:25:43.390 # bcc5b607e7b7fef3be5691065a5d6665201a44fd voted for 692bfddd9b7bfb87a6920588e1851a967a2d2839 120573:X 19 Jan 2021 13:25:43.454 # +elected-leader master redis_master 192.168.1.171 637920573:X 19 Jan 2021 13:25:43.454 # +failover-state-select-slave master redis_master 192.168.1.171 637920573:X 19 Jan 2021 13:25:43.533 # +selected-slave slave 192.168.1.172:6379 192.168.1.172 6379 @ redis_master 192.168.1.171 637920573:X 19 Jan 2021 13:25:43.533 * +failover-state-send-slaveof-noone slave 192.168.1.172:6379 192.168.1.172 6379 @ redis_master 192.168.1.171 637920573:X 19 Jan 2021 13:25:43.634 * +failover-state-wait-promotion slave 192.168.1.172:6379 192.168.1.172 6379 @ redis_master 192.168.1.171 637920573:X 19 Jan 2021 13:25:44.441 # +promoted-slave slave 192.168.1.172:6379 192.168.1.172 6379 @ redis_master 192.168.1.171 6379# 重新配置配置文件20573:X 19 Jan 2021 13:25:44.441 # +failover-state-reconf-slaves master redis_master 192.168.1.171 637920573:X 19 Jan 2021 13:25:44.503 * +slave-reconf-sent slave 192.168.1.173:6379 192.168.1.173 6379 @ redis_master 192.168.1.171 637920573:X 19 Jan 2021 13:25:45.448 * +slave-reconf-inprog slave 192.168.1.173:6379 192.168.1.173 6379 @ redis_master 192.168.1.171 637920573:X 19 Jan 2021 13:25:45.448 * +slave-reconf-done slave 192.168.1.173:6379 192.168.1.173 6379 @ redis_master 192.168.1.171 637920573:X 19 Jan 2021 13:25:45.531 # -odown master redis_master 192.168.1.171 637920573:X 19 Jan 2021 13:25:45.531 # +failover-end master redis_master 192.168.1.171 6379# master切换到node2（192.168.1.17220573:X 19 Jan 2021 13:25:45.531 # +switch-master redis_master 192.168.1.171 6379 192.168.1.172 637920573:X 19 Jan 2021 13:25:45.531 * +slave slave 192.168.1.173:6379 192.168.1.173 6379 @ redis_master 192.168.1.172 637920573:X 19 Jan 2021 13:25:45.531 * +slave slave 192.168.1.171:6379 192.168.1.171 6379 @ redis_master 192.168.1.172 6379# node1服务处于离线状态20573:X 19 Jan 2021 13:26:15.550 # +sdown slave 192.168.1.171:6379 192.168.1.171 6379 @ redis_master 192.168.1.172 637920573:X 19 Jan 2021 13:32:13.445 # -sdown sentinel a19143eabf9605d7a8d6276fe9f1f02adf8c744f 192.168.1.171 26379 @ redis_master 192.168.1.172 6379# 检查当前主节点信息，可以看到当前master为node2（192.168.1.172）192.168.1.172:26379&gt; info sentinel# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0sentinel_simulate_failure_flags:0master0:name=redis_master,status=ok,address=192.168.1.172:6379,slaves=2,sentinels=3 重新开启node1网络12345678910# 查看node1的redis状态，已经变成了slave[root@node1 ~]# redis-cli -p 6379127.0.0.1:6379&gt; auth master123..OK127.0.0.1:6379&gt; role1) "slave"2) "192.168.1.172"3) (integer) 63794) "connected"5) (integer) 248346 添加删除哨兵添加添加一个新的Sentinel到您的部署是一个简单的过程，因为Sentinel实现了自动发现机制。只需要启动配置为监视当前活动master的新Sentinel。在10秒内，哨兵将获得其他哨兵的列表和附加到master的slave集合如果一次添加多个哨兵，需要你一个接一个地添加，等其他哨兵都知道第一个哨兵后再添加下一个哨兵，以确保不会出现网络分区的现象可以使用SENTINEL MASTER mastername命令来检查MASTER的SENTINEL总数 删除Sentinel永远不会忘记已经看到的Sentinel，即使该sentinel已经离线。因此，要删除哨兵，应在没有网络分区的情况下执行以下步骤： 停止要删除的哨兵的哨兵进程 向所有其他Sentinel实例发送SENTINEL RESET *命令（如果只想重置单个主机，可以使用SENTINEL RESET mastername），实例之间至少等待30秒。Sentinel将在接下来的10秒内刷新副本列表，只添加从当前master INFO输出正确复制的副本列表 通过检查每个Sentinel的SENTINEL MASTER mastername的输出，检查Sentinel的数量]]></content>
      <categories>
        <category>数据库基础</category>
      </categories>
      <tags>
        <tag>数据库基础</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 上Redis 6.x主从复制配置以及复制原理]]></title>
    <url>%2F2021%2F01%2F16%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%2FRedis6_master_slave%2F</url>
    <content type="text"><![CDATA[环境 安装redis，详见：CentOS 7 安装Redis 6.x 三台主机操作系统均为CentOS 7 2009，且都关闭了防火墙 主机 IP 安装服务 角色 node1 192.168.1.171 redis 6.0.5 master node2 192.168.1.172 redis 6.0.5 slave node3 192.168.1.173 redis 6.0.5 slave 结构如图 配置主库配置12345678910[root@node1 ~]# vim /redis/conf/redis_6379.conf # 修改配置文件，绑定当前IPbind 192.168.1.171# 添加设置认证密码，可选requirepass master123..# 重启redis[root@node1 ~]# systemctl restart redis 从库配置1234567891011121314# 两台从库配置基本一致[root@node2 ~]# vim /redis/conf/redis_6379.conf # 修改配置文件，绑定当前IPbind 192.168.1.172# 指定主库master网络信息，5.x版本为slaveofreplicaof 192.168.1.171 6379# 指定master密码masterauth master123..# 重启redis[root@node2 ~]# systemctl restart redis 主库查看状态12345678910111213141516171819[root@node1 ~]# redis-cli -h 192.168.1.171192.168.1.171:6379&gt; auth master123..OK192.168.1.171:6379&gt; info replication# Replicationrole:master# 当前有两个从库connected_slaves:2# 两个从库的IP信息slave0:ip=192.168.1.172,port=6379,state=online,offset=1176,lag=0slave1:ip=192.168.1.173,port=6379,state=online,offset=1176,lag=0master_replid:065330c593522e0d0709198265ec26126de2ff5amaster_replid2:0000000000000000000000000000000000000000master_repl_offset:1176second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:1176 从库查看状态12345678910111213141516171819202122232425[root@node2 ~]# redis-cli -h 192.168.1.172192.168.1.172:6379&gt; info replication# Replicationrole:slavemaster_host:192.168.1.171master_port:6379# 连接状态up，表示连接成功master_link_status:upmaster_last_io_seconds_ago:4master_sync_in_progress:0slave_repl_offset:1246slave_priority:100slave_read_only:1connected_slaves:0# 从库在内存中记录了主库的ID：master_replid，以及偏移量：master_repl_offset:1246# 当从库网络掉线重新连接后，会给master发送ID和偏移量，以请求增量同步数据# 由于信息存储在内存中，重启redis会消失master_replid:065330c593522e0d0709198265ec26126de2ff5amaster_replid2:0000000000000000000000000000000000000000master_repl_offset:1246second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:1246 原理每个redis主服务器master都有一个复制 ID（master_replid，一个伪随机字符串），以及一个偏移量（master_repl_offset），该偏移量将对生成的、要发送到slave的命令流的每个字节进行增量，以便标识redis数据集的一个新的更改状态。需要注意的时，即使没有slave实际连接，偏移量也会增加 redis主从同步一般有以下情形： 当slave和master刚刚建立连接时，会进行一次全量同步，并建立长连接（用于发送命令流），slave在内存中记录master的ID和偏移量 当master和slave连接状况良好时，master通过向slave发送命令流来保持数据的更新 当master和slave之间的链接中断、网络问题或由于在master或slave中一方发现超时时，slave将重新连接并尝试进行增量同步，发送复制ID和偏移量，尝试获取它在断开连接期间丢失的命令流 当slave发来的偏移量信息还在master缓冲区，master会给slave发送离线期间丢失的命令流，这就是增量同步；若偏移量已经不在master的缓冲区中，或者复制ID有错，slave将被要求重新进行全量同步 全量同步初次连接时，可以看到全量同步日志 123456789101112131415161718192021222324252627282930313233343536373839# master节点日志如下（截取部分）[root@node1 ~]# tail -f /redis/log/redis_6379.log # 收到来自192.168.1.172的同步信息67888:M 14 Jan 2021 16:21:06.212 * Replica 192.168.1.172:6379 asks for synchronization# 全量同步67888:M 14 Jan 2021 16:21:06.212 * Full resync requested by replica 192.168.1.172:6379# BGSAVE开启子进程，保存数据文件67888:M 14 Jan 2021 16:21:06.212 * Starting BGSAVE for SYNC with target: disk67888:M 14 Jan 2021 16:21:06.212 * Background saving started by pid 6792967929:C 14 Jan 2021 16:21:06.214 * DB saved on disk67929:C 14 Jan 2021 16:21:06.215 * RDB: 0 MB of memory used by copy-on-write67888:M 14 Jan 2021 16:21:06.269 * Background saving terminated with success# 发送数据文件成功67888:M 14 Jan 2021 16:21:06.269 * Synchronization with replica 192.168.1.172:6379 succeeded# slave节点日志如下（截取部分）[root@node2 ~]# tail -f /redis/log/redis_6379.log # 连接MASTER 192.168.1.171:637918767:S 14 Jan 2021 16:21:06.229 * Connecting to MASTER 192.168.1.171:637918767:S 14 Jan 2021 16:21:06.229 * MASTER &lt;-&gt; REPLICA sync started# 开始非阻塞同步18767:S 14 Jan 2021 16:21:06.229 * Non blocking connect for SYNC fired the event.18767:S 14 Jan 2021 16:21:06.229 * Master replied to PING, replication can continue...# 判断是否可以进行增量同步，不满足则进行全量同步18767:S 14 Jan 2021 16:21:06.231 * Partial resynchronization not possible (no cached master)# 全量同步18767:S 14 Jan 2021 16:21:06.232 * Full resync from master: ee35451bf4086280a6281395cc1fdfacc1e9a273:42# 接收数据18767:S 14 Jan 2021 16:21:06.289 * MASTER &lt;-&gt; REPLICA sync: receiving 336 bytes from master to disk# 清空之前的老数据18767:S 14 Jan 2021 16:21:06.289 * MASTER &lt;-&gt; REPLICA sync: Flushing old data# 加载数据到内存18767:S 14 Jan 2021 16:21:06.289 * MASTER &lt;-&gt; REPLICA sync: Loading DB in memory18767:S 14 Jan 2021 16:21:06.289 * Loading RDB produced by version 6.0.518767:S 14 Jan 2021 16:21:06.289 * RDB age 0 seconds18767:S 14 Jan 2021 16:21:06.289 * RDB memory usage when created 1.87 Mb# 完成全量同步18767:S 14 Jan 2021 16:21:06.289 * MASTER &lt;-&gt; REPLICA sync: Finished with success 由此，我们可以推断全量同步的过程 slave连接master，发送SYNC命令，请求同步 master收到SYNC命令后，开始执行BGSAVE生成RDB文件，并在期间记录执行的修改数据命令 master的BGSAVE完成后，向从服务器发送RDB文件 slave收到RDB文件后，丢失旧数据，载入收到的RDB文件数据 master与slave建立连接，发送期间的命令流以及后续的命令流 slave接收来自master的命令流，并执行 流程图如下 增量同步 断开slave的网络，隔一段时间后重连，可以看到增量同步成功的日志，期间redis不能重启，否则master_replid发生变化，判断无法增量同步，会继续执行全量同步 12345678910111213141516171819# master节点日志如下（截取部分）[root@node1 ~]# tail -f /redis/log/redis_6379.log # 收到slave的同步消息67888:M 14 Jan 2021 16:28:25.888 * Replica 192.168.1.173:6379 asks for synchronization# 判断ID正确后，根据偏移量发送同步数据67888:M 14 Jan 2021 16:28:25.888 * Partial resynchronization request from 192.168.1.173:6379 accepted. Sending 70 bytes of backlog starting from offset 575.# slave节点日志如下（截取部分）[root@node2 ~]# tail -f /redis/log/redis_6379.log 11061:S 14 Jan 2021 16:28:25.902 * Connecting to MASTER 192.168.1.171:637911061:S 14 Jan 2021 16:28:25.903 * MASTER &lt;-&gt; REPLICA sync started11061:S 14 Jan 2021 16:28:25.903 * Non blocking connect for SYNC fired the event.11061:S 14 Jan 2021 16:28:25.905 * Master replied to PING, replication can continue...# 尝试进行增量同步 ID:offset11061:S 14 Jan 2021 16:28:25.906 * Trying a partial resynchronization (request ee35451bf4086280a6281395cc1fdfacc1e9a273:575).# 增量同步成功11061:S 14 Jan 2021 16:28:25.907 * Successful partial resynchronization with master.11061:S 14 Jan 2021 16:28:25.907 * MASTER &lt;-&gt; REPLICA sync: Master accepted a Partial Resynchronization. 由此，我们可以推断增量同步的过程 slave连接到master，使用PSYNC命令发起增量同步请求，携带复制ID（master_replid）和偏移量（master_repl_offset） master判断该ID，并到缓冲区环形队列中查找offset，若offset对应的命令流还存在，则建立连接，发送离线期间的命令流；否则告诉slave进行全量复制 slave根据情况接收命令流，并执行；或者发起全量复制请求 流程图如下 常用配置123456789101112131415161718192021222324252627282930313233# 指定主库IP和端口replicaof 192.168.75.136 6379# 指定主库得认证密码masterauth 123456# 从库正在复制时，从库可以相应用户读请求，如果设置为no,则返回报错信息。replica-serve-stale-data yes# 设置从库为只读replica-read-only yes# 启动socket方式复制数据库，master生成rdb文件，不在是先保存到磁盘，然后发给从库，而是直接把rdb发送给从库，减少了磁盘IOrepl-diskless-sync yes# 配置延时时间，让更多slave加入传输队列，如果复制已经开始，则5秒内，不接受新的slave同步请求repl-diskless-sync-delay 5# 指定从库定期检查主库状态，默认10秒repl-ping-replica-period 10# 同步超时时间repl-timeout 60# 是否禁用tcp-nodelay，yes表示禁用，redis会在写缓存积累到一定量之后一起发送，节省带宽，但是会导致master和slave数据延迟# no，表示启用，redis会立即发送数据包，即使是很小数据，数据同步会比较快，但是消耗更多带宽repl-disable-tcp-nodelay no# 设置在同步过程中，写缓冲区得大小，需要考虑到同步的时间和数据的写入速度repl-backlog-size 1mb# 设置从库的优先级，在主库宕机后，根据优先级选择slave,值越小，则优先级越高，0,表示不参与竞选，故永远不会被选中。replica-priority 100]]></content>
      <categories>
        <category>数据库基础</category>
      </categories>
      <tags>
        <tag>数据库基础</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL基于Mycat的读写分离配置]]></title>
    <url>%2F2021%2F01%2F08%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%2FMySQL5.7_read_write_separation%2F</url>
    <content type="text"><![CDATA[简介MySQL读写分离，原理是让Master数据库处理事务性增、删除、修改、更新操作（CREATE、 INSERT、UPDATE、DELETE），而让Slave数据库处理SELECT操作。所以，读写分离是基于主从复制完成的，这样可以保证在Master上修改数据，Slave同步之后，应用可以读取到Slave端 的数据 准备 所有主机操作系统均为 CentOS7 2009 minimal install 主机 IP 安装服务 角色 node1 192.168.1.171 mycat 1.6.7.4 、MySQL Client proxy node2 192.168.1.172 MySQL Server 5.7 （Master） write node node3 192.168.1.173 MySQL Server 5.7 （Slave） read node （standby write node） 拓扑图如下 前期准备三台主机防火墙均已关闭 node1已安装MySQL客户端工具（用于测试,也可以使用node2或者node3的MySQL客户端），详见附录 node2与node3已经安装MySQL 5.7服务，并且做了主从复制操作，详见：MySQL 5.7 主从复制 mycat安装 node1操作 安装jdk由于mycat使用Java语言设计编写，所以需要先安装JDK，此处使用 jdk-11.0.9_linux-x64_bin.tar压缩包方式安装 JDK下载页面：https://www.oracle.com/cn/java/technologies/javase-downloads.html 1234567891011121314151617181920# 先上传下载的jdk到root路径下# 解压到/usr/local下[root@node1 ~]# tar -zxvf jdk-11.0.9_linux-x64_bin.tar.gz -C /usr/local/[root@node1 ~]# ls /usr/local/jdk-11.0.9/bin conf include jmods legal lib README.html release# 添加环境变量（全局）[root@node1 ~]# vi /etc/profile.d/java.sh# java environmentexport JAVA_HOME=/usr/local/jdk-11.0.9/export PATH=$JAVA_HOME/bin:$PATH# 重新加载环境变量[root@node1 ~]# source /etc/profile# 验证[root@node1 ~]# java --versionjava 11.0.9 2020-10-20 LTSJava(TM) SE Runtime Environment 18.9 (build 11.0.9+7-LTS)Java HotSpot(TM) 64-Bit Server VM 18.9 (build 11.0.9+7-LTS, mixed mode) 安装mycat此处使用版本为：Mycat-server-1.6.7.4-release mycat官网：http://www.mycat.org.cn/ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# 先上传mycat到root路径下[root@node1 ~]# tar -zxvf Mycat-server-1.6.7.4-release-20200105164103-linux.tar.gz -C /usr/local# 配置环境变量（全局）[root@node1 ~]# vim /etc/profile.d/mycat.sh# mycat environmentexport MYCAT_HOME=/usr/local/mycat/export PATH=$MYCAT_HOME/bin:$PATH# 重新加载环境变量[root@node1 ~]# source /etc/profile# 验证[root@node1 ~]# mycatUsage: /usr/local/mycat//bin/mycat &#123; console | start | stop | restart | status | dump &#125;# 配置java路径，配置wrapper.java.command为实际java路径[root@node1 ~]# vi /usr/local/mycat/conf/wrapper.conf # Java Applicationwrapper.java.command=/usr/local/jdk-11.0.9/bin/java# 配置systemd管理[root@node1 ~]# vi /usr/lib/systemd/system/mycatd.service[Unit]Description=MyCAT Database ProxyDescription=MyCATAfter=syslog.targetAfter=network.target[Service]Type=simpleRestart=on-abortPIDFile=/usr/local/mycat/logs/mycat.pidExecStart=/usr/local/mycat/bin/mycat startPrivateTmp=true[Install]WantedBy=multi-user.target# 重新加载systemd服务[root@node1 ~]# systemctl daemon-reload[root@node1 ~]# systemctl start mycatd[root@node1 ~]# systemctl status mycatd● mycatd.service - MyCAT Loaded: loaded (/usr/lib/systemd/system/mycatd.service; disabled; vendor preset: disabled) Active: active (running) since Wed 2021-01-06 14:58:46 EST; 8s ago Main PID: 2822 (wrapper-linux-x) CGroup: /system.slice/mycatd.service └─2822 /usr/local/mycat/bin/./wrapper-linux-x86-64 /usr/local/mycat/conf/wrapper.conf wrapper.syslog.ident=my...Jan 06 14:58:46 node1 systemd[1]: Started MyCAT.Jan 06 14:58:46 node1 mycat[2773]: Starting Mycat-server... 配置配置mysqlnode2上创建测试数据 1234567891011121314151617181920212223242526272829303132[root@node2 ~]# mysql -uroot -pEnter password: mysql&gt; CREATE DATABASE testdb1 DEFAULT CHARSET utf8mb4; mysql&gt; use testdb1;CREATE TABLE t_user01( id int auto_increment primary key, name varchar(40)) ENGINE = InnoDB;INSERT INTO t_user01 VALUES (1,&apos;user01&apos;);INSERT INTO t_user01 VALUES (2,&apos;user02&apos;);INSERT INTO t_user01 VALUES (3,&apos;user03&apos;);INSERT INTO t_user01 VALUES (4,&apos;user04&apos;);INSERT INTO t_user01 VALUES (5,&apos;user05&apos;);commit;mysql&gt; CREATE DATABASE testdb2 DEFAULT CHARSET utf8mb4; mysql&gt; use testdb2;CREATE TABLE t_user01( id int auto_increment primary key, name varchar(40)) ENGINE = InnoDB;INSERT INTO t_user01 VALUES (1,&apos;user01&apos;);INSERT INTO t_user01 VALUES (2,&apos;user02&apos;);INSERT INTO t_user01 VALUES (3,&apos;user03&apos;);INSERT INTO t_user01 VALUES (4,&apos;user04&apos;);INSERT INTO t_user01 VALUES (5,&apos;user05&apos;);commit; node2上创建mycat的授权用户 12mysql&gt; CREATE USER &apos;mycatuser&apos;@&apos;%&apos; IDENTIFIED BY &apos;mycat123..&apos;;mysql&gt; GRANT ALL PRIVILEGES ON *.* TO &apos;mycatuser&apos;@&apos;%&apos; IDENTIFIED BY &apos;mycat123..&apos;; node3上去掉readonly 1234# 由于需要测试写节点故障转移，所以去除只读配置[root@node3 ~]# vi /etc/my.cnfread_only = 0[root@node3 ~]# systemctl restart mysqld 配置mycat配置权限（server.xml） 12345678910111213141516171819202122232425262728293031# 备份配置文件[root@node1 ~]# cp /usr/local/mycat/conf/server.xml&#123;,.bak&#125;# 配置用户权限[root@node1 ~]# vi /usr/local/mycat/conf/server.xml &lt;!-- 文件最下方--&gt; &lt;!-- 配置mycat管理用户以及逻辑数据库，只有配置了用户对应的逻辑库，才可以访问--&gt; &lt;user name="root" defaultAccount="true"&gt; &lt;property name="password"&gt;123456&lt;/property&gt; &lt;property name="schemas"&gt;LOGICDB1,LOGICDB2&lt;/property&gt; &lt;property name="defaultSchema"&gt;LOGICDB1&lt;/property&gt; &lt;!-- 可配置详细权限，此处不配置--&gt; &lt;!-- 四个数字依次对应 insert,update,select,delete 的权限，0表示无权限，1表示有权限--&gt; &lt;!-- &lt;privileges check="false"&gt; &lt;schema name="LOGICDB" dml="0110" &gt; &lt;table name="tb01" dml="0000"&gt;&lt;/table&gt; &lt;table name="tb02" dml="1111"&gt;&lt;/table&gt; &lt;/schema&gt; &lt;/privileges&gt; --&gt; &lt;/user&gt; &lt;!-- 配置mycat只读用户以及逻辑数据库--&gt; &lt;user name="user"&gt; &lt;property name="password"&gt;user&lt;/property&gt; &lt;property name="schemas"&gt;LOGICDB1,LOGICDB2&lt;/property&gt; &lt;property name="readOnly"&gt;true&lt;/property&gt; &lt;property name="defaultSchema"&gt;LOGICDB1&lt;/property&gt; &lt;/user&gt; 配置读写分离（schema.xml） 123456789101112131415161718192021222324252627282930313233# 备份配置文件[root@node1 ~]# cp /usr/local/mycat/conf/schema.xml&#123;,.bak&#125;# 配置读写分离[root@node1 ~]# vi /usr/local/mycat/conf/schema.xml &lt;!-- 配置两个逻辑库以及数据节点 --&gt; &lt;schema name="LOGICDB1" checkSQLschema="true" sqlMaxLimit="100" randomDataNode="dn1" dataNode="dn1"&gt; &lt;/schema&gt; &lt;schema name="LOGICDB2" checkSQLschema="true" sqlMaxLimit="100" randomDataNode="dn2" dataNode="dn2"&gt; &lt;/schema&gt; &lt;!-- 配置数据节点（数据分片）对应的后端真实的数据库 --&gt; &lt;dataNode name="dn1" dataHost="dh1" database="testdb1" /&gt; &lt;dataNode name="dn2" dataHost="dh1" database="testdb2" /&gt; &lt;!-- 配置读写库以及均衡策略（balance）、故障切换策略（switchType） --&gt; &lt;!-- balance="3"，所有读请求随机的分发到 wiriterHost 对应的 readhost 执行 --&gt; &lt;!-- switchType="1"，默认值，故障时自动切换，不推荐，此处仅为测试 --&gt; &lt;dataHost name="dh1" maxCon="1000" minCon="10" balance="3" writeType="0" dbType="mysql" dbDriver="native" switchType="1" slaveThreshold="100"&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host="hostM1" url="192.168.1.172:3306" user="mycatuser" password="mycat123.."&gt; &lt;readHost host="hostS1" url="192.168.1.173:3306" user="mycatuser" password="mycat123.." weight="1"/&gt; &lt;/writeHost&gt; &lt;!-- 备用写节点 --&gt; &lt;writeHost host="hostM2" url="192.168.1.173:3306" user="mycatuser" password="mycat123.."/&gt; &lt;/dataHost&gt;# 重启mycat生效[root@node1 ~]# systemctl restart mycatd 验证修改日志级别 1234# 修改日志级别为debug[root@node1 ~]# sed -i 's/level="info"/level="debug"/g' /usr/local/mycat/conf/log4j2.xml # 重启mycat[root@node1 ~]# systemctl restart mycatd 测试读写分离操作数据库 12345678910111213141516171819202122232425262728293031323334[root@node1 ~]# mysql -uroot -p123456 -P8066 -h127.0.0.1mysql&gt; show databases;+----------+| DATABASE |+----------+| LOGICDB1 || LOGICDB2 |+----------+2 rows in set (0.01 sec)mysql&gt; use LOGICDB1;mysql&gt; show tables;+-------------------+| Tables_in_testdb1 |+-------------------+| t_user01 |+-------------------+1 row in set (0.01 sec)mysql&gt; select * from t_user01;+----+--------+| id | name |+----+--------+| 1 | user01 || 2 | user02 || 3 | user03 || 4 | user04 || 5 | user05 |+----+--------+5 rows in set (0.17 sec)mysql&gt; INSERT INTO t_user01 VALUES (6,&apos;user06&apos;);Query OK, 1 row affected (0.01 sec) 查看日志 1234567# 查看日志，可以看到select操作被发送到node3节点（slave），insert被发送到node2节点（master）[root@node1 ~]# vi /usr/local/mycat/logs/mycat.log2021-01-06 18:41:18.271 DEBUG [$_NIOREACTOR-0-RW] (io.mycat.server.NonBlockingSession.releaseConnection(NonBlockingSession.java:386)) - release connection MySQLConnection@1368884227 [id=11, lastTime=1609976478130, user=mycatuser, schema=testdb1, old shema=testdb1, borrowed=true, fromSlaveDB=true, threadId=13, charset=utf8, txIsolation=3, autocommit=true, attachment=dn1&#123;select * from t_user01&#125;, respHandler=SingleNodeHandler [node=dn1&#123;select * from t_user01&#125;, packetId=9], host=192.168.1.173, port=3306, statusSync=null, writeQueue=0, modifiedSQLExecuted=false]2021-01-06 18:43:55.855 DEBUG [$_NIOREACTOR-0-RW] (io.mycat.server.NonBlockingSession.releaseConnection(NonBlockingSession.java:386)) - release connection MySQLConnection@2088398114 [id=6, lastTime=1609976635842, user=mycatuser, schema=testdb1, old shema=testdb1, borrowed=true, fromSlaveDB=false, threadId=42, charset=utf8, txIsolation=3, autocommit=true, attachment=dn1&#123;INSERT INTO t_user01 VALUES (6,'user06')&#125;, respHandler=SingleNodeHandler [node=dn1&#123;INSERT INTO t_user01 VALUES (6,'user06')&#125;, packetId=1], host=192.168.1.172, port=3306, statusSync=null, writeQueue=0, modifiedSQLExecuted=true] 测试故障切换12# node2关闭mysql[root@node2 ~]# systemctl stop mysqld 操作数据库 12mysql&gt; INSERT INTO t_user01 VALUES (7,&apos;user07&apos;);Query OK, 1 row affected (0.00 sec) 查看日志 1234# 查看日志，可以看到insert被发送到node3节点[root@node1 ~]# vi /usr/local/mycat/logs/mycat.log2021-01-06 18:51:58.780 DEBUG [$_NIOREACTOR-0-RW] (io.mycat.server.NonBlockingSession.releaseConnection(NonBlockingSession.java:386)) - release connection MySQLConnection@2040837958 [id=15, lastTime=1609977118762, user=mycatuser, schema=testdb1, old shema=testdb1, borrowed=true, fromSlaveDB=false, threadId=15, charset=utf8, txIsolation=3, autocommit=true, attachment=dn1&#123;INSERT INTO t_user01 VALUES (7,'user07')&#125;, respHandler=SingleNodeHandler [node=dn1&#123;INSERT INTO t_user01 VALUES (7,'user07')&#125;, packetId=1], host=192.168.1.173, port=3306, statusSync=null, writeQueue=0, modifiedSQLExecuted=true] 附录mycat学习Mycat权威指南：http://111.11.227.72/cache/www.mycat.org.cn/document/mycat-definitive-guide.pdf?ich_args2=7-07075611030945_6e9bfa33679fcff272d52808502788da_10001002_9c8a6425dec4f6d59633518939a83798_4176e3eaeacddb20667f7015ddecd38f mycat核心配置：https://blog.51cto.com/zero01/2465837?source=drh yum安装mysql客户端1234567# 添加rpm源[root@node1 ~]# rpm -ivh https://repo.mysql.com//mysql57-community-release-el7-11.noarch.rpm[root@node1 ~]## 通过yum搜索[root@node1 ~]# yum search mysql-community# 安装x64位的 mysql客户端[root@node1 ~]# yum install mysql-community-client.x86_64 -y]]></content>
      <categories>
        <category>数据库基础</category>
      </categories>
      <tags>
        <tag>数据库基础</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL主从复制原理以及实验]]></title>
    <url>%2F2020%2F12%2F12%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%2FMySQL5.7_master-slave_replication%2F</url>
    <content type="text"><![CDATA[主从复制简介主从复制原理 复制一共分以下五个步骤 主节点（master） 开启二进制日志（binary log），并将数据库的改变记录到二进制日志中 （这些记录叫做二进制日志事件，binary log events） 从节点（slave） 开启一个线程（I/O Thread），请求主节点的二进制日志文件中的事件 master 启动一个线程（dump Thread），检查自己二进制日志中的事件，跟对方请求的位置对比，并将事件发送给 slave 的I/O线程 slave 的 I/O Thread 将 master 的二进制日志事件解析到它的中继日志（relay log） slave 的 sql Thread将中继日志事件还原并生成数据 复制中各个线程的作用从节点： I/O Thread：从 master 节点请求二进制日志事件，并保存于中继日志中 sql Thread：从 relay log 中读取日志事件并在本地完成重放 主节点： dump Thread：每个 slave 的 I/O Thread 都会启动一个 dump Thread，用于向从节点发送二进制事件 MySQL的四种同步方式异步复制（asynchronous）搭建简单，使用非常广泛，从mysql诞生之初，就产生了这种架构，性能非常好，可谓 非常成熟。 但是这种架构数据是异步的，所以有丢失数据库的风险。 全同步复制（fully synchronous） 保证数据安全，不丢数据，损失性能 传统半同步复制（semi synchronous）性能，功能都介于异步和全同步中间。从mysql5.5开始诞生，目的是为了折中上述两 种架构的性能以及优缺点。 无损复制 | 增强版的半同步复制（lossless replication）数据零丢失，性能好 ，mysql5.7开始支持，需安装插件 GTIDGTID特性GTID （Global Transaction Identifiers），对于一个已提交事务的全局编号，事务的唯一编号。GTID 和事务会记录到 binlog 中，用来标识事务。 GTID 是用来替代以前传统复制方法（binlog+position），可以避免同一个事务，在同一个节点中出现多次的情况。MySQL 5.6.2 开始支持 GTID GTID 的优势 根据 GTID 可以快速的确定事务最初是在哪个实例上提交的 简单的实现 failover，不用以前那样在需要找 log_file 和 log_pos 更简单的搭建主从复制，确保每个事务只会被执行一次 比传统的复制更加安全。 (5) GTID 的引入使运维更省事 GTID使用注意事项 因为基于 GTID 的复制依赖于事务，所以在使用 GTID 时，有些 MySQL 特性是不支持的 主从库的表存储引擎必须是一致的； 不支持非事务引擎（从库报错） 不支持 create table … select 语句复制（主库直接报错） 不允许在一个 SQL 同时更新一个事务引擎和非事务引擎的表 在一个复制组中，必须要求统一开启 GTID 或是关闭 GTID 开启 GTID 需要重启（5.7 中可能不需要） 开启 GTID 后，就不在使用原来的传统的复制方式 对于 create temporary table 和 drop temporary table 语句不支持 不支持 sql_slave_skip_counter 不推荐在 GTID 模式的实例上进行 mysql_upgrade，因为 mysql_upgrade 的过程要创建或修改系统表（非事务引擎），所以不建议在开启 GTID 的模式的实例上使用带 有–write-binlog 选项的 mysql_upgrade 准备准备三台安装了mysql的主机，结构图如下： 主机角色 IP 安装服务 角色 192.168.1.171 mysql 5.7 master 192.168.1.172 mysql 5.7 slave-1 192.168.1.173 mysql 5.7 slave-2 配置配置过程主节点（master） 启用二进制日志 为当前节点设置一个全局唯一的server_id 创建有复制权限（REPLIACTION SLAVE ,REPLIATION CLIENT）的用户账号 从节点（slave） 启动中继日志 为当前节点设置一个全局唯一的server_id 使用有复制权限的用户账号连接至主节点，并启动复制线程 配置master创建日志目录1234# 准备主机的binlog目录并授权[root@master ~]# mkdir -p /mysql/log/3306/binlog[root@master ~]# chown -R mysql:mysql /mysql/log/3306/binlog[root@master ~]# chmod -R 755 /mysql/log/3306/binlog 准备主库参数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# 在my.cnf后面添加以下参数[root@master ~]# vi /etc/my.cnfbind-address = 192.168.1.171server_id = 1713306skip_name_resolve = ONtransaction-isolation = READ-COMMITTED# 安装半同步模块插件plugin_dir = /mysql/app/mysql/lib/plugin/plugin_load = "rpl_semi_sync_master=semisync_master.so"# 配置binlog## binlog路径log_bin = /mysql/log/3306/binlog/testdb-binloglog_bin_index = /mysql/log/3306/binlog/testdb-binlog.index## 忽略哪些库的数据同步，一般同步不要同步mysql库，因为有很多用户名和密码# binlog-ignore-db=mysqlbinlog-ignore-db=sys# binlog格式binlog_format = ROW## 开启详细日志binlog_rows_query_log_events = on## 开启磁盘同步sync_binlog = 1## 开启分布式事务innodb_support_xa =1## 配置过期时间expire_logs_days = 7## binlog缓存大小，建议1~4Mbinlog_cache_size = 1M## binlog最大限制max_binlog_size = 2048M## 同步函数和存储过程log_bin_trust_function_creators = 1## 开启刷新log buffer，并flush到磁盘innodb_flush_log_at_trx_commit =1# 配置GPIDgtid_mode = ONenforce_gtid_consistency = 1log-slave-updates = 1binlog_gtid_simple_recovery = 1# 配置同步方式为增强半同步方式loose_rpl_semi_sync_master_enabled = 1loose_rpl_semi_sync_master_timeout = 5000rpl_semi_sync_master_wait_point = AFTER_SYNCrpl_semi_sync_master_wait_for_slave_count = 1# 重启mysql，使配置生效[root@master ~]# systemctl restart mysqld 创建复制用户并授权1234567891011[root@master ~]# mysql -uroot -pEnter password: # 创建用于主从复制的用户repusermysql&gt; CREATE USER &apos;repuser&apos;@&apos;%&apos; IDENTIFIED WITH mysql_native_password BY &apos;abc123..&apos;;Query OK, 0 rows affected (0.70 sec)# 授予repuser权限replication client以及replication slavemysql&gt; GRANT replication client, replication slave ON *.* TO &apos;repuser&apos;@&apos;%&apos;;Query OK, 0 rows affected (0.11 sec)# 刷新权限非必须mysql&gt; flush privileges;Query OK, 0 rows affected (0.37 sec) 检查状态123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778# 查看用户是否正常创建mysql&gt; SELECT user,host FROM mysql.user;+---------------+-----------+| user | host |+---------------+-----------+| repuser | % || root | % || mysql.session | localhost || mysql.sys | localhost || root | localhost |+---------------+-----------+5 rows in set (0.07 sec)# 查看binlog是否开启mysql&gt; show variables like &apos;log_bin&apos;;+---------------+-------+| Variable_name | Value |+---------------+-------+| log_bin | ON |+---------------+-------+1 row in set (0.14 sec)# 查看插件状态以及设置的参数是否都正常mysql&gt; show global variables like &apos;%master%&apos;;+-------------------------------------------+------------+| Variable_name | Value |+-------------------------------------------+------------+| master_info_repository | FILE || master_verify_checksum | OFF || rpl_semi_sync_master_enabled | ON || rpl_semi_sync_master_timeout | 5000 || rpl_semi_sync_master_trace_level | 32 || rpl_semi_sync_master_wait_for_slave_count | 1 || rpl_semi_sync_master_wait_no_slave | ON || rpl_semi_sync_master_wait_point | AFTER_SYNC || sync_master_info | 10000 |+-------------------------------------------+------------+9 rows in set (0.01 sec)# 查看master状态mysql&gt; show master status\G;*************************** 1. row *************************** File: testdb-binlog.000007 Position: 154 Binlog_Do_DB: Binlog_Ignore_DB: sysExecuted_Gtid_Set: 1 row in set (0.00 sec)ERROR: No query specified# 查看当前线程状态mysql&gt; show processlist\G;*************************** 1. row *************************** Id: 2 User: repuser Host: 192.168.1.172:59606 db: NULLCommand: Binlog Dump GTID Time: 419 State: Master has sent all binlog to slave; waiting for more updates Info: NULL*************************** 2. row *************************** Id: 3 User: root Host: localhost db: NULLCommand: Query Time: 0 State: starting Info: show processlist2 rows in set (0.00 sec)ERROR: No query specified 配置slave 两台 slave 都配置 创建日志目录1234# 准备从机的relaylog目录[root@slave-1 ~]# mkdir -p /mysql/log/3306/relaylog[root@slave-1 ~]# chown -R mysql:mysql /mysql/log/3306/relaylog[root@slave-1 ~]# chmod -R 755 /mysql/log/3306/relaylog 准备从库参数1234567891011121314151617181920212223242526272829# 在my.cnf后面添加以下参数[root@slave-1 ~]# vi /etc/my.cnf# 绑定IP，根据实际修改bind-address = 192.168.1.172# 全局ID，根据实际修改，此处配置为：IP最后一段+端口server_id = 1723306skip_name_resolve = ON# 配置只读模式read_only = 1# 配置插件plugin_dir = /mysql/app/mysql/lib/plugin/plugin_load = "rpl_semi_sync_slave=semisync_slave.so"# 配置GTIDgtid_mode = ONenforce_gtid_consistency = 1# log-slave-updates = 1# binlog_gtid_simple_recovery = 1# 配置relaylogrelay_log = /mysql/log/3306/relaylog/testdb-relay.log# 配置同步方式为增强半同步（无损同步）loose_rpl_semi_sync_slave_enabled = 1# 重启使参数生效[root@slave-1 ~]# systemctl restart mysqld 在从库上发起与主库的连接1234567891011121314151617181920[root@slave-1 ~]# mysql -uroot -pEnter password: # 清除slave配置mysql&gt; stop slave;mysql&gt; reset master;mysql&gt; reset slave;# 修改master参数mysql&gt; change master tomaster_host=&apos;192.168.1.171&apos;,master_port=3306,master_user=&apos;repuser&apos;,master_password=&apos;abc123..&apos;,master_auto_position=1;# 启动slavemysql&gt; start slave;Query OK, 0 rows affected (0.04 sec) 检查状态1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798# 查看slave状态，I/O Thread 和 SQL Thread都要处于运行状态mysql&gt; show slave status \G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.1.171 Master_User: repuser Master_Port: 3306 Connect_Retry: 60 Master_Log_File: testdb-binlog.000006 Read_Master_Log_Pos: 154 Relay_Log_File: testdb-relay.000002 Relay_Log_Pos: 375 Relay_Master_Log_File: testdb-binlog.000006 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 154 Relay_Log_Space: 579 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1713306 Master_UUID: cb3ba17a-3a94-11eb-90ee-000c29251f98 Master_Info_File: /mysql/data/3306/data/master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 1 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version: 1 row in set (0.00 sec)ERROR: No query specifiedmysql&gt; show processlist\G;*************************** 1. row *************************** Id: 2 User: root Host: localhost db: NULLCommand: Query Time: 0 State: starting Info: show processlist*************************** 2. row *************************** Id: 3 User: system user Host: db: NULLCommand: Connect Time: 476 State: Waiting for master to send event Info: NULL*************************** 3. row *************************** Id: 4 User: system user Host: db: NULLCommand: Connect Time: 476 State: Slave has read all relay log; waiting for more updates Info: NULL3 rows in set (0.00 sec)ERROR: No query specified 验证主库操作数据1234567891011121314151617mysql&gt; CREATE DATABASE testdb DEFAULT CHARSET utf8mb4; mysql&gt; CREATE USER &apos;testuser&apos;@&apos;%&apos; IDENTIFIED BY &apos;qwert123&apos;;mysql&gt; GRANT ALL PRIVILEGES ON testdb.* TO &apos;testuser&apos;@&apos;%&apos; IDENTIFIED BY &apos;qwert123&apos;; mysql&gt; flush privileges;use testdb;CREATE TABLE t_user01( id int auto_increment primary key, name varchar(40)) ENGINE = InnoDB;INSERT INTO t_user01 VALUES (1,&apos;user01&apos;);INSERT INTO t_user01 VALUES (2,&apos;user02&apos;);INSERT INTO t_user01 VALUES (3,&apos;user03&apos;);INSERT INTO t_user01 VALUES (4,&apos;user04&apos;);INSERT INTO t_user01 VALUES (5,&apos;user05&apos;);commit; 备库查询123456789101112131415161718192021222324252627282930313233343536[root@slave-1 ~]# mysql -utestuser -pEnter password: # 查看数据库，可以看到testdb同步过来了mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || testdb |+--------------------+2 rows in set (0.00 sec)# 进入数据库，查看表已经同步过来mysql&gt; use testdb;Database changedmysql&gt; show tables;+------------------+| Tables_in_testdb |+------------------+| t_user01 |+------------------+1 row in set (0.00 sec)# 数据也同步过来了mysql&gt; SELECT * FROM t_user01;+----+--------+| id | name |+----+--------+| 1 | user01 || 2 | user02 || 3 | user03 || 4 | user04 || 5 | user05 |+----+--------+5 rows in set (0.00 sec) my.cnf常用参数基本参数12345678910111213141516171819# 绑定地址bind-address = 192.168.1.172# 数据同步的唯一ID（此处为IP最后一段+端口）server_id = 1723306# 跳过主机名域名解析skip_name_resolve = ON# 事务隔离级别（读已提交）transaction-isolation = READ-COMMITTED# 是否只读read_only = 1# 插件路径plugin_dir = /mysql/app/mysql/lib/plugin/# 加载插件，此处以加载主从复制插件为例plugin_load = "rpl_semi_sync_master=semisync_master.so;rpl_semi_sync_slave=semisync_slave.so" 关于binlog参数1234567891011121314151617181920212223242526272829303132333435# 二进制日志binlog路径以及索引路径log_bin = /mysql/log/3306/binlog/testdb-binloglog_bin_index = /mysql/log/3306/binlog/testdb-binlog.index# 忽略哪些库的数据同步，一般同步不要同步mysql库，因为有很多用户名和密码binlog-ignore-db=mysqlbinlog-ignore-db=sys# binlog格式binlog_format = ROW# 记录更详细的sql操作binlog_rows_query_log_events = on# 默认为1，每次提交事务时将binlog同步到磁盘上，防止崩溃丢失sync_binlog = 1# 默认为1，每次提交事务时将log buffer的数据写到log file，并flush到磁盘innodb_flush_log_at_trx_commit =1# 默认为0，不同步函数和存储过程log_bin_trust_function_creators = 1# binlog大小限制，默认1024Mmax_binlog_size = 2048M# binlog保存时间，单位：天expire_logs_days = 7# binlog缓存大小，默认32k，建议 1~4 Mbinlog_cache_size = 1M# 默认为1，分布式事务支持，确保事务日志写入bin-log的顺序与事务的time-line一致innodb_support_xa =1 关于relaylog日志参数123456789# 中继日志relaylog路径relay_log = /mysql/log/3306/relaylog/testdb-relay.log# 开启崩溃恢复模式relay-log-recover = 1# 默认file，配置table，将relay-info写入到mysql.salve_relay_log_info这张表，确保SQL线程安全relay_log_info_repository = table# 默认file，配置table，将master-info写入到mysql.salve_master_info这张表，确保IO线程安全master_info_repository = table 关于同步方式的参数12345678910111213141516# 使用增强半同步复制（无损复制）# mysql5.6 开启master的半同步方式：rpl_semi_sync_master_enabled = 1loose_rpl_semi_sync_master_enabled = 1# mysql5.6 开启slave的半同步方式：rpl_semi_sync_slave_enabled = 1loose_rpl_semi_sync_slave_enabled = 1# 半同步复制超时时间，5S后切回异步，master配置loose_rpl_semi_sync_master_timeout = 5000# 至少收到1个slave的ack回复，master配置rpl_semi_sync_master_wait_for_slave_count = 1# mysql5.7 开启无损复制的方式（推荐），master配置rpl_semi_sync_master_wait_point = AFTER_SYNC# mysql5.7 开启半同步复制的方式，master配置rpl_semi_sync_master_wait_point = AFTER_COMMIT 关于GTID的参数12345678910111213141516171819202122232425262728# gtid模式# ON：产生GTID，slave只接受带GTID的事务# ON_PERMISSIVE：产生GTID，slave既接受带GTID的事务，也接受不带GTID的事务# OFF：不产生GTID，slave只接受不带GTID的事务# OFF_PERMISSIVE：不产生GTID，slave既接受带GTID的事务，也接受不带GTID的事务gtid_mode = ON# 检查事务是否支持GTID# ON（1）：检查，并返回错误信息# WARN：检查，返回警告，并在日志中记录# OFF（0）：不检查enforce_gtid_consistency = 1# 开启log-slave-updates，从库binlog会记录来源于主库的操作日志，多用于级联slavelog-slave-updates = 1# 默认为1，mysql启动或者重启时快速执行恢复binlog_gtid_simple_recovery = 1# 控制表压缩率gtid_executed_compression_period# 获取下一个事务的方式，automatic为自动获取gtid_next:automatic# 执行事务的gtid对应线程idgtid_owned: 思考从节点需要建立二进制日志文件吗？如果从节点需要作为其他节点的主节点时，是需要开启二进制日志文件的。这种情况叫做级联复制。如果只是作为从节点，则不需要创建二进制文件]]></content>
      <categories>
        <category>数据库基础</category>
      </categories>
      <tags>
        <tag>数据库基础</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 安装 MySQL 5.7]]></title>
    <url>%2F2020%2F12%2F08%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%2FMySQL5.7_install%2F</url>
    <content type="text"><![CDATA[环境主机：CentOS Linux release 7.9.2009 (Core) Minimal Install 使用Linux - Generic TAR 包安装 mysql 压缩包官网下载地址：https://downloads.mysql.com/archives/community/ Select Version:5.7.31 Select Operating System:Linux - Generic Select OS Version:Linux - Generic (glibc 2.12) (x86, 64-bit) 列表中下载： Compressed TAR Archive：mysql-5.7.31-linux-glibc2.12-x86_64.tar.gz 准备关闭防火墙和selinux 12345systemctl stop firewalldsystemctl disable firewalldsetenforce 0sed -i 's/=enforcing/=disabled/g' /etc/sysconfig/selinux 卸载系统自带的mariadb 12345# 查看系统自带的Mariadb[root@node1 ~]# rpm -qa | grep mariadbmariadb-libs-5.5.68-1.el7.x86_64# 卸载系统自带的Mariadb[root@node1 ~]# rpm -e --nodeps mariadb-libs-5.5.68-1.el7.x86_64 创建安装路径 123456# mysql程序目录[root@node1 ~]# mkdir -p /mysql/app# mysql数据目录[root@node1 ~]# mkdir -p /mysql/data/3306# mysql日志目录[root@node1 ~]# mkdir -p /mysql/log/3306 创建用户和组并授权 123456# 创建用户组[root@node1 ~]# groupadd -g 1001 mysql# 创建系统用户，默认无shell[root@node1 ~]# useradd -r -g mysql -s /bin/false -u 1001 mysql# 目录授权[root@node1 ~]# chown -R mysql:mysql /mysql 安装上传解压mysql压缩包 1234# 解压安装包[root@node1 ~]# tar -zxvf mysql-5.7.31-linux-glibc2.12-x86_64.tar.gz -C /mysql/app/# 重命名安装包[root@node1 ~]# mv /mysql/app/mysql-5.7.31-linux-glibc2.12-x86_64/ /mysql/app/mysql 创建配置文件my.cnf 1234567891011121314151617181920212223242526272829303132333435[root@node1 ~]# vi /mysql/data/3306/my.cnf[mysql]# set mysql client default chararterdefault-character-set=utf8socket=/mysql/data/3306/mysql.sock[mysqld]# set mysql server port port=3306socket=/mysql/data/3306/mysql.sock# set mysql install base dirbasedir=/mysql/app/mysql# set the data store dirdatadir=/mysql/data/3306/data# set the number of allow max connnectionmax_connections=200# set server charactre default encodingcharacter-set-server=utf8# the storage enginedefault-storage-engine=INNODBinnodb_buffer_pool_size=200Mlower_case_table_names=1max_allowed_packet=16Mexplicit_defaults_for_timestamp=truelog-output=FILEgeneral_log=0general_log_file=/myysql/log/3306/db-general.errslow_query_log=ONslow_query_log_file=/mysql/log/3306/db-query.errlong_query_time=10log-error=/mysql/log/3306/db-error.err# 创建配置文件软链接[root@node1 ~]# ln -sf /mysql/data/3306/my.cnf /etc/my.cnf 初始化 123456789101112# 初始化[root@node1 ~]# /mysql/app/mysql/bin/mysqld --initialize --user=mysql --basedir=/mysql/app/mysql/ --datadir=/mysql/data/3306/data/# 查看初始化root密码[root@node1 ~]# cat /mysql/log/3306/db-error.err 2020-12-05T18:46:13.226586Z 0 [Warning] InnoDB: New log files created, LSN=457902020-12-05T18:46:13.271620Z 0 [Warning] InnoDB: Creating foreign key constraint system tables.2020-12-05T18:46:13.344337Z 0 [Warning] No existing UUID has been found, so we assume that this is the first time that this server has been started. Generating a new UUID: 262b1196-372a-11eb-8924-000c29251f98.2020-12-05T18:46:13.345989Z 0 [Warning] Gtid table is not ready to be used. Table 'mysql.gtid_executed' cannot be opened.2020-12-05T18:46:14.341174Z 0 [Warning] CA certificate ca.pem is self signed.2020-12-05T18:46:14.473638Z 1 [Note] A temporary password is generated for root@localhost: y.zI8QQTRjs7 至此，mysql安装完成 后期设置加入systemd管理 123456789101112131415161718192021222324252627[root@node1 ~]# vi /usr/lib/systemd/system/mysqld.service[Unit]Description=MySQL Community ServerDocumentation=man:mysqld(8)Documentation=http://dev.mysql.com/doc/refman/en/using-systemd.htmlAfter=network.targetAfter=syslog.target[Install]WantedBy=multi-user.targetAlias=mysql.service[Service]User=mysqlGroup=mysql# 指定Type=forking则要配置PID或者指定守护进程(daemonize)运行Type=forkingPermissionsStartOnly=trueExecStart=/mysql/app/mysql/bin/mysqld --defaults-file=/mysql/data/3306/my.cnf --daemonizeLimitNOFILE = 65536LimitNPROC = 65536 # 重新加载systemd文件[root@node1 ~]# systemctl daemon-reload 配置环境变量（全局） 1234567# 在/etc/profile最后添加 export PATH=$PATH:/mysql/app/mysql/bin/[root@node1 ~]# vi /etc/profile.d/mysql.sh# set mysql environmentexport PATH=$PATH:/mysql/app/mysql/bin/# 重新加载/etc/profile[root@node1 ~]# source /etc/profile 修改密码并授权 1234567891011121314151617# 开启mysql[root@node1 ~]# systemctl start mysqld# 登录mysql[root@node1 ~]# mysql -uroot -pEnter password: # 此处输入初始化密码# 设置root用户新密码为qwert123..mysql&gt; SET PASSWORD=PASSWORD("qwert123..");Query OK, 0 rows affected, 1 warning (0.00 sec)# 授予root与用户所有数据库（表）、所有主机登录的权限mysql&gt; GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'qwert123..' WITH GRANT OPTION;Query OK, 0 rows affected, 1 warning (0.00 sec)# 刷新权限mysql&gt; FLUSH PRIVILEGES;Query OK, 0 rows affected (0.16 sec) 常用操作登录12[root@node1 ~]# mysql -uroot -p -h 192.168.1.171Enter password: 创建数据库123# 创建数据库testdbmysql&gt; CREATE DATABASE testdb DEFAULT CHARSET utf8mb4; Query OK, 1 row affected (0.33 sec) 创建用户并授权1234567授权格式：GRANT [权限] ON [库.表] TO [用户名]@[IP] IDENTIFIED BY [密码] # WITH GRANT OPTION; 1234567891011# 创建用户testuser，密码为qwert123mysql&gt; CREATE USER &apos;testuser&apos;@&apos;%&apos; IDENTIFIED BY &apos;qwert123&apos;;Query OK, 0 rows affected (0.41 sec)# 授予testuser在所有主机登录、以及数据库testdb的权限mysql&gt; GRANT ALL PRIVILEGES ON testdb.* TO &apos;testuser&apos;@&apos;%&apos; IDENTIFIED BY &apos;qwert123&apos;; Query OK, 0 rows affected, 1 warning (0.27 sec)# 刷新权限mysql&gt; FLUSH PRIVILEGES;Query OK, 0 rows affected (0.16 sec) 查看所有用户1234567891011mysql&gt; SELECT HOST,USER FROM mysql.user;+-----------+---------------+| HOST | USER |+-----------+---------------+| % | root || % | testuser || localhost | mysql.session || localhost | mysql.sys || localhost | root |+-----------+---------------+5 rows in set (0.32 sec) 查看用户权限1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# 查看简略信息mysql&gt; SHOW GRANTS FOR testuser;+------------------------------------------------------+| Grants for testuser@% |+------------------------------------------------------+| GRANT USAGE ON *.* TO &apos;testuser&apos;@&apos;%&apos; || GRANT ALL PRIVILEGES ON `testdb`.* TO &apos;testuser&apos;@&apos;%&apos; |+------------------------------------------------------+2 rows in set (0.30 sec)# 查看详细信息mysql&gt; SELECT * FROM mysql.user WHERE user=&apos;testuser&apos;\G;*************************** 1. row *************************** Host: % User: testuser Select_priv: N Insert_priv: N Update_priv: N Delete_priv: N Create_priv: N Drop_priv: N Reload_priv: N Shutdown_priv: N Process_priv: N File_priv: N Grant_priv: N References_priv: N Index_priv: N Alter_priv: N Show_db_priv: N Super_priv: N Create_tmp_table_priv: N Lock_tables_priv: N Execute_priv: N Repl_slave_priv: N Repl_client_priv: N Create_view_priv: N Show_view_priv: N Create_routine_priv: N Alter_routine_priv: N Create_user_priv: N Event_priv: N Trigger_priv: NCreate_tablespace_priv: N ssl_type: ssl_cipher: x509_issuer: x509_subject: max_questions: 0 max_updates: 0 max_connections: 0 max_user_connections: 0 plugin: mysql_native_password authentication_string: *CA57CBD0790575D1668CC58E7ECB5D23A8C77608 password_expired: N password_last_changed: 2020-12-08 09:57:51 password_lifetime: NULL account_locked: N1 row in set (0.00 sec)ERROR: No query specified 创建表123456mysql&gt; USE testdb;CREATE TABLE t_user01( id int auto_increment primary key, name varchar(15)) ENGINE = InnoDB; 插入数据123456INSERT INTO t_user01 VALUES (1,&apos;user01&apos;);INSERT INTO t_user01 VALUES (2,&apos;user02&apos;);INSERT INTO t_user01 VALUES (3,&apos;user03&apos;);INSERT INTO t_user01 VALUES (4,&apos;user04&apos;);INSERT INTO t_user01 VALUES (5,&apos;user05&apos;);commit; 查询数据1234567891011mysql&gt; SELECT * FROM testdb.t_user01;+----+--------+| id | name |+----+--------+| 1 | user01 || 2 | user02 || 3 | user03 || 4 | user04 || 5 | user05 |+----+--------+5 rows in set (0.28 sec)]]></content>
      <categories>
        <category>数据库基础</category>
      </categories>
      <tags>
        <tag>数据库基础</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[华为交换机stp配置]]></title>
    <url>%2F2020%2F12%2F05%2F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%2Fhw_stp%2F</url>
    <content type="text"><![CDATA[简介生成树协议用于在一个存在冗余路径的以太网中为终端构建没有环路的交换路径。常用的生成树协议有 生成树协议（Spanning Tree Protocol，STP） 快速生成树协议（Rapid Spanning Tree Protocol，RSTP） 多生成树协议（Multiple Spanning Tree Protocol，MSTP） 其中，STP和RSTP基于以太网构建生成树，MSTP可以基于VLAN构建生成树 本篇主要实验STP简单配置 网络拓扑 交换机优先级 交换机 优先级 S4 4096（根网桥） S2 8192 S3 12288 S5 16384 S6 20480 S1 32768（默认值） S7 32768（默认值） 根据网络拓扑和交换机优先级，可以预测配置生成树协议后的阻塞端口 交换机 阻塞端口 S1 0/0/2 S3 0/0/1 S5 0/0/1 S6 0/0/1 S7 0/0/1 配置S1配置 1234&lt;Huawei&gt;system-view [Huawei]undo info-center enable [Huawei]stp mode stp[Huawei]stp enable S2配置 12345678&lt;Huawei&gt;system-view [Huawei]undo info-center enable # 配置stp模式[Huawei]stp mode stp# 配置stp优先级[Huawei]stp priority 8192# 开启stp[Huawei]stp enable S3配置 12345&lt;Huawei&gt;system-view [Huawei]undo info-center enable [Huawei]stp mode stp[Huawei]stp priority 12288[Huawei]stp enable S4配置 12345&lt;Huawei&gt;system-view [Huawei]undo info-center enable [Huawei]stp mode stp[Huawei]stp priority 4096[Huawei]stp enable S5配置 12345&lt;Huawei&gt;system-view [Huawei]undo info-center enable [Huawei]stp mode stp[Huawei]stp priority 16384[Huawei]stp enable S6配置 12345&lt;Huawei&gt;system-view [Huawei]undo info-center enable [Huawei]stp mode stp[Huawei]stp priority 20480[Huawei]stp enable S7配置 1234&lt;Huawei&gt;system-view [Huawei]undo info-center enable [Huawei]stp mode stp[Huawei]stp enable 验证查看端口状态是否与预期一致S1 1234[Huawei]display stp brief MSTID Port Role STP State Protection 0 GigabitEthernet0/0/1 ROOT FORWARDING NONE 0 GigabitEthernet0/0/2 ALTE DISCARDING NONE S3 123456[Huawei]dis stp brief MSTID Port Role STP State Protection 0 GigabitEthernet0/0/1 ALTE DISCARDING NONE 0 GigabitEthernet0/0/2 DESI FORWARDING NONE 0 GigabitEthernet0/0/3 DESI FORWARDING NONE 0 GigabitEthernet0/0/24 ROOT FORWARDING NONE S5 1234567[Huawei]dis stp brief MSTID Port Role STP State Protection 0 GigabitEthernet0/0/1 ALTE DISCARDING NONE 0 GigabitEthernet0/0/2 DESI FORWARDING NONE 0 GigabitEthernet0/0/3 ROOT FORWARDING NONE 0 GigabitEthernet0/0/4 DESI FORWARDING NONE 0 GigabitEthernet0/0/15 DESI FORWARDING NONE S6 123456[Huawei]display stp brief MSTID Port Role STP State Protection 0 GigabitEthernet0/0/1 ALTE DISCARDING NONE 0 GigabitEthernet0/0/2 ALTE DISCARDING NONE 0 GigabitEthernet0/0/3 DESI FORWARDING NONE 0 GigabitEthernet0/0/24 ROOT FORWARDING NONE S7 1234[Huawei]dis stp brief MSTID Port Role STP State Protection 0 GigabitEthernet0/0/1 ALTE DISCARDING NONE 0 GigabitEthernet0/0/2 ROOT FORWARDING NONE STP生成拓扑如下图所示，与预期一致 验证重新构建生成树删除物理链路，形成如下拓扑 查看STP重新调整的阻塞端口S1 1234[Huawei]display stp brief MSTID Port Role STP State Protection 0 GigabitEthernet0/0/1 ROOT FORWARDING NONE 0 GigabitEthernet0/0/2 ALTE DISCARDING NONE S3 123456[Huawei]dis stp brief MSTID Port Role STP State Protection 0 GigabitEthernet0/0/1 ALTE DISCARDING NONE 0 GigabitEthernet0/0/2 DESI FORWARDING NONE 0 GigabitEthernet0/0/3 DESI FORWARDING NONE 0 GigabitEthernet0/0/24 ROOT FORWARDING NONE S5 12345[Huawei]dis stp brief MSTID Port Role STP State Protection 0 GigabitEthernet0/0/1 ROOT FORWARDING NONE 0 GigabitEthernet0/0/2 ALTE DISCARDING NONE 0 GigabitEthernet0/0/15 DESI FORWARDING NONE S6 123456[Huawei]display stp brief MSTID Port Role STP State Protection 0 GigabitEthernet0/0/1 ALTE DISCARDING NONE 0 GigabitEthernet0/0/2 DESI FORWARDING NONE 0 GigabitEthernet0/0/3 DESI FORWARDING NONE 0 GigabitEthernet0/0/24 ROOT FORWARDING NONE S7 123[Huawei]display stp brief MSTID Port Role STP State Protection 0 GigabitEthernet0/0/1 ROOT FORWARDING NONE STP生成拓扑如下图所示 ensp拓扑下载链接：https://pan.baidu.com/s/1zkBTY51DdmMzl5O2ziwL7g提取码：t8se]]></content>
      <categories>
        <category>网络基础</category>
      </categories>
      <tags>
        <tag>网络基础</tag>
        <tag>交换机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[华为交换机mux vlan介绍以及配置]]></title>
    <url>%2F2020%2F11%2F26%2F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%2Fhw_mux_vlan%2F</url>
    <content type="text"><![CDATA[MUX VLAN简介MUX VLAN（Multiplex VLAN）是一种在第二层实现流量隔离的机制。在MUX VLAN机制下，可以创建一个主VLAN和多个从VLAN，这些从VLAN又可以分为一个孤立VLAN和多个团VLAN，具有以下通信特点： 属于从VLAN（包括孤立VLAN和团VLAN）的终端可以和主VLAN终端通信 属于孤立VLAN的终端之间不能相互通信 属于孤立VLAN的终端不可以和团VLAN终端通信 属于同一团VLAN的终端之间可以相互通信 以下实验将验证MUX VLAN的这些特点 网络拓扑图 IP以及VLAN划分MUX VLAN划分 VLAN ID 属性 2 主VLAN 3 孤立VLAN 4 团VLAN 交换机端口划分 交换机 端口 端口类型 VLAN设置 对端设备 SW1 0/0/1 access 3 PC1 SW1 0/0/2 access 3 PC2 SW1 0/0/3 access 4 PC3 SW1 0/0/4 access 4 PC4 SW1 0/0/24 access 2 Server1 设备IP 设备 IP 服务器 192.168.1.200 PC1 192.168.1.11 PC2 192.168.1.12 PC3 192.168.1.13 PC4 192.168.1.14 配置12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;Huawei&gt;system-view Enter system view, return user view with Ctrl+Z.[Huawei]undo info-center enable Info: Information center is disabled.[Huawei]vlan batch 2 to 4Info: This operation may take a few seconds. Please wait for a moment...done.# 配置vlan2为主vlan，vlan3为孤立vlan，vlan4为团vlan[Huawei]vlan 2[Huawei-vlan2]mux-vlan[Huawei-vlan2]subordinate separate 3 [Huawei-vlan2]subordinate group 4[Huawei-vlan2]quit# 配置各个端口的默认vlan，同时开启支持mux-vlan[Huawei]interface GigabitEthernet 0/0/1[Huawei-GigabitEthernet0/0/1]port link-type access [Huawei-GigabitEthernet0/0/1]port default vlan 3[Huawei-GigabitEthernet0/0/1]port mux-vlan enable [Huawei-GigabitEthernet0/0/1]quit[Huawei]interface GigabitEthernet 0/0/2[Huawei-GigabitEthernet0/0/1]port link-type access [Huawei-GigabitEthernet0/0/1]port default vlan 3[Huawei-GigabitEthernet0/0/1]port mux-vlan enable [Huawei-GigabitEthernet0/0/1]quit[Huawei]interface GigabitEthernet 0/0/3[Huawei-GigabitEthernet0/0/3]port link-type access[Huawei-GigabitEthernet0/0/3]port default vlan 4[Huawei-GigabitEthernet0/0/3]port mux-vlan enable[Huawei-GigabitEthernet0/0/3]quit[Huawei]interface GigabitEthernet 0/0/4[Huawei-GigabitEthernet0/0/4]port link-type access[Huawei-GigabitEthernet0/0/4]port default vlan 4[Huawei-GigabitEthernet0/0/4]port mux-vlan enable[Huawei-GigabitEthernet0/0/4]quit[Huawei]interface GigabitEthernet 0/0/24[Huawei-GigabitEthernet0/0/24]port link-type access[Huawei-GigabitEthernet0/0/24]port default vlan 2[Huawei-GigabitEthernet0/0/24]port mux-vlan enable[Huawei-GigabitEthernet0/0/24]quit[Huawei]quit&lt;Huawei&gt;save 验证使用孤立VLAN下的PC1（192.168.1.11）去ping同属于孤立VLAN的PC2（192.168.1.12），无法ping通 使用孤立VLAN下的PC1（192.168.1.11）去ping主VLAN的Server1(192.168.1.200)，可以ping通 与预期相符合 使用孤立VLAN下的PC1（192.168.1.11）去ping同属于团VLAN的PC3（192.168.1.13），无法ping通 与预期相符合 使用团VLAN下的PC3（192.168.1.13）去ping同属于团VLAN的PC4（192.168.1.14），可以ping通 使用团VLAN下的PC3（192.168.1.11）去ping主VLAN的Server1(192.168.1.200)，可以ping通 与预期相符合 ensp拓扑下载链接：https://pan.baidu.com/s/1ibPRlxa_-G64oHg0WMV8fA提取码：3qy8]]></content>
      <categories>
        <category>网络基础</category>
      </categories>
      <tags>
        <tag>网络基础</tag>
        <tag>交换机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 下 Oracle12c 图形化界面安装]]></title>
    <url>%2F2020%2F11%2F26%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%2Foracle12c_install%2F</url>
    <content type="text"><![CDATA[准备 主机：IP 操作系统 角色 192.168.1.174 CentOS Linux release 7.8.2003 (Core) Minimal Install oracle服务端 192.168.1.240 Windows 10 专业工作站版 2004 plsql客户端 基础配置配置主机名 1[root@localhost ~]# hostnamectl set-hostname oracledb 配置时区 1[root@oracledb ~]# timedatectl set-timezone Asia/Shanghai 关闭防火墙和selinux 123456[root@oracledb ~]# systemctl stop firewalld[root@oracledb ~]# systemctl disable firewalld[root@oracledb ~]# setenforce 0[root@oracledb ~]# sed -i 's/=enforcing/=disabled/g' /etc/sysconfig/selinux 关闭NetworkManager 12[root@oracledb ~]# systemctl stop NetworkManager[root@oracledb ~]# systemctl disable NetworkManager 配置yum源备份 1[root@oracledb ~]# mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 下载新的 CentOS-Base.repo 到 /etc/yum.repos.d/ 1[root@oracledb ~]# curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo 生成缓存 1[root@oracledb ~]# yum makecache 安装一些常用工具 1[root@oracledb ~]# yum install -y wget vim oracle适配安装oracle所需依赖 1[root@oracledb ~]# yum install -y binutils compat-libcap1 compat-libstdc++-33 gcc gcc-c++ glibc glibc-devel ksh make sysstat unixODBC unixODBC-devel libgcc libstdc++ libstdc++-devel libaio libaio-devel libXp 建立用户和组 如果要安装Oracle数据库，则需要以下本地操作系统组和用户： Oracle inventory组(通常为 oinstall) OSDBA组 (通常为 dba) OSOPER组 (通常为 oper) Oracle软件所有者(通常为 oracle） 1234567[root@oracledb ~]# groupadd oinstall[root@oracledb ~]# groupadd dba[root@oracledb ~]# groupadd oper[root@oracledb ~]# useradd -g oinstall -G dba,oper oracle# 设置oracle用户的登录密码[root@oracledb ~]# echo "123456" | passwd --stdin oracle 创建安装目录 123[root@oracledb ~]# mkdir -p /orcl/app/[root@oracledb ~]# chown -R oracle:oinstall /orcl/app/[root@oracledb ~]# chmod -R 775 /orcl/app/ 修改内核参数 123456789101112131415[root@oracledb ~]# vim /etc/sysctl.conf# 添加以下参数fs.aio-max-nr = 1048576 fs.file-max = 6815744 kernel.shmall = 2097152 kernel.shmmax = 1200000000 kernel.shmmni = 4096 kernel.sem = 250 32000 100 128 net.ipv4.ip_local_port_range = 9000 65500 net.core.rmem_default = 262144 net.core.rmem_max = 4194304 net.core.wmem_default = 262144 net.core.wmem_max = 1048576# 重新载入配置[root@oracledb ~]# sysctl -p 修改连接限制和打开文件限制 123456789101112131415161718192021222324252627282930[root@oracledb ~]# vim /etc/security/limits.conf# 添加以下参数oracle soft nproc 2047oracle hard nproc 16384oracle soft nofile 1024oracle hard nofile 65536oracle soft stack 10240[root@oracledb ~]# vim /etc/pam.d/login# 添加以下参数session required pam_limits.sosession required /lib64/security/pam_limits.so# 修改oracle用户资源限制# 指定管道缓冲区大小16384# 修改同一时间可开启文件数65536[root@oracledb ~]# vim /etc/profile# 添加以下参数if [ $USER = "oracle" ]; then if [ $SHELL = "/bin/ksh" ]; then ulimit -p 16384 ulimit -n 65536 else ulimit -u 16384 -n 65536 fi fi[root@oracledb ~]# source /etc/profile 修改oracle用户环境变量 123456789101112[root@oracledb ~]# vim /home/oracle/.bash_profileORACLE_BASE=/orcl/app/oracle ORACLE_HOME=$ORACLE_BASE/product/12.2.0ORACLE_SID=orcl export ORACLE_BASE ORACLE_HOME ORACLE_SID PATH=$ORACLE_HOME/bin:$PATH export PATH DISPLAY=:0.0export DISPLAY[root@oracledb ~]# xhost + 卸载系统自带的open-jdk，安装oracle-jdk 网址：https://www.oracle.com/java/technologies/javase-downloads.html 根据需要下载对应版本，此处下载Java SE 11 12345[root@oracledb ~]# yum remove jdk# 下载对应的jdk（rpm或压缩包）并上传到服务器[root@oracledb ~]# rpm -ivh jdk-11.0.9_linux-x64_bin.rpm 安装界面 123[root@oracledb ~]# yum groupinstall -y "X Window System"yum groupinstall -y "GNOME Desktop" 增加swap空间 1234567891011121314151617181920212223242526# 此处swap为2G，oracle12c需要swap为2.67G[root@oracledb ~]# free total used free shared buff/cache availableMem: 1863012 850396 68524 29640 944092 825836Swap: 2097148 0 2097148# 增加1G swap# 创建一个1G文件[root@oracledb ~]# dd if=/dev/zero of=/home/swap bs=1024 count=10485761048576+0 records in1048576+0 records out1073741824 bytes (1.1 GB) copied, 4.21729 s, 255 MB/s# 格式化成swap文件类型[root@oracledb ~]# mkswap /home/swapSetting up swapspace version 1, size = 1048572 KiBno label, UUID=e1bf10ce-ebaf-4ead-9343-1cf58736661f# 扩容[root@oracledb ~]# swapon /home/swapswapon: /home/swap: insecure permissions 0644, 0600 suggested.# 写入fstab[root@oracledb ~]# vim /etc/fstab/home/swap swap swap defaults 0 0 安装oracle1234# 上传oracle安装包到/orcl/app/database[root@oracledb ~]# cd /orcl/app/# 解压安装包[root@oracledb app]# unzip linuxx64_12201_database.zip 安装1234567# 界面登录，切换到oracle用户,进入/orcl/app/database,运行runInstaller[root@oracledb ~]# init 5# 切换到oracle用户[root@oracledb ~]# su - oracle# 安装oracle[oracle@oracledb ~]$ cd /orcl/app/database./runInstaller 不接收oracle推送信息 只安装数据库管理软件，之后再建数据库 安装单实例还是数据库集群，选择单实例 选择企业版 软件存放目录，默认以安装包放置的路径开头 选择产品清单目录 配置安装组 检查安装的先决条件，如果有不通过的会显示，全部通过则确定安装即可 如果出现如图情况，先不要着急的点OK，需要用 root 用户执行如图提示的两条命令，执行完后再点OK 12345678910111213141516171819202122232425262728[root@oracledb ~]# cd /orcl/app/oraInventory[root@oracledb oraInventory]# ./orainstRoot.sh [root@oracledb ~]# cd /orcl/app/oracle/product/12.2.0/[root@oracledb 12.2.0]# ./root.sh Performing root user operation.The following environment variables are set as: ORACLE_OWNER= oracle ORACLE_HOME= /orcl/app/oracle/product/12.2.0Enter the full pathname of the local bin directory: [/usr/local/bin]: Copying dbhome to /usr/local/bin ... Copying oraenv to /usr/local/bin ... Copying coraenv to /usr/local/bin ...Creating /etc/oratab file...Entries will be added to the /etc/oratab file as needed byDatabase Configuration Assistant when a database is createdFinished running generic part of root script.Now product-specific root actions will be performed.Do you want to setup Oracle Trace File Analyzer (TFA) now ? yes|[no] : yesInstalling Oracle Trace File Analyzer (TFA).Log File: /orcl/app/oracle/product/12.2.0/install/root_oracledb_2020-11-05_23-23-29-185770578.logFinished installing Oracle Trace File Analyzer (TFA) 软件安装成功 配置监听也可以在配置数据库时再一同配置 12# 图形化界面运行命令[oracle@oracledb ~]$ netca 选择配置监听 选择添加一个监听 监听名称，默认即可 监听所遵从的协议，默认即可 选择监听端口号 是否创建下一个监听，选择否 监听配置完成 创建数据库12# 图形化界面运行命令dbca[oracle@oracledb ~]$ dbca 创建数据库 默认方式还是高级模式，选择高级模式 数据库用途 配置CBD容器数据库 选择存储方式，文件存储还是流存储 快速恢复选项，默认即可 选择监听器 数据库安全配置 内存、块、连接数、字符集、连接模式、添加实例配置 连接数量配置 字符集配置 选择连接模式，直连还是共享连接池 是否创建简单实例 配置Oracle EM（企业管理） 口令配置，此处用的是统一口令 创建数据库配置 创建数据库 创建数据库模板（以后可以基于模板创建一模一样的数据库） 创建数据库脚本（以后可以基于脚本创建一模一样的数据库） 总结界面，确认配置 创建数据库完成 plsql安装和配置plsql下载地址：https://www.allroundautomations.com/registered-plsqldev/ Oracle Instant Client下载地址：https://www.oracle.com/database/technologies/instant-client/downloads.html 安装plsql 安装免费版本 完全安装 将oracle instant client解压 此处解压到到plsql安装目录，并在解压后的目录新建文件夹network，network下新建文件夹admin 下载oracle安装目录下的tnsnames.ora到admin文件夹下 tnsnames.ora路径如下 1234root@oracledb admin]# pwd/orcl/app/oracle/product/12.2.0/network/admin[root@oracledb admin]# lslistener.ora samples shrept.lst tnsnames.ora 配置plsql配置环境变量 启动plsql，先取消登录，进入主界面，点击配置选项卡的首选项（configure–&gt;preferences） 配置Oracle Home为oracle instant client目录（此处为） 配置OCI library为oracle instant client下oci.dll完整路径（此处为） 测试连接 关闭plsql，重新打开就会出现Database下拉列表以及Connect As下拉框，代表配置成功 输入用户名和密码（之前配置）即可连接oracle，左侧tables下可以检索到表数据 scott用户测试数据导入oracle 12c自带了scott的脚本，路径为$ORACLE_HOME/rdbms/admin/utlsampl.sql，我们需要做的就是要将该脚本导入 查看已有PDB（也可以新建）12345678910111213141516171819202122232425262728293031323334# sqlplus连接oracle[root@oracledb ~]# su - oracle[oracle@oracledb ~]$ sqlplus / as sysdba# 设置行宽、设置列宽;使得数据显示更直观点SQL&gt; set linesize 200;SQL&gt; col name format a20;# 查看当前容器SQL&gt; show con_name;CON_NAME------------------------------CDB$ROOT# 查看CDB容器中的PDB信息SQL&gt; select con_id,dbid,guid,name,open_mode from v$pdbs; CON_ID DBID GUID NAME OPEN_MODE---------- ---------- -------------------------------- -------------------- ---------- 2 4290827074 B372306B8D476B69E05302D00B6F0A31 PDB$SEED READ ONLY 3 999196482 B3724BF4FFA877CDE05302D00B6F4E6B ORCLPDB READ WRITE# 或者直接查看有哪些PDBSQL&gt; show pdbs; CON_ID CON_NAME OPEN MODE RESTRICTED---------- ------------------------------ ---------- ---------- 2 PDB$SEED READ ONLY NO 3 ORCLPDB READ WRITE NO 修改配置1234567891011121314151617181920212223242526272829303132# 另开一个会话，登录oracle用户# 为orclpdb添加tnsnames，plsql中的tnsnames.ora同样需要修改[oracle@oracledb ~]$ vim /orcl/app/oracle/product/12.2.0/network/admin/tnsnames.ora# tnsnames.ora Network Configuration File: /orcl/app/oracle/product/12.2.0/network/admin/tnsnames.ora# Generated by Oracle configuration tools.LISTENER_ORCL = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.1.174)(PORT = 1521))ORCL = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.1.174)(PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = orcl.192.168.1.174) ) )ORCLPDB = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.1.174)(PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = orclpdb.192.168.1.174) ) ) # 修改utlsampl.sql，使其直连到ORCLPDB进行操作[oracle@oracledb ~]$ vim /orcl/app/oracle/product/12.2.0/rdbms/admin/utlsampl.sql# 修改CONNECT SCOTT/tiger 为 CONNECT SCOTT/tiger@ORCLPDB 导入脚本1234# 返回sqlplus的会话# 执行脚本utlsampl.sql，导入测试用户scottSQL&gt; @$ORACLE_HOME/rdbms/admin/utlsampl.sql;# 执行完成后会退出连接 验证1234567891011121314151617181920# 以scott用户登录，查询数据SQL&gt; conn scott/tiger@orclpdb;Connected.SQL&gt; select table_name from user_tables;TABLE_NAME--------------------------------------------------------------------------------DEPTEMPBONUSSALGRADESQL&gt; select * from DEPT; DEPTNO DNAME LOC---------- -------------- ------------- 10 ACCOUNTING NEW YORK 20 RESEARCH DALLAS 30 SALES CHICAGO 40 OPERATIONS BOSTON plsql使用scott用户登录修改tnsnames.ora后，Database里会出现ORCLPDB选项 连接后查看Table，有测试的四个表 至此，oracle12c安装以及相关操作全部完成]]></content>
      <categories>
        <category>数据库基础</category>
      </categories>
      <tags>
        <tag>数据库基础</tag>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS ssh密钥认证(免密登录)]]></title>
    <url>%2F2020%2F10%2F13%2FLinux%E6%9C%8D%E5%8A%A1%2Fssh_with_key%2F</url>
    <content type="text"><![CDATA[简介SSH （Secure Shell ）是一个安全的远程登录工具，由 IETF 的网络小组（Network Working Group）所制定，是建立在应用层基础上的安全协议，常监听于TCP的22端口。SSH最初是UNIX系统上的一个程序，后来又迅速扩展到其他操作平台。SSH客户端适用于多种平台，几乎所有UNIX平台—包括HP-UX、Linux、AIX、Solaris、Digital UNIX、Irix，以及其他平台，都可运行SSH。 ssh服务有两种验证用户登录的方式，一种是基于密码口令的认证，一种是基于密钥的认证，本文主要是实现基于密钥的认证。 密钥认证原理： 准备 主机：IP 操作系统 角色 node1:192.168.1.171 CentOS Linux release 7.8.2003 (Core) Minimal Install 客户端 node2:192.168.1.172 CentOS Linux release 7.8.2003 (Core) Minimal Install 服务端 配置客户端生成密钥对1234567891011121314151617181920212223# 格式：ssh-keygen -t rsa [-P ''] [-f ~/.ssh/id_rsa]# [-P '']:指定私钥密码为空# [-f ~/.ssh/id_rsa]:指定密钥对保存路径[root@node1 ~]# ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsaGenerating public/private rsa key pair.Created directory '/root/.ssh'.Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:SHA256:MFEhbpes0PiW6AQpKardZakmzvfabNVOIdboi/WS7lQ root@node1The key's randomart image is:+---[RSA 2048]----+| o.o. || . . + + . ||+ o o * +o ||o. . = B+ o ||. o OoSoE. ||.. + = +.o ||. o = +.* || o o.oo.+ o || o..++oo. |+----[SHA256]-----+ 复制公钥到远程主机（服务端）将生成的公钥传给远程主机，并加入到文件~/.ssh/authorized_keys；只要写入文件即可，写入方式多种，也可以复制粘贴过去，推荐ssh-copy-id方式 12345678910111213141516# 格式：ssh-copy-id [-i indetify_file ] USER@REMOTE_HOST# [-i indetify_file ]:指定公钥[root@node1 ~]# ssh-copy-id -i .ssh/id_rsa.pub root@192.168.1.172/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: ".ssh/id_rsa.pub"The authenticity of host '192.168.1.172 (192.168.1.172)' can't be established.ECDSA key fingerprint is SHA256:rRRfvxHXkXXyc0qBcfpbt3mXlxAaWP551y07Ysoqn+U.ECDSA key fingerprint is MD5:fa:a8:e1:c8:35:da:b5:ff:ec:4f:d2:bf:55:da:ce:31.Are you sure you want to continue connecting (yes/no)? yes/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keysroot@192.168.1.172's password: Number of key(s) added: 1Now try logging into the machine, with: "ssh 'root@192.168.1.172'"and check to make sure that only the key(s) you wanted were added. 测试1234# 此时已经可以使用root免密登录到node2[root@node1 ~]# ssh root@192.168.1.172Last login: Sun Oct 4 11:17:05 2020 from 192.168.1.154[root@node2 ~]# 优化（以下为进阶内容）这里我们会发现，在复制公钥的时候，如果是首次登陆，需要进行指纹核对（fingerprint verification），并且需要手动输入密码，可以使用shell脚本编程中的expect语法，代替我们验证指纹以及输入登录密码 expect依赖于tcl，CentOS 7最小化安装默认不包含tcl以及expect，网络上的主机可以yum安装，局域网的下载rpm安装，以网络上主机为例 配置阿里云yum源（可选）123456# 备份原有的yum仓库[root@node1 ~]# mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup# 配置阿里云yum源[root@node1 ~]# curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo# 生成缓存[root@node1 ~]# yum makecache 安装expect123[root@node1 ~]# yum install -y expect[root@node1 ~]# expect -vexpect version 5.45 编写自动远程执行脚本第一版：免指纹核对以及输入密码脚本使用expect来代替我们验证指纹以及输入登录密码 12345678910#!/usr/bin/expectspawn ssh 192.168.1.172expect &#123; # 指纹核对回复yes "yes/no" &#123; send "yes\n";exp_continue &#125; # 输入密码 "password" &#123; send "YOUR_PASSWORD\n" &#125;&#125;interactexpect eof 第二版：配置多主机ssh免密登录脚本结合密钥对生成以及复制公钥到远程多个主机 1234567891011121314151617181920212223#!/bin/bash# 判断密钥对是否存在，若不存在则创建密钥[ ! -f /root/.ssh/id_rsa.pub ] &amp;&amp; ssh-keygen -t rsa -P '' -f /root/.ssh/id_rsa &amp;&gt;/dev/null# 读取存储ip的文件while read line;do # 提取文件中的ip remote_host=$( echo $line | cut -d' ' -f1 ) # 提取文件中的用户名 username=$( echo $line | cut -d' ' -f2 ) # 提取文件中的密码 password=$( echo $line | cut -d' ' -f3 )expect &gt;&gt; ./expect.log &lt;&lt; EOF spawn ssh-copy-id -i /root/.ssh/id_rsa.pub $username@$remote_host expect &#123; "yes/no" &#123; send "yes\n";exp_continue &#125; "password" &#123; send "$password\n" &#125; &#125; expect eofEOFdone &lt; ./host_ip.txt 其中./host_ip.txt为保存主机信息的文件，格式如下 123[root@node1 workspace]# cat ./host_ip.txt 192.168.1.172 root 520123192.168.1.173 root 520123 第三版：基于ssh多主机运行本地脚本的shell脚本结合远程运行本地脚本文件并将输出收集到日志 123456789101112131415161718192021222324252627282930313233343536#!/bin/bash#------------------------------------------## FileName: ssh_auto.sh# Revision: 1.1.0# Date: 2020-10-05 00:21:00# Author: nemo# Email: sky.nemo@outlook.com# Website: www.skynemo.cn# Description: This script can achieve ssh password-free login, # and can be deployed in batches, configuration # 判断密钥对是否存在，若不存在则创建密钥[ ! -f /root/.ssh/id_rsa.pub ] &amp;&amp; ssh-keygen -t rsa -P '' -f /root/.ssh/id_rsa &amp;&gt;/dev/null# 读取存储ip的文件while read line;do # 提取文件中的ip remote_host=$( echo $line | cut -d' ' -f1 ) # 提取文件中的用户名 username=$( echo $line | cut -d' ' -f2 ) # 提取文件中的密码 password=$( echo $line | cut -d' ' -f3 )expect &gt;&gt; ./expect.log &lt;&lt; EOF spawn ssh-copy-id -i /root/.ssh/id_rsa.pub $username@$remote_host expect &#123; "yes/no" &#123; send "yes\n";exp_continue &#125; "password" &#123; send "$password\n" &#125; &#125; expect eofEOF date=$( ssh -T $username@$remote_host &lt; ./date.sh) echo $remote_host date : $date &gt;&gt; ./date.logdone &lt; ./host_ip.txt 其中其中./host_ip.txt为保存主机信息的文件，格式同上；./date.sh为远程执行的shell脚本，格式如下 123[root@node1 workspace]# cat ./date.sh #!/bin/bashdate 测试脚本 123456# 网络中没有192.168.1.173这台主机，所以提示连接失败[root@node1 workspace]# ./ssh_auto.sh ssh: connect to host 192.168.1.173 port 22: No route to host[root@node1 workspace]# cat date.log 192.168.1.172 date : Sun Oct 4 13:41:47 EDT 2020192.168.1.173 date : 第四版：解耦将脚本文件分成： 配置多主机免密登录脚本：./bin/ssh_auto.sh 在多主机运行本地脚本的调用脚本：./bin/remote_run_script.sh 待运行的本地脚本：./bin/uptime.sh（根据需求自定义，此处以获取uptime为例） 主机信息表：./conf/host.conf 入口脚本：./bin/main.sh 日志文件分为： 分发公钥expect日志：./log/expect.log 返回信息：./log/info.log 配置多主机免密登录脚本 1234567891011121314151617181920212223#!/bin/bash# 判断密钥对是否存在，若不存在则创建密钥[ ! -f /root/.ssh/id_rsa.pub ] &amp;&amp; ssh-keygen -t rsa -f /root/.ssh/id_rsa -P '' &amp;&gt;/dev/null# 读取存储ip的文件while read line;do # 提取文件中的ip remote_host=$( echo $line | cut -d' ' -f1 ) # 提取文件中的用户名 username=$( echo $line | cut -d' ' -f2 ) # 提取文件中的密码 password=$( echo $line | cut -d' ' -f3 )expect &gt;&gt; ../log/expect.log &lt;&lt; EOF spawn ssh-copy-id -i /root/.ssh/id_rsa.pub $username@$remote_host expect &#123; "yes/no" &#123; send "yes\n";exp_continue &#125; "password" &#123; send "$password\n" &#125; &#125; expect eof EOFdone &lt; ../conf/host.conf 在多主机运行本地脚本的调用脚本 123456789101112131415161718192021222324252627282930313233343536373839404142#!/bin/bashdatetime=$( date -d today +"%Y-%m-%d %H:%M:%S" )read -e -p "please input the script path : " -t 30 script# 判断待运行脚本是否存在if [[ ! -f $script ]];then echo "ERROR $script is not a file, check please!" exit 10fi# 判断主机信息配置文件是否存在if [[ ! -f ../conf/host.conf ]];then echo "ERROR ../conf/host.conf is no exits, check please!" exit 10fiwhile read linedo &#123; # 提取文件中的ip remote_host=$( echo $line | cut -d' ' -f1 ) # 提取文件中的用户名 username=$( echo $line | cut -d' ' -f2 ) return_info=$( ssh -T $username@$remote_host &lt; $script 2&gt;/dev/null ) return_code=$? #退出状态码不为0，说明ssh连接没有成功 if [[ ! $return_code -eq 0 ]];then &#123; echo "$remote_host connect fail, please check the host infomation or MaxStartups" exit 10 &#125; fi echo "$remote_host is running script..." echo -e "$datetime at remote host $remote_host run $script \n $return_info" &gt;&gt; ../log/info.log&#125; &amp;done &lt; ../conf/host.confwait 待运行的本地脚本 12345# 根据实际需要编写脚本，此处只为测试，所以写个获取uptime的简单脚本#!/bin/bashuptime=$( uptime | awk '&#123; print $3 &#125;')echo $uptime 主机信息表 1234567# 此处有一些重复的行，在入口脚本时进行删除[root@node1 conf]# cat host.conf192.168.1.173 root 520123192.168.1.172 root 520123192.168.1.173 root 520123192.168.1.172 root 520123192.168.1.172 root 520123 入口脚本 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#!/bin/bashconf=../conf/host.confdatetime=$( date -d today +"%Y-%m-%d %H:%M:%S" )# 清洗函数：删除host.conf重复行,生成MD5文件host_config_cleaning()&#123;# 清除host.conf的重复行sort -n $conf | uniq &gt; ../conf/host.conf.tmprm -rf $confmv ../conf/host.conf.tmp $conf# 重新生成md5文件host_md5=$( md5sum -b $conf | awk '&#123;print $1&#125;'| sed 's/ //g' )echo $host_md5 &gt; ../conf/host.conf.md5&#125;# 检查主机信息host.conf是否存在if [[ ! -f $conf ]];then &#123; echo "./conf/host.conf does no exist, check please !" exit 10&#125;fi# 检查免密登录脚本是否存在if [[ ! -f ./ssh_auto.sh ]];then &#123; echo "./bin/ssh_auto.sh does no exist, check please !" exit 10&#125;fi# 检查调用脚本是否存在if [[ ! -f ./run_auto.sh ]];then &#123; echo "./bin/run_auto.sh does no exist, check please !" exit 10&#125;fi# 检查host.conf是否有变化，通过MD5# 检查./conf/host.conf.md5文件是否存在，若不存在删除host.conf重复行,生成MD5文件if [[ ! -f ../conf/host.conf.md5 ]];then &#123; # 调用清洗函数 host_config_cleaning # 调用免密登录脚本，发放公钥 ./ssh_auto.sh &#125; else &#123; host_md5_old=$( cat ../conf/host.conf.md5 | sed 's/ //g') host_md5_new=$( md5sum -b $conf | awk '&#123;print $1&#125;'|sed 's/ //g' ) # 若当前MD5与原有的不同，说明主机配置文件(./conf/host.conf)发生改变 # 删除host.conf重复行,生成MD5文件 if [[ "$host_md5_old" == "$host_md5_new" ]];then &#123; echo "$datetime : host.conf is no change !" &gt; ../log/info.log &#125; else &#123; # 调用清洗函数 host_config_cleaning # 调用免密登录脚本，发放公钥 ./ssh_auto.sh &#125; fi &#125;fi# 调用多主机运行本地脚本的调用脚本./remote__run_script.sh 最终脚本打包链接（包含expect和tcl的rpm包，适用于centos7） https://skynemo-1258540788.cos.ap-chengdu.myqcloud.com/SkyNemo-Blog/linux/service/remote_service/0_ssh/ssh_auto.tar.gz]]></content>
      <categories>
        <category>Linux服务</category>
      </categories>
      <tags>
        <tag>Linux服务</tag>
        <tag>远程服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 安装Nginx]]></title>
    <url>%2F2020%2F09%2F12%2FLinux%E6%9C%8D%E5%8A%A1%2Fnginx_install_commend%2F</url>
    <content type="text"><![CDATA[简介&amp;准备简介nginx（读音：engine x）是可以作为HTTP和反向代理服务器、邮件代理服务器和通用TCP/UDP代理服务器，通常用于高负载的场景下，因为它的稳定性、丰富的模块库、灵活的配置和低系统资源的消耗而闻名 nginx的版本mainline version：主线版本，版本号通常是奇数，目前最新但是还未经过大量测试的版本 stable version：最新稳定版本，版本号通常为偶数，经过大量测试，企业中经常使用该版本 lagacy version：历史稳定版本，往期的稳定版本 nginx安装方式 yum安装部署 源码安装部署 准备主机CentOS Linux release 7.8.2003 (Core) Minimal Install 1台 关闭防火墙和selinux123456789# 关闭防火墙firewall并设置开机不启动[root@node1 ~]# systemctl stop firewalld[root@node1 ~]# systemctl disable firewalldRemoved symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.# 关闭selinux并设置开机不启动[root@node1 ~]# setenforce 0[root@node1 ~]# sed -i 's/=enforcing/=disabled/g' /etc/sysconfig/selinux 配置aliyun的yum仓库(可选)1234567# 参考：https://developer.aliyun.com/mirror/centos?spm=a2c6h.13651102.0.0.3e221b119TjB18# 备份[root@node1 ~]# mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup# 下载新的 CentOS-Base.repo 到 /etc/yum.repos.d/[root@node1 ~]# curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo#运行 yum makecache 生成缓存[root@node1 ~]# yum makecache 安装vim、yum-utils、wget（可选）1[root@node1 ~]# yum install vim yum-utils wget -y yum安装参考官网：http://nginx.org/en/linux_packages.html#RHEL-CentOS 配置yum仓库1234567891011121314151617# 此处的配置默认使用stable版本，根据需要将enbaled置为0或1[root@node1 ~]# vim /etc/yum.repos.d/nginx.repo[nginx-stable]name=nginx stable repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=1enabled=1gpgkey=https://nginx.org/keys/nginx_signing.keymodule_hotfixes=true[nginx-mainline]name=nginx mainline repobaseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/gpgcheck=1enabled=0gpgkey=https://nginx.org/keys/nginx_signing.keymodule_hotfixes=true 安装稳定版本12345# 由于默认配置即为稳定版本，所以直接安装即可[root@node1 ~]# yum install nginx -y# 查看版本信息[root@node1 ~]# nginx -vnginx version: nginx/1.18.0 安装主线版本12345678910# 卸载刚才安装的稳定版本[root@node1 ~]# yum remove nginx -y# 配置mainline版本为enabled，也可以vim配置文件修改[root@node1 ~]# yum-config-manager --enable nginx-mainline# 安装[root@node1 ~]# yum install nginx -y# 查看版本信息[root@node1 ~]# nginx -vnginx version: nginx/1.19.2 源码安装安装依赖1[root@node1 ~]# yum install gcc gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel -y 下载解压源码包1234567# 官网下载页面（http://nginx.org/en/download.html）复制下载链接，wget下载到/usr/local/src# 下载[root@node1 ~]# wget -P /usr/local/src http://nginx.org/download/nginx-1.18.0.tar.gz[root@node1 ~]# cd /usr/local/src# 解压[root@node1 src]# tar -zxvf nginx-1.18.0.tar.gz [root@node1 src]# cd nginx-1.18.0 预编译12345678910格式：./configure [options]预编译主要是用来检查系统环境是否满足安装软件包的条件，并生成Makefile文件，该文件为编译、安装、升级nginx指明了相应参数。./configure --help可以查看预编译参数以及详细解释，常用参数如下：--prefix 指定nginx编译安装的目录；--user=*** 指定nginx的属主--group=*** 指定nginx的属主与属组--with-*** 指定编译某模块--without-** 指定不编译某模块--add-module 编译第三方模块 1234567891011# 查看目录[root@node1 nginx-1.18.0]# lsauto CHANGES CHANGES.ru conf configure contrib html LICENSE man README src# 预编译[root@node1 nginx-1.18.0]# ./configure --prefix=/usr/local/nginx# 再次查看目录，可以发现多了Makefile文件以及objs目录[root@node1 nginx-1.18.0]# lsauto CHANGES.ru configure html Makefile objs srcCHANGES conf contrib LICENSE man README 编译并安装1234567891011121314151617181920212223242526格式：make [options]# 查看Makefile文件，可以看到编译命令make的常用参数以及作用[root@node1 nginx-1.18.0]# cat Makefile default: buildclean: rm -rf Makefile objsbuild: $(MAKE) -f objs/Makefileinstall: $(MAKE) -f objs/Makefile installmodules: $(MAKE) -f objs/Makefile modulesupgrade: /usr/local/nginx/sbin/nginx -t kill -USR2 `cat /usr/local/nginx/logs/nginx.pid` sleep 1 test -f /usr/local/nginx/logs/nginx.pid.oldbin kill -QUIT `cat /usr/local/nginx/logs/nginx.pid.oldbin` 格式:make [options]make clean : 重新预编译时，通常执行这条命令删除上次的编译文件make build : 编译，默认参数，可省略build参数make install : 安装make modules : 编译模块make upgrade : 在线升级 12345# 编译并安装[root@node1 nginx-1.18.0]# make &amp;&amp; make install# 查看版本[root@node1 ~]# /usr/local/nginx/sbin/nginx -vnginx version: nginx/1.18.0 启动nginx123456[root@node1 ~]# /usr/local/nginx/sbin/nginx# 检查进程和端口[root@node1 ~]# ps -ef | grep nginxroot 17249 1 0 23:48 ? 00:00:00 nginx: master process /usr/local/nginx/sbin/nginxnobody 17250 17249 0 23:48 ? 00:00:00 nginx: worker processroot 17252 12403 0 23:48 pts/0 00:00:00 grep --color=auto nginx 简便操作简化路径12345678910111213# 如果觉得每次都需要输入绝对路径执行命令麻烦，可以通过以下3种方法（选一执行即可）实现直接使用nginx命令1、建立软连接（推荐）[root@node1 ~]# ln -s /usr/local/nginx/sbin/* /usr/local/sbin2、配置环境变量[root@node1 ~]# echo "export PATH=/usr/local/nginx/sbin:$PATH" &gt; /etc/profile.d/nginx.sh# 重新读取profile[root@node1 ~]# source /etc/profile3、设置别名alias nginx='/usr/local/nginx/sbin/nginx'# 注：which会优先找别名 加入systemd管理123456789101112131415161718192021222324# 源码安装需要手动添加至systemd管理[root@node1 conf]# vim /usr/lib/systemd/system/nginx.service [Unit]Description=nginx - high performance web serverDocumentation=http://nginx.org/en/docs/After=network-online.target remote-fs.target nss-lookup.targetWants=network-online.target[Service]Type=forking# 若要指定pidfile，则nginx.conf中应该配置同一个pidfile，否则会导致systemctl start nginx卡住PIDFile=/var/run/nginx.pidExecStart=/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.confExecReload=/bin/sh -c "/bin/kill -s HUP $(/bin/cat /var/run/nginx.pid)"ExecStop=/bin/sh -c "/bin/kill -s TERM $(/bin/cat /var/run/nginx.pid)"[Install]WantedBy=multi-user.target# 重新加载[root@node1 conf]# systemctl daemon-reload# 可用systemctl运行[root@node1 conf]# systemctl start nginx 卸载yum方式安装的卸载 1[root@node1 system]# yum remove nginx -y 源码安装方式的卸载 1234567891011# 查看nginx是否启动[root@node1 ~]# ps -ef | grep nginxroot 17249 1 0 03:11 ? 00:00:00 nginx: master process /usr/local/nginx/sbin/nginxnobody 17250 17249 0 03:11 ? 00:00:00 nginx: worker processroot 20447 20222 0 09:38 pts/1 00:00:00 grep --color=auto nginx# 停止nginx服务[root@node1 ~]# nginx -s quit[root@node1 ~]# ps -ef | grep nginx root 20534 20222 0 09:39 pts/1 00:00:00 grep --color=auto nginx# find查找路径后卸载[root@node1 ~]# find / -name nginx* | grep /usr | xargs -i rm -rf &#123;&#125; nginx常用命令12345678910111213141516# 查看帮助[root@node1 ~]# nginx -hnginx version: nginx/1.18.0Usage: nginx [-?hvVtTq] [-s signal] [-c filename] [-p prefix] [-g directives]Options: -?,-h : this help -v : show version and exit -V : show version and configure options then exit -t : test configuration and exit -T : test configuration, dump it and exit -q : suppress non-error messages during configuration testing -s signal : send signal to a master process: stop, quit, reopen, reload -p prefix : set prefix path (default: /usr/local/nginx/) -c filename : set configuration file (default: conf/nginx.conf) -g directives : set global directives out of configuration file 启动nginx 1nginx 立即停止nginx 1nginx -s stop 优雅停止nginx 1nginx -s quit 重新打开日志文件 1nginx -s reopen 重新加载配置文件 1nginx -s reload 启动并指定配置文件 1nginx -c [conf file] 设置全局变量 1234# 通过设置全局变量，让nginx在前端运行nginx -g "daemon off;"# 此时ctrl +c，则nginx就退出了。可以使用ctrl +z放置后台运行。]]></content>
      <categories>
        <category>Linux服务</category>
      </categories>
      <tags>
        <tag>Linux服务</tag>
        <tag>web服务</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 文件共享FTP部署配置]]></title>
    <url>%2F2020%2F09%2F09%2FLinux%E6%9C%8D%E5%8A%A1%2Fftp_install_config%2F</url>
    <content type="text"><![CDATA[简介&amp;准备vsftpd 是“very secure FTP daemon”的缩写，是一个完全免费的、开放源代码的ftp服务器软件。特点是：非常高的安全性需求、带宽限制、良好的可伸缩性等 主机信息CentOS Linux release 7.8.2003 (Core) 最小安装两台主机 主机角色 主机：IP 角色 安装服务 node1:192.168.1.201 ftp服务端 vsftp node1:192.168.1.202 ftp客户端 ftp或lftp 关闭防火墙和selinux12345678910# 两个节点都操作# 关闭selinuxsetenforce 0# 设置selinux开机不自启sed -i 's/=enforcing/=disabled/g' /etc/sysconfig/selinux# 关闭firewallsystemctl stop firewalld# 设置firewall开机不启动systemctl disable firewalld 安装服务端安装 1[root@node1 ~]# yum install -y vsftpd 客户端安装 12# ftp与lftp选一即可，基础用法相似，高级用法查看man ftp和man lftp[root@node2 ~]# yum -y install ftp lftp 启动服务 12[root@node1 ~]# systemctl start vsftpd [root@node1 ~]# systemctl enable vsftpd 常用操作为测试客户端常用命令，在服务端创建一些文件 1234# 默认的共享目录是 /var/ftp，在/var/ftp/pub下创建一些文件[root@node1 pub]# for i in $(seq 1 10); do echo $i &gt; file$i ; done[root@node1 pub]# lsfile1 file10 file2 file3 file4 file5 file6 file7 file8 file9 ftp客户端常用命令连接123456789101112131415# 使用ftp连接，需要手动输入匿名用户ftp，默认密码为空[root@node2 ~]# ftp 192.168.1.201Connected to 192.168.1.201 (192.168.1.201).220 (vsFTPd 3.0.2)Name (192.168.1.201:root): ftp331 Please specify the password.Password:230 Login successful.Remote system type is UNIX.Using binary mode to transfer files.ftp&gt; # 使用lftp连接，默认使用匿名用户ftp[root@node2 ~]# lftp 192.168.1.201lftp 192.168.1.201:~&gt; help查看帮助1234567891011121314151617181920212223242526272829303132# 连接上服务器后，可以使用help获取帮助，以ftp为例，lftp类似ftp&gt; helpCommands may be abbreviated. Commands are:! debug mdir sendport site$ dir mget put sizeaccount disconnect mkdir pwd statusappend exit mls quit structascii form mode quote systembell get modtime recv suniquebinary glob mput reget tenexbye hash newer rstatus tickcase help nmap rhelp tracecd idle nlist rename typecdup image ntrans reset userchmod lcd open restart umaskclose ls prompt rmdir verbosecr macdef passive runique ?delete mdelete proxy send# 常用命令如下：# ascii：设置以ascii码方式传输数据，一般用于传输文本文件ftp&gt; ascii200 Switching to ASCII mode.# binary：设置以二进制方式传输数据，一般用于传输压缩包、库文件、二进制等除文本以外的文件ftp&gt; binary200 Switching to Binary mode.# passive：用于开启和关闭ftp的主被动模式ftp&gt; passivePassive mode off.ftp&gt; passivePassive mode on.# ls、pwd同linux；文件操作命令下面详解 get下载单个文件12345678910111213141516171819202122232425ftp&gt; ls227 Entering Passive Mode (192,168,1,201,28,47).150 Here comes the directory listing.drwxr-xr-x 2 0 0 137 Sep 07 14:41 pub226 Directory send OK.# 切换到pub目录ftp&gt; cd pub250 Directory successfully changed.ftp&gt; ls227 Entering Passive Mode (192,168,1,201,60,75).150 Here comes the directory listing.-rw-r--r-- 1 0 0 2 Sep 07 14:41 file1-rw-r--r-- 1 0 0 3 Sep 07 14:41 file10-rw-r--r-- 1 0 0 2 Sep 07 14:41 file2-rw-r--r-- 1 0 0 2 Sep 07 14:41 file3-rw-r--r-- 1 0 0 2 Sep 07 14:41 file4-rw-r--r-- 1 0 0 2 Sep 07 14:41 file5-rw-r--r-- 1 0 0 2 Sep 07 14:41 file6-rw-r--r-- 1 0 0 2 Sep 07 14:41 file7-rw-r--r-- 1 0 0 2 Sep 07 14:41 file8-rw-r--r-- 1 0 0 2 Sep 07 14:41 file9226 Directory send OK.# get下载单个文件，默认会下载到你客户端使用ftp命令的当前目录下# cd用于切换服务端目录，lcd切换本地目录ftp&gt; get file1 mget批量下载12345# ftp客户端批量下载时需关闭交互，否则每个文件都会讯问；lftp不需要ftp&gt; prompt offInteractive mode off.# 下载所有file开头的文件ftp&gt; mget file* put上传单个文件默认配置只能进行文件的读取和下载，不能上传，先配置开启匿名用户创建文件、重命名、删除、上传权限 12345678910# node1(服务端)配置匿名用户权限[root@node1 ~]# vim /etc/vsftpd/vsftpd.conf#开启匿名用户上传权限anon_upload_enable=YES#开启匿名用户创建文件权限anon_mkdir_write_enable=YES#开启匿名用户重命名，删除权限anon_other_write_enable=YES# ftp用户属于other；所以给other组用户添加写权限[root@node1 ~]# chmod o+w /var/ftp/pub 12345# 创建目录ftp&gt; mkdir testDir257 "/pub/testDir" created# 上传文件ftp&gt; put anaconda-ks.cfg mput批量上传1ftp&gt; mput file_* miror下载目录123# ftp不提供下载目录，lftp可以用miror下载目录lftp 192.168.1.201:/pub&gt; mirror testDirTotal: 1 directory, 0 files, 0 symlinks rmdir删除目录123456# ftp均使用rmdir删除目录ftp&gt; rmdir testDir250 Remove directory operation successful.lftp 192.168.1.201:/pub&gt; rmdir testDir2rmdir ok, `testDir2' removed 删除文件1234567# ftp使用delete删除文件ftp&gt; delete file6250 Delete operation successful.# lftp使用rm删除文件lftp 192.168.1.201:/pub&gt; rm file7 rm ok, `file7' removed bye断开连接123456# 断开连接# ftp与lftp一样，bye和quit均可以 [root@node2 ~]# lftp 192.168.1.201lftp 192.168.1.201:~&gt; quit[root@node2 ~]# lftp 192.168.1.201lftp 192.168.1.201:~&gt; bye ftp的主被动模式注：当vsftpd配置为主动模式时，客户端需要同步开启主动模式，否则无法正常操作；被动模式同理 主动模式主动模式，也称为active模式、port模式；连接过程如下： 客户端从一个任意的非特权端口N（N&gt;1024）向服务器的FTP端口（默认是21）发送连接请求，服务器接受连接，建立一条命令链路。 客户端开始监听端口N+1 下载数据时，客户端发送FTP命令port N+1到FTP服务器，告诉服务器：“我打开了N+1端口，你过来连接我”。接着服务器会从它自己的数据端口（20）连接到客户端指定的数据端口（N+1）。建立一条数据链路来传送数据 下图为连接过程简要描述： 主动模式配置服务端配置 1234[root@node1 ~]# vim /etc/vsftpd/vsftpd.conf pasv_enable=NOport_enable=YES[root@node1 ~]# systemctl restart vsftpd 客户端配置 12345# ftpftp&gt; passive off# lftplftp 192.168.1.201:/&gt; set ftp:passive-mode 0 被动模式注：常用于客户端在局域网，与服务端中间有防火墙或NAT映射的情形下 被动模式，也称为passive模式、pasv模式；被动方式FTP中，命令连接和数据连接都由客户端发起，这样就可以解决从服务器到客户端的数据端口的入方向连接被防火墙过滤掉的问题，vsftpd默认就是使用被动模式；连接过程如下： 客户端打开两个任意的非特权本地端口（N&gt;1024和N+1）。第一个端口连接服务器的21端口 下载数据时，与主动模式不同，客户端不会提交PORT信令并允许服务器来回连它的数据端口，而是提交PASV信令，告诉服务端连接模式是被动模式。 服务端接收待PASV信令后，会开启一个任意的非特权端口（P&gt;1024），并发送port P命令给客户端。然后客户端发起从本地端口N+1到服务器的端口P的连接用来传送数据。 下图为连接过程简要描述： 被动模式配置服务端配置 1234[root@node1 ~]# vim /etc/vsftpd/vsftpd.conf pasv_enable=YESport_enable=NO[root@node1 ~]# systemctl restart vsftpd 客户端配置 12345# ftpftp&gt; passive on# lftplftp 192.168.1.201:/&gt; set ftp:passive-mode 1 ftp服务端常用配置举例例1-配置本地用户访问 12345678910111213# 服务端node1添加一个测试用户testUser[root@node1 ~]# useradd testUser[root@node1 ~]# echo "123456" | passwd --stdin testUser# 修改配置文件，设置本地用户可以登录[root@node1 ~]# vim /etc/vsftpd/vsftpd.conf local_enable=YES# 重启生效[root@node1 ~]# systemctl restart vsftpd# 客户端node2测试登录[root@node2 test]# lftp testUser@192.168.1.201Password: lftp testUser@192.168.1.201:~&gt; 例2-配置不让匿名用户登录 12345678910# 修改配置文件，设置不让匿名用户登录[root@node1 ~]# vim /etc/vsftpd/vsftpd.conf anonymous_enable=NO# 重启生效[root@node1 ~]# systemctl restart vsftpd# 客户端node2测试登录，已经无法正常操作[root@node2 test]# lftp 192.168.1.201lftp 192.168.1.201:~&gt; ls`ls' at 0 [Sending commands...] 例3-配置全部用户都不能切换家目录 1234567891011# 安装vsftpd后不做配置的话，系统用户是可以向上切换到其他目录的（默认用户不行）# 修改配置文件，设置限制系统用户在其主目录[root@node1 ~]# vim /etc/vsftpd/vsftpd.conf chroot_local_user=YESchroot_list_enable=NOallow_writeable_chroot=YES# chroot_local_user： 是否将所有用户限制在主目录,YES为启用，NO禁用.(该项默认值是NO)# chroot_list_enable： 是否启动限制用户（特例）的名单 YES为启用，NO禁用(包括注释掉也为禁用)# allow_writeable_chroot:如果用户被限定在了其主目录下，则该用户的主目录不能再具有写权限了,如果检查发现还有写权限，就会报错误;allow_writeable_chroot=YES允许该用户的主目录具有写权限 故障解决12345678910111213# 如果重启或者登陆服务器时，报错如下：[root@node1 ~]# systemctl restart vsftpdJob for vsftpd.service failed because the control process exited with errorcode. See "systemctl status vsftpd.service" and "journalctl -xe" for details.[root@node1 ~]# journalctl -xe-- Unit vsftpd.service has begun starting up.8月 08 02:59:14 localhost.localdomain vsftpd[12751]: 500 OOPS: bad bool value inconfig file for: anonymous_en8月 08 02:59:14 localhost.localdomain systemd[1]: vsftpd.service: controlprocess exited, code=exited status=2# 这种问题一般就是空格导致的，是每一行配置后面都不能有空格，也不能跟注释。 通常而言，vsftp服务器放置于内部局域网使用，前面还有防火墙，一般来说很安全了，不过vsftpd还有更安全的配置方式，就是虚拟用户。 虚拟用户较为复杂，打算在另一篇文章介绍 附录vsftpd.conf常用配置1234567891011121314151617181920212223242526272829303132333435listen=&lt;YES/NO&gt; :设置为YES时vsftpd以独立运行方式启动，设置为NO时以xinetd方式启动（xinetd是管理守护进程的，将服务集中管理，可以减少大量服务的资源消耗）listen_port=&lt;port&gt; :设置控制连接的监听端口号，默认为21listen_address=&lt;ip address&gt; :将在绑定到指定IP地址运行，适合多网卡connect_from_port_20=&lt;YES/NO&gt; :若为YES，则强迫FTP－DATA的数据传送使用port 20，默认YESpasv_enable=&lt;YES/NO&gt; :是否使用被动模式的数据连接，如果客户机在防火墙后，请开启为YESpasv_min_port=&lt;n&gt;pasv_max_port=&lt;m&gt; :设置被动模式后的数据连接端口范围在n和m之间,建议为50000－60000端口message_file=&lt;filename&gt; :设置使用者进入某个目录时显示的文件内容，默认为 .messagedirmessage_enable=&lt;YES/NO&gt; :设置使用者进入某个目录时是否显示由message_file指定的文件内容ftpd_banner=&lt;message&gt; :设置用户连接服务器后的显示信息，就是欢迎信息banner_file=&lt;filename&gt; :设置用户连接服务器后的显示信息存放在指定的filename文件中connect_timeout=&lt;n&gt; :如果客户机连接服务器超过N秒，则强制断线，默认60accept_timeout=&lt;n&gt; :当使用者以被动模式进行数据传输时，服务器发出passive port指令等待客户机超过N秒，则强制断线，默认60accept_connection_timeout=&lt;n&gt; :设置空闲的数据连接在N秒后中断，默认120data_connection_timeout=&lt;n&gt; : 设置空闲的用户会话在N秒后中断，默认300max_clients=&lt;n&gt; : 在独立启动时限制服务器的连接数，0表示无限制max_per_ip=&lt;n&gt; :在独立启动时限制客户机每IP的连接数，0表示无限制（不知道是否跟多线程下载有没干系）local_enable=&lt;YES/NO&gt; :设置是否支持本地用户帐号访问guest_enable=&lt;YES/NO&gt; :设置是否支持虚拟用户帐号访问write_enable=&lt;YES/NO&gt; :是否开放本地用户的写权限local_umask=&lt;nnn&gt; :设置本地用户上传的文件的生成掩码，默认为077local_max_rate&lt;n&gt; :设置本地用户最大的传输速率，单位为bytes/sec，值为0表示不限制local_root=&lt;file&gt; :设置本地用户登陆后的目录，默认为本地用户的主目录chroot_local_user=&lt;YES/NO&gt; :是否将所有用户限制在主目录,YES为启用，NO禁用.(该项默认值是NO)chroot_list_enable=&lt;YES/NO&gt; :是否启动限制用户（特例）的名单 YES为启用，NO禁用(包括注释掉也为禁用)chroot_list_file=&lt;filename&gt; :当chroot_list_enable=YES时，只有filename文件指定的用户为例外用户anonymous_enable=&lt;YES/NO&gt; :设置是否支持匿名用户访问anon_max_rate=&lt;n&gt; :设置匿名用户的最大传输速率，单位为B/s，值为0表示不限制anon_world_readable_only=&lt;YES/NO&gt; 是否开放匿名用户的浏览权限anon_upload_enable=&lt;YES/NO&gt; 设置是否允许匿名用户上传anon_mkdir_write_enable=&lt;YES/NO&gt; :设置是否允许匿名用户创建目录anon_other_write_enable=&lt;YES/NO&gt; :设置是否允许匿名用户其他的写权限（注意，这个在安全上比较重要，一般不建议开，不过关闭会不支持续传）anon_umask=&lt;nnn&gt; :设置匿名用户上传的文件的生成掩码，默认为077]]></content>
      <categories>
        <category>Linux服务</category>
      </categories>
      <tags>
        <tag>Linux服务</tag>
        <tag>文件共享服务</tag>
        <tag>ftp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 文件共享NFS以及autofs部署配置]]></title>
    <url>%2F2020%2F09%2F05%2FLinux%E6%9C%8D%E5%8A%A1%2Fnfs-autofs_install_config%2F</url>
    <content type="text"><![CDATA[简介NFSNFS，即Network File System，网络文件系统。网络文件系统是FreeBSD支持的文件系统中的一种。他最大的特点就是可以通过网络，让不同的机器，不同的系统实现文件共享。NFS客户端可以将NFS服务器共享的目录挂载在本地的文件系统中，访问目录就如同访问自 己本地目录一样 AutoFSAutofs与Mount/Umount的不同之处在于，它是一种看守程序。如果它检测到用户正试图访问一个尚未挂接的文件系统，它就会自动检测该文件系统，如果存在，那么Autofs会自动将其挂接。另一方面，如果它检测到某个已挂接的文件系统在一段时间内没有被使用，那么Autofs会自动将其卸载。因此一旦运行了Autofs后，用户就不再需要手动完成文件系统的挂接和卸载。 准备操作系统CentOS Linux release 7.8.2003 (Core) 最小安装-两台 主机角色 主机：IP 角色 安装服务 node1：192.168.1.201 NFS服务端，NTP服务端（可选） nfs-utils，ntp（可选） node2：192.168.1.202 NFS客户端，NTP客户端（可选） nfs-utils，autofs，ntp（可选） 关闭防火墙12345678910# 两个节点都操作# 关闭selinuxsetenforce 0# 设置selinux开机不自启sed -i 's/=enforcing/=disabled/g' /etc/sysconfig/selinux# 关闭firewallsystemctl stop firewalld# 设置firewall开机不启动systemctl disable firewalld 修改hostname（可选）123# 两个节点分别操作# 根据规划名称修改主机名,以node1为例hostnamectl set-hostname node1 配置阿里yum源（可选，网速好的可以不配置）1234567# 两个节点都操作# 备份原yum源mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup# 下载新的 CentOS-Base.repo 到 /etc/yum.repos.d/curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo# 运行 yum makecache 生成缓存yum makecache 安装vim（可选）12# 两个节点都操作yum install vim -y 配置时间同步（ntp|可选）12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 也可以用chrony时间同步，本质一样# 两个节点都操作# 关闭chrony并设置开机不自启systemctl stop chronydsystemctl disable chronyd# 安装ntpyum install ntp -y# 设置时区为上海timedatectl set-timezone Asia/Shanghai# 设置允许使用ntptimedatectl set-ntp yes# 配置ntp服务端，node1操作# 注释原有的互联网server[root@node1 ~]# sed -i '/^server/ s/^\(.*\)$/# \1/g' /etc/ntp.conf# 添加配置以自身为时间同步源[root@node1 ~]# sed -i '/^# Please / a\server 127.127.1.0 iburst' /etc/ntp.conf# 添加配置时间服务器层级为10，可配置0~16，0为顶级[root@node1 ~]# sed -i '/^server 127/ a\fudge 127.127.1.0 startum 10' /etc/ntp.conf# 注释默认的不允许查询修改[root@node1 ~]# sed -i '/^restrict default/ s/^\(.*\)$/# \1/g' /etc/ntp.conf# 添加配置可访问的客户端网段[root@node1 ~]# sed -i '/^# Hosts/ a\restrict 192.168.1.0 mask 255.255.255.0 nomodify' /etc/ntp.conf# 配置ntp客户端，node2操作# 注释原有的互联网serversed -i '/^server/ s/^\(.*\)$/# \1/g' /etc/ntp.conf# 添加配置以node1为时间同步源sed -i '/^# Please / a\server 192.168.1.201 iburst' /etc/ntp.conf# 两个节点操作# 重启ntp服务systemctl restart ntpd# 设置开机自启systemctl enable ntpd# node2查看同步状态是否正常[root@node2 ~]# ntpstatsynchronised to NTP server (192.168.1.201) at stratum 7 time correct to within 1387 ms polling server every 64 s[root@node2 ~]# ntpq -p remote refid st t when poll reach delay offset jitter==============================================================================*192.168.1.201 LOCAL(0) 6 u 37 64 1 0.407 -0.014 0.051 NFS安装部署安装12# 两个节点都操作yum -y install nfs-utils 配置服务端123456789101112131415# node1操作# 创建要分享的目录，data为分享目录，share为client操作的目录mkdir -p /data/share# 为share目录other组添加权限，后面会说明原因chmod o+w -R /data/share# 编辑/etc/export文件，格式如下:# [共享目录] [客户端IP(参数)] [客户端IP(参数)][root@node1 ~]# vim /etc/exports/data 192.168.1.0/24(ro) 192.168.1.202(rw)# 可以使用完整的IP或者是网络号# 重启服务，nfs依赖于rpcbind，先重启rpcbind[root@node1 ~]# systemctl restart rpcbind[root@node1 ~]# systemctl restart nfs# 导出nfs维护表，重新共享目录[root@node1 ~]# exportfs -r 配置客户端123456789101112131415161718192021222324252627# node2操作# 发现可用的共享文件[root@node2 ~]# showmount -e 192.168.1.201Export list for 192.168.1.201:/data 192.168.1.0/24# 创建目录，用于挂载[root@node2 ~]# mkdir -p /mnt/nfs# 挂载，二选一执行，推荐软挂载## 硬挂载mount -t nfs 192.168.1.201:/data /mnt/nfs[root@node2 ~]# mount -t nfs 192.168.1.201:/data /mnt/nfs[root@node2 ~]# df -hFilesystem Size Used Avail Use% Mounted on......192.168.1.201:/data 17G 1.5G 16G 9% /mnt/nfs## 软挂载[root@node2 ~]# mount -t nfs -o soft,timeo=1 192.168.1.201:/data /mnt/nfs[root@node2 ~]# df -hFilesystem Size Used Avail Use% Mounted on......192.168.1.201:/data 17G 1.5G 16G 9% /mnt/nfs# 参数说明# soft: 软挂载，遇到报错会终止挂载，并返回信息；默认是硬挂载，一直尝试挂载# timeo: 超时时间，配合软挂载使用 使用以及客户端权限问题12345678910111213141516171819202122232425262728293031323334353637# node2操作# 进入共享的目录[root@node2 ~]# cd /mnt/nfs/[root@node2 nfs]# touch a.txttouch: cannot touch ‘a.txt’: Permission denied# 此时会发现无法没有权限创建文件(可读不可写)# 查看nfs权限，nfs对root用户应该是可写的，问题出在什么地方呢？[root@node2 nfs]# ll /mnt/total 0drwxr-xr-x. 3 root root 32 Sep 4 23:48 nfs# 进入share，可以创建文件(可写)[root@node2 ~]# cd /mnt/nfs/share/[root@node2 share]# touch a.txt# share目录权限不同之处在于other组用户是可写的[root@node2 share]# ll /mnt/nfs/total 0drwxr-xrwx. 2 root root 19 Sep 4 23:59 share# 查看客户端创建的文件，属主是nfsnobody[root@node2 share]# lltotal 0-rw-r--r--. 1 nfsnobody nfsnobody 0 Sep 4 23:59 a.txt# node1操作# 查看详细配置[root@node1 ~]# exportfs -v/data 192.168.1.202(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,root_squash,no_all_squash)......# 可以看到rw和root_squash参数# rw:客户端具有可写权限，默认应该是可写的啊，是什么问题呢？# root_squash:如果客户端用root身份访问，则被压缩成nfsnobody,权限也将受到限制。nfsnobody是属于other组用户。所以，在other有可写权限的share目录中可写，在nfs中不可写# 所以，当客户端有权限问题时# 1、查看服务端配置是否可写，权限是否被压缩# 2、可以通过配置不压缩权限（不推荐），或者新建一个other组可写权限的目录share规避# 3、服务端配置root_squash压缩root时，客户端可以新建非root用户规避，但同样，该用户需要有目录相应权限 解读服务端配置文件-exports12345# node1操作# 查看服务端配置，系统默认会给我们加上很多配置[root@node1 ~]# exportfs -v/data 192.168.1.202(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,root_squash,no_all_squash)/data 192.168.1.0/24(sync,wdelay,hide,no_subtree_check,sec=sys,ro,secure,root_squash,no_all_squash) 参数 说明 ro 该共享目录的权限是只读（read-only） rw 该共享目录的权限是可读写（read-write） hide 隐藏文件系统 noaccess 阻止访问这个目录及其子目录 wdelay 为合并多次更新而延迟写入磁盘 no_wdelay 尽可能快地把数据写入磁盘 sync 将数据同步写入内存缓冲区与磁盘中（同步模式） async 将数据线暂存在内存缓冲区中，而非直接写入磁盘（非同步模式） subtree_check 验证每个被请求的文件都在导出的目录树中 no_subtree_check 只验证涉及被导出的文件系统的文件请求 all_squash 将所有本地和远程账户映射到匿名用户 root_squash 将根用户及所属组都映射为匿名用户或用户组（nfsnobody） no_root_squash 将远程根用户当成本地根用户，不建议使用 all_squash 不管访问者是什么身份，包括root，全部压缩至匿名用户 no_all_squash 保留访问用户的身份uid以及gid,一般只能查看，不能修改，权限问题，但是可以强制保存 anonuid 为匿名用户账户指定组ID anongid 为匿名用户账户指定用户ID 卸载时报错处理123456789[root@node2 ~]# umount /mnt/nfs[root@node2 ~]# umount.nfs4: /mnt/jfedu: device is busy# 强行解除挂载[root@node2 ~]# umount -l /mnt/nfs # 或者使用# 将会显示使用这个模块的pid[root@node2 ~]# fuser -m /mnt/nfs # 直接kill那个pid[root@node2 ~]# fuser -mk /mnt/nfs autofs安装部署autofs服务程序与mount命令不同之处在于它是一种守护进程，只有检测到用户试图访问一个尚未挂载 的文件系统时才自动的检测并挂载该文件系统。 autofs非常方便，主要有两点： 设置不需要在开机就挂载的目录，当用的时候才实现自动挂载。 用户不使用自动挂载的目录一段的时间，会自动卸载（默认时间为5分钟）,可以在autofs.conf修改配置 安装12# node2操作[root@node2 ~]# yum install autofs -y autofs配置12345678910111213141516171819202122232425262728293031323334# node2操作# autofs配置主要由/etc/auto.master及其关联的文件(通常为*.misc)两部分构成# 先配置/etc/auto.master# 注释原有的配置映射，新增自己的配置[root@node2 ~]# vim /etc/auto.master# /misc /etc/auto.misc/mnt/nfs /etc/nfs.misc# /mnt/nfs定义了mount的挂载点，是总的访问目录(客户端的目录)# 而/etc/nfs.misc是对总访问目录的描述，定义了mount的动作，用于子目录的编辑、用户权限分离；/etc/nfs.misc本身不存在，可以自己创建# 创建/etc/nfs.misc[root@node2 ~]# vim /etc/nfs.miscshare -fstype=nfs,rw,sync 192.168.1.201:/data# data是nfs服务器共享的目录# -fstype可以配置绝大部分mount -o的所有配置选项# 如果nfs服务端exportfs，设置的权限为ro，那么即使此处写rw，也是不可写的# 如果nfs服务端exportfs，设置的权限为rw，那么可以在此处设置rw或者ro# 重启autofs[root@node2 ~]# systemctl restart autofs# 查看目录，是空的[root@node2 ~]# ll /mnt/nfstotal 0# 访问目录即可以自动挂载[root@node2 ~]# cd /mnt/nfs/share[root@node2 share]# df -hFilesystem Size Used Avail Use% Mounted on......192.168.1.201:/data 17G 1.5G 16G 9% /mnt/nfs/share#查看挂载的参数，可以根据需要在/etc/nfs.misc设置[root@node2 share]# mount......192.168.1.201:/data on /mnt/nfs/share type nfs4 (rw,relatime,sync,vers=4.1,rsize=131072,wsize=131072,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=192.168.1.202,local_lock=none,addr=192.168.1.201) NFS常用命令1234567891011121314151617181920212223# 格式：nfsstat [参数]# 参数如下：## -m, --mounts 显示已经挂载的nfs文件系统的详细参数## -c, --client 显示NFS客户端的统计信息## -s, --server 显示NFS服务器端的统计信息## -2 显示nfsv2的统计信息## -3 显示nfsv3的统计信息## -4 显示nfsv4的统计信息## nfsstat -o [facility] 显示指定类型的统计信息## facility如下：#### nfs NFS协议信息#### rpc 一般RPC信息#### net 网络统计信息#### all 显示以上所有信息# 格式：rpcinfo [参数]-p 显示注册的端口-m 显示 rpcbind 操作的统计信息表-s 显示所有已注册的 RPC 程序的简明列表-T 显示有关使用特定传输或协议的服务的信息-t 探测使用 TCP 的 RPC 程序-u 探测使用 UDP 的 RPC 程序 NFS简单原理NFS服务由五个守护进程（daemon）负责： rpc.nfsd，它做了大部分的工作； rpc.lockd以及rpc.statd，处理文件锁定； rpc.mountd，它处理初始装载请求， 以及rpc.rquotad，它处理导出卷上的用户文件配额。 每个daemon都需要占用一些端口，但有些daemon是可选的，也许用户根本不会启用它们。所以，NFS并没有给每个NFS daemon保留固定端口。然而，客户端需要知道服务端的这些端口，所以就有了rpcbind进程（之前为rpc.portmap，原理功能一样），用于端口的分配 在系统启动时，给需要启用的NFS daemon分配端口，然后把这些端口号告诉rpcbind。rpcbind的端口号是固定的111。当客户端需要连接NFS的某个daemon时，就先咨询rpcbind，获得该NFS daemon对应的端口号，然后再发送NFS请求。如下图所示 基本流程如下： 首先服务器端启动rpcbind，并开启111端口 服务器端启动NFS服务，并向rpcbind注册端口信息 客户端启动rpcbind，向服务端的rpcbind服务请求服务端的NFS服务端口 服务端的rpcbind服务反馈NFS服务端口信息给客户端。 客户端通过获取的NFS服务端口来建立和服务端的NFS连接并进行数据的传输 注： 1、在启动NFS SERVER之前，首先要启动rpcbind服务（即portmap服务），否则NFS SERVER就无法向RPC服务区注册 2、如果RPC服务重新启动，原来已经注册好的NFS端口数据就会全部丢失。因此此时RPC服务管理的NFS程序也要重新启动以重新向RPC注册 3、一般修改NFS配置文档后，不需要重启NFS的，systemctl reload nfs或exportfs –rv即可使修改的/etc/exports生效 NFS常用优化参数主要优化mount -o 的相关参数（同autofs的-fstype参数） 123456789101112async：异步同步，数据不会立刻同步至磁盘，此参数会提高I/O性能，但会降低数据安全（除非对性能要求很高，对数据可靠性不要求的场合。一般生产环境，不推荐使用）。noatime：取消更新文件系统上的inode访问时间,提升I/O性能，优化I/O目的，推荐使用。nodiratime：取消更新文件系统上的directory inode访问时间，高并发环境，推荐显式应用该选项，提高系统性能noexec：挂载的这个文件系统，要不要执行程序（安全选项）。nosuid：挂载的这个文件系统上面，可不可以设置UID（安全选项）。rsize/wsize：读取（rsize）/写入（wsize）的区块大小（block size），这个设置值可以影响客户端与服务端传输数据的缓冲存储量。一般来说，如果在局域网内，并且客户端与服务端都具有足够内存，这个值可以设置大一点，比如说32768（bytes）,提升缓冲区块将可提升NFS文件系统的传输能力 附录ntp配置文件ntp服务端 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# For more information about this file, see the man pages# ntp.conf(5), ntp_acc(5), ntp_auth(5), ntp_clock(5), ntp_misc(5), ntp_mon(5).driftfile /var/lib/ntp/drift# Permit time synchronization with our time source, but do not# permit the source to query or modify the service on this system.# restrict default nomodify notrap nopeer noquery# Permit all access over the loopback interface. This could# be tightened as well, but to do so would effect some of# the administrative functions.restrict 127.0.0.1 restrict ::1# Hosts on local network are less restricted.restrict 192.168.1.0 mask 255.255.255.0 nomodify#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap# Use public servers from the pool.ntp.org project.# Please consider joining the pool (http://www.pool.ntp.org/join.html).server 127.127.1.0 iburstfudge 127.127.1.0 startum 10# server 0.centos.pool.ntp.org iburst# server 1.centos.pool.ntp.org iburst# server 2.centos.pool.ntp.org iburst# server 3.centos.pool.ntp.org iburst#broadcast 192.168.1.255 autokey # broadcast server#broadcastclient # broadcast client#broadcast 224.0.1.1 autokey # multicast server#multicastclient 224.0.1.1 # multicast client#manycastserver 239.255.254.254 # manycast server#manycastclient 239.255.254.254 autokey # manycast client# Enable public key cryptography.#cryptoincludefile /etc/ntp/crypto/pw# Key file containing the keys and key identifiers used when operating# with symmetric key cryptography. keys /etc/ntp/keys# Specify the key identifiers which are trusted.#trustedkey 4 8 42# Specify the key identifier to use with the ntpdc utility.#requestkey 8# Specify the key identifier to use with the ntpq utility.#controlkey 8# Enable writing of statistics records.#statistics clockstats cryptostats loopstats peerstats# Disable the monitoring facility to prevent amplification attacks using ntpdc# monlist command when default restrict does not include the noquery flag. See# CVE-2013-5211 for more details.# Note: Monitoring will not be disabled with the limited restriction flag.disable monitor ntp客户端 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# For more information about this file, see the man pages# ntp.conf(5), ntp_acc(5), ntp_auth(5), ntp_clock(5), ntp_misc(5), ntp_mon(5).driftfile /var/lib/ntp/drift# Permit time synchronization with our time source, but do not# permit the source to query or modify the service on this system.restrict default nomodify notrap nopeer noquery# Permit all access over the loopback interface. This could# be tightened as well, but to do so would effect some of# the administrative functions.restrict 127.0.0.1 restrict ::1# Hosts on local network are less restricted.#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap# Use public servers from the pool.ntp.org project.# Please consider joining the pool (http://www.pool.ntp.org/join.html).server 192.168.1.201 iburst# server 0.centos.pool.ntp.org iburst# server 1.centos.pool.ntp.org iburst# server 2.centos.pool.ntp.org iburst# server 3.centos.pool.ntp.org iburst#broadcast 192.168.1.255 autokey # broadcast server#broadcastclient # broadcast client#broadcast 224.0.1.1 autokey # multicast server#multicastclient 224.0.1.1 # multicast client#manycastserver 239.255.254.254 # manycast server#manycastclient 239.255.254.254 autokey # manycast client# Enable public key cryptography.#cryptoincludefile /etc/ntp/crypto/pw# Key file containing the keys and key identifiers used when operating# with symmetric key cryptography. keys /etc/ntp/keys# Specify the key identifiers which are trusted.#trustedkey 4 8 42# Specify the key identifier to use with the ntpdc utility.#requestkey 8# Specify the key identifier to use with the ntpq utility.#controlkey 8# Enable writing of statistics records.#statistics clockstats cryptostats loopstats peerstats# Disable the monitoring facility to prevent amplification attacks using ntpdc# monlist command when default restrict does not include the noquery flag. See# CVE-2013-5211 for more details.# Note: Monitoring will not be disabled with the limited restriction flag.disable monitor]]></content>
      <categories>
        <category>Linux服务</category>
      </categories>
      <tags>
        <tag>Linux服务</tag>
        <tag>文件共享服务</tag>
        <tag>nfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ceph-deploy安装ceph集群-nautilus版]]></title>
    <url>%2F2020%2F08%2F29%2FLinux%E6%9C%8D%E5%8A%A1%2Fceph_nautilus_install%2F</url>
    <content type="text"><![CDATA[ceph-deploy安装ceph集群准备主机设置 节点 系统 IP地址 安装软件 时间同步 ceph-admin CentOS 7 x64 2003 192.168.1.150192.168.2.150 ceph-deploy server ceph-node1 CentOS 7 x64 2003 192.168.1.151192.168.2.151 mon / osd client ceph-node2 CentOS 7 x64 2003 192.168.1.152192.168.2.152 osd client ceph-node3 CentOS 7 x64 2003 192.168.1.153192.168.2.153 osd client ceph-client CentOS 7 x64 2003 192.168.1.154192.168.2.154 client 准备工作0、配置aliyun的基础yum源（自认网速好的可以不设置） 1234567891011# 所有节点操作# 备份原有的配置文件mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup# 下载aliyun的CentOS 7的yum配置文件curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo# 或 (注：最小安装没有wget)wget -O /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo# 生成缓存yum makecache 1、安装vim（可选） 12# 所有节点操作yum install -y vim 2、修改hostname为节点名并相互解析 123456789101112# 所有节点操作# 根据预定的名称修改，以ceph-admin为例hostnamectl set-hostname ceph-admin# 配置hosts相互解析cat&gt;&gt;/etc/hosts&lt;&lt;EOF192.168.2.150 ceph-admin192.168.2.151 ceph-node1192.168.2.152 ceph-node2192.168.2.153 ceph-node3192.168.2.154 ceph-clientEOF 3、关闭防火墙以及selinux 12345678# 所有节点操作# 关闭防火墙并设置开启不启动systemctl stop firewalldsystemctl disable firewalld# 关闭selinux并设置开启不启动setenforce 0sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux 4、配置chrony时间同步 123456789101112131415161718192021222324252627# 所有节点设置时区timedatectl set-timezone Asia/Shanghai# ceph-admin节点操作,配置成chrony server# 注释原有的时间同步server[root@ceph-admin ~]# sed -i '/^server/ s/^\(.*\)$/# \1/g' /etc/chrony.conf# 新增以自己为server[root@ceph-admin ~]# sed -i '/^# Please / a\server 127.127.0.1 iburst' /etc/chrony.conf# 配置允许访问的client网段[root@ceph-admin ~]# sed -i '/#allow / a\allow 192.168.2.0/24' /etc/chrony.conf# 设置即使不同步其他时钟源，该server依然可以作为时钟源[root@ceph-admin ~]# sed -i '/^#local / s/^#\(.*\)$/\1/g' /etc/chrony.conf# 其他节点操作,配置成chrony client# 注释原有的时间同步serversed -i '/^server/ s/^\(.*\)$/# \1/g' /etc/chrony.conf# 新增以ceph-admin为serversed -i '/^# Please / a\server 192.168.2.150 iburst' /etc/chrony.conf# 所有节点重启chrony，使其生效systemctl restart chronyd# 检查时间同步是否正常，client端出现*号表示时间同步正常[root@ceph-node1 ~]# chronyc sources210 Number of sources = 1MS Name/IP address Stratum Poll Reach LastRx Last sample ===============================================================================^* 192.168.2.150 10 6 17 29 -3121ns[ -90us] +/- 100us 5、配epel源和ceph源 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# 所有节点操作,包括client# 配置aliyun的epel源# 备份(如有配置其他epel源)mv /etc/yum.repos.d/epel.repo /etc/yum.repos.d/epel.repo.backupmv /etc/yum.repos.d/epel-testing.repo /etc/yum.repos.d/epel-testing.repo.backup# 下载新repo 到/etc/yum.repos.d/curl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo# 或wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo# 配置aliyun的ceph源,一般只用[ceph-noarch]cat&gt;/etc/yum.repos.d/ceph.repo&lt;&lt;EOF[ceph-source]name=Ceph source packagesbaseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/SRPMS/enabled=1gpgcheck=0type=rpm-mdgpgkey=https://mirrors.aliyun.com/ceph/keys/release.ascpriority=1[ceph-aarch64]name=Ceph aarch64 packagesbaseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/aarch64/enabled=1gpgcheck=0type=rpm-mdgpgkey=https://mirrors.aliyun.com/ceph/keys/release.ascpriority=1[ceph-noarch]name=Ceph noarch packagesbaseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/noarch/enabled=1gpgcheck=0type=rpm-mdgpgkey=https://mirrors.aliyun.com/ceph/keys/release.ascpriority=1[ceph-x86_64]name=Ceph x86_64 packagesbaseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/x86_64/enabled=1gpgcheck=0type=rpm-mdgpgkey=https://mirrors.aliyun.com/ceph/keys/release.ascpriority=1EOF# 更新并查看配置的仓库yum updateyum repolist# 应出现epel和ceph仓库信息# 生成缓存yum makecache 6、设置ssh免密码登录 123456789# ceph-admin节点操作# 由于使用root用户安装，所以不创建新账号# 创建公钥，选项全部默认[root@ceph-admin ~]# ssh-keygen# 将公钥分发到各个node节点[root@ceph-admin ~]# ssh-copy-id -i /root/.ssh/id_rsa.pub ceph-node1[root@ceph-admin ~]# ssh-copy-id -i /root/.ssh/id_rsa.pub ceph-node2[root@ceph-admin ~]# ssh-copy-id -i /root/.ssh/id_rsa.pub ceph-node3[root@ceph-admin ~]# ssh-copy-id -i /root/.ssh/id_rsa.pub ceph-client 7、admin节点安装ceph-deploy 1234567891011[root@ceph-admin ~]# yum -y install ceph-deploy# 安装python的distrubute包，ceph-deploy运行需要该模块# python的distribute包网址https://pypi.org/project/distribute/，找到下载路径下载[root@ceph-admin ~]# yum install -y unzip# 下载解压，也可以用迅雷或其他工具下载后传上去，看自己网速[root@ceph-admin ~]# wget https://files.pythonhosted.org/packages/5f/ad/1fde06877a8d7d5c9b60eff7de2d452f639916ae1d48f0b8f97bf97e570a/distribute-0.7.3.zip[root@ceph-admin ~]# unzip distribute-0.7.3.zip [root@ceph-admin ~]# cd distribute-0.7.3# 安装distribute模块[root@ceph-admin distribute-0.7.3]# python setup.py install[root@ceph-admin distribute-0.7.3]# cd 部署集群创建集群1、admin节点创建集群 1234567# 因为部署会产生许多文件，所以创建一个文件[root@ceph-admin ~]# mkdir -p /root/my-cluster[root@ceph-admin ~]# cd ~/my-cluster# 创建一个集群,配置public-network用于对外服务，cluster-network用于集群内部同步，配置monitor节点为ceph-node1ceph-deploy new --public-network 192.168.1.0/24 --cluster-network 192.168.2.0/24 ceph-node1[root@ceph-admin my-cluster]# ceph-deploy new --public-network 192.168.1.0/24 --cluster-network 192.168.2.0/24 ceph-node1 2、node节点安装软件包 123# 3个node节点运行# 根据角色，node节点安装ceph软件包，此处全装yum install -y ceph ceph-mon ceph-mgr ceph-radosgw ceph-mds 3、admin节点初始化monitor 1234# admin节点运行，初始化monitor[root@ceph-admin my-cluster]# ceph-deploy mon create-initial# 将配置文件以管理员（admin）用推送到各个节点，注：此处的admin是代表管理员角色，与节点无关[root@ceph-admin my-cluster]# ceph-deploy admin ceph-node1 ceph-node2 ceph-node3 4、在monitor节点检查是否初始化完成 12345678910111213141516# node1节点（monitor节点）查看集群是否初始化成功，HEALTH_OK代表集群正常[root@ceph-node1 ~]# ceph -s cluster: id: 1f1dd9dd-355b-4224-a995-e2ea3da78a01 health: HEALTH_OK services: mon: 1 daemons, quorum ceph-node1 (age 5m) mgr: no daemons active osd: 0 osds: 0 up, 0 in data: pools: 0 pools, 0 pgs objects: 0 objects, 0 B usage: 0 B used, 0 B / 0 B avail pgs: 5、部署manager demon（mgr）用于监控 12345678910111213141516171819202122# admin节点运行# 部署mgr到node1节点[root@ceph-admin my-cluster]# ceph-deploy mgr create ceph-node1# node1节点运行，查看mgr是否添加到ceph集群# 此处的HEALTH_WARN代表还没添加OSD[root@ceph-node1 ~]# ceph -s cluster: id: 1f1dd9dd-355b-4224-a995-e2ea3da78a01 health: HEALTH_WARN OSD count 0 &lt; osd_pool_default_size 3 services: mon: 1 daemons, quorum ceph-node1 (age 13m) mgr: ceph-node1(active, since 2m) osd: 0 osds: 0 up, 0 in data: pools: 0 pools, 0 pgs objects: 0 objects, 0 B usage: 0 B used, 0 B / 0 B avail pgs: 6、添加OSD 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 每台主机上添加两块5G的硬盘# 如下/dev/sdb和/dev/sdc即为要添加为OSD的硬盘，无需格式化[root@ceph-node1 ~]# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 20G 0 disk ├─sda1 8:1 0 1G 0 part /boot└─sda2 8:2 0 19G 0 part ├─centos-root 253:0 0 17G 0 lvm / └─centos-swap 253:1 0 2G 0 lvm [SWAP]sdb 8:16 0 5G 0 disk sdc 8:32 0 5G 0 disk sr0 11:0 1 9.6G 0 rom # admin节点操作，生产中可以加上journal进行加速# 将三个节点的/dev/sdb加入OSD[root@ceph-admin my-cluster]# ceph-deploy osd create ceph-node1 --data /dev/sdb[root@ceph-admin my-cluster]# ceph-deploy osd create ceph-node2 --data /dev/sdb[root@ceph-admin my-cluster]# ceph-deploy osd create ceph-node2 --data /dev/sdb# 可以在monitor节点查看osd[root@ceph-node1 ~]# ceph osd treeID CLASS WEIGHT TYPE NAME STATUS REWEIGHT PRI-AFF -1 0.01469 root default -3 0.00490 host ceph-node1 0 hdd 0.00490 osd.0 up 1.00000 1.00000 -5 0.00490 host ceph-node2 1 hdd 0.00490 osd.1 up 1.00000 1.00000 -7 0.00490 host ceph-node3 2 hdd 0.00490 osd.2 up 1.00000 1.00000 # 至此，一个简易版的集群已经部署完毕，包含一个monitor、一个mgr、三个osd[root@ceph-node1 ~]# ceph -s cluster: id: 1f1dd9dd-355b-4224-a995-e2ea3da78a01 health: HEALTH_OK services: mon: 1 daemons, quorum ceph-node1 (age 39m) mgr: ceph-node1(active, since 39m) osd: 3 osds: 3 up (since 3m), 3 in (since 3m) data: pools: 0 pools, 0 pgs objects: 0 objects, 0 B usage: 3.0 GiB used, 12 GiB / 15 GiB avail pgs: 扩展集群扩展mon和mgr 123456789101112131415161718192021222324252627282930313233343536373839404142434445# mon是集群的核心，使用了paxos算法，所以一般会使用奇数个节点# admin节点操作，添加node2和node3为monitor[root@ceph-admin my-cluster]# ceph-deploy mon add ceph-node2 --address 192.168.2.152[root@ceph-admin my-cluster]# ceph-deploy mon add ceph-node3 --address 192.168.2.153# 查看仲裁状态[root@ceph-node1 ~]#ceph quorum_status --format json-pretty# 或查看mon状态[root@ceph-node1 ~]# ceph mon state3: 3 mons at &#123;ceph-node1=[v2:192.168.1.151:3300/0,v1:192.168.1.151:6789/0],ceph-node2=[v2:192.168.1.152:3300/0,v1:192.168.1.152:6789/0],ceph-node3=[v2:192.168.1.153:3300/0,v1:192.168.1.153:6789/0]&#125;, election epoch 14, leader 0 ceph-node1, quorum 0,1,2 ceph-node1,ceph-node2,ceph-node3# 查看mon详细状态[root@ceph-node1 ~]# ceph mon dump dumped monmap epoch 3epoch 3fsid 1f1dd9dd-355b-4224-a995-e2ea3da78a01last_changed 2020-08-25 12:37:16.468139created 2020-08-25 11:20:41.663956min_mon_release 14 (nautilus)0: [v2:192.168.1.151:3300/0,v1:192.168.1.151:6789/0] mon.ceph-node11: [v2:192.168.1.152:3300/0,v1:192.168.1.152:6789/0] mon.ceph-node22: [v2:192.168.1.153:3300/0,v1:192.168.1.153:6789/0] mon.ceph-node3# mgr默认是主备模式，同一时间只有一个是运行的# admin节点操作，扩容mgr[root@ceph-admin my-cluster]# ceph-deploy mgr create ceph-node2 ceph-node3# node1节点查看当前mgr[root@ceph-node1 ~]# ceph -s cluster: id: 1f1dd9dd-355b-4224-a995-e2ea3da78a01 health: HEALTH_OK services: mon: 3 daemons, quorum ceph-node1,ceph-node2,ceph-node3 (age 10m) mgr: ceph-node1(active, since 60m), standbys: ceph-node2, ceph-node3 osd: 3 osds: 3 up (since 24m), 3 in (since 24m) data: pools: 0 pools, 0 pgs objects: 0 objects, 0 B usage: 3.0 GiB used, 12 GiB / 15 GiB avail pgs: # 可以看到node1是主，运行状态，node2 node3是备用 # 至此，集群拥有三个monitor、三个mgr、三个OSD 使用ceph存储-rbd创建pool 123456789# monitor节点运行# 创建存储池，ceph-demo为pool name，默认三个副本[root@ceph-node1 ~]# ceph osd pool create ceph-demo 64 64pool 'ceph-demo' created# 查看所有pool[root@ceph-node1 ~]# ceph osd lspools1 ceph-demo#查看pool详细信息，pg数量，pgp数量，副本数，调度算法等；可以用set设置pool配置[root@ceph-node1 ~]# ceph osd pool get ceph-demo pg_num|pgp_num|size|crush_rule 客户端安装ceph 1234567[root@ceph-client ~]# yum -y install ceph ceph-radosgw# 查看是否安装成功[root@ceph-client ~]# ceph --versionceph version 14.2.11 (f7fdb2f52131f54b891a2ec99d8205561242cdaf) nautilus (stable)# admin节点赋于管理员权限给client[root@ceph-admin my-cluster]# ceph-deploy admin ceph-client RBD使用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475# client节点操作# 创建一个10G的rbd镜像，使用pool为ceph-demo，feature为layering# 关于feature，CentOS 7 2003内核为3.10.0-1127.el7.x86_64，只支持layering，需要其他feature请升级内核4.x以上[root@ceph-client ~]# rbd create -p ceph-demo --image rbd-demo.img --size 10G --image-feature layering# 或者[root@ceph-client ~]# rbd create ceph-demo/rbd-demo1.img --size 10G# 初始化rbd[root@ceph-client ~]# rbd pool init ceph-demo# 查看pool下的所有rbd[root@ceph-client ~]# rbd -p ceph-demo lsrbd-demo.imgrbd-demo1.img# 查看rbd详细信息[root@ceph-client ~]# rbd info ceph-demo/rbd-demo.imgrbd image 'rbd-demo.img': size 10 GiB in 2560 objects order 22 (4 MiB objects) snapshot_count: 0 id: 38346e95f989 block_name_prefix: rbd_data.38346e95f989 format: 2 features: layering op_features: flags: create_timestamp: Tue Aug 25 23:45:29 2020 access_timestamp: Tue Aug 25 23:45:29 2020 modify_timestamp: Tue Aug 25 23:45:29 2020# 删除rbd镜像[root@ceph-client ~]# rbd rm -p ceph-demo --image rbd-demo1.imgRemoving image: 100% complete...done.# 映射[root@ceph-client ~]# rbd map ceph-demo/rbd-demo.img/dev/rbd0# 查看rbd信息[root@ceph-client ~]# rbd device listid pool namespace image snap device 0 ceph-demo rbd-demo.img - /dev/rbd0 # 可以看到多出了一个裸设备/dev/rdb0[root@ceph-client ~]# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 20G 0 disk ├─sda1 8:1 0 1G 0 part /boot└─sda2 8:2 0 19G 0 part ├─centos-root 253:0 0 17G 0 lvm / └─centos-swap 253:1 0 2G 0 lvm [SWAP]sr0 11:0 1 1024M 0 rom rbd0 252:0 0 10G 0 disk # 格式化设备，挂载使用[root@ceph-client ~]# mkfs.ext4 /dev/rbd0# 挂载[root@ceph-client ~]# mkdir /mnt/rbd-demo[root@ceph-client ~]# mount /dev/rbd0 /mnt/rbd-demo[root@ceph-client ~]# df -hTFilesystem Type Size Used Avail Use% Mounted ondevtmpfs devtmpfs 475M 0 475M 0% /devtmpfs tmpfs 487M 0 487M 0% /dev/shmtmpfs tmpfs 487M 7.7M 479M 2% /runtmpfs tmpfs 487M 0 487M 0% /sys/fs/cgroup/dev/mapper/centos-root xfs 17G 2.0G 16G 12% //dev/sda1 xfs 1014M 168M 847M 17% /boottmpfs tmpfs 98M 0 98M 0% /run/user/0/dev/rbd0 ext4 9.8G 37M 9.2G 1% /mnt/rbd-demo# 至此，rbd挂载完成，可以正常使用 扩容rbd 12345678910111213141516171819202122# 扩容rbd[root@ceph-client ~]# rbd resize ceph-demo/rbd-demo.img --size 10GResizing image: 100% complete...done.#刷新文件系统[root@ceph-client ~]# resize2fs /dev/rbd0resize2fs 1.42.9 (28-Dec-2013)Filesystem at /dev/rbd0 is mounted on /mnt/rbd-demo; on-line resizing requiredold_desc_blocks = 1, new_desc_blocks = 2The filesystem on /dev/rbd0 is now 2621440 blocks long.# 查看是否扩容成功[root@ceph-client ~]# df -hFilesystem Size Used Avail Use% Mounted ondevtmpfs 475M 0 475M 0% /devtmpfs 487M 0 487M 0% /dev/shmtmpfs 487M 7.7M 479M 2% /runtmpfs 487M 0 487M 0% /sys/fs/cgroup/dev/mapper/centos-root 17G 2.0G 16G 12% //dev/sda1 1014M 168M 847M 17% /boot/dev/rbd0 9.8G 23M 9.3G 1% /mnt/rbd-demotmpfs 98M 0 98M 0% /run/user/0]]></content>
      <categories>
        <category>Linux服务</category>
      </categories>
      <tags>
        <tag>Linux服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables原理简介]]></title>
    <url>%2F2020%2F06%2F09%2FLinux%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2Fiptables_theory%2F</url>
    <content type="text"><![CDATA[iptables和netfilteriptables其实不是真正的防火墙，我们可以把它理解成一个客户端代理，用户通过 iptables这个代理，将用户的安全设定执行到对应的安全框架”中，这个”安全框架”才是真正的防火墙，这个框架的名字叫 netfilter。netfilter才是防火墙真正的安全框架（ framework）， netfilter位于内核空间。iptables其实是个命令行工具，位于用户空间，我们用这个工具操作真正的框架 表、链和规则iptables结构iptables -&gt; 表 -&gt; 链 -&gt; 规则（ iptables -&gt; tables -&gt; chains -&gt; rules）. 简单地讲，表由链组成，而链又由规则组成。我们通过设置规则来完成过滤、重定向、修改数据包等功能 iptables的内建链和内建表链（chain）什么是链呢？当数据包从网络上来到主机，需要经过一些关卡，经过这些关卡的时候，则必须符合通过的条件，而且，关卡会根据检验条件来放行、拒绝或者丢弃数据等等；这里的关卡就是链，而条件就是规则；iptables默认有5个内建链，如下图所示： 每个内建链的功能如下： INPUT链 – 处理来自外部的数据 OUTPUT链 – 处理向外发送的数据 FORWARD链– 将数据转发到本机的其他网卡设备上 PREROUTING链 – 处理刚到达本机并在路由转发前的数据包。它可以转换数据包中的目标IP地址（destination ip address），通常用于DNAT(destination NAT) POSTROUTING链 – 处理即将离开本机的数据包。它可以转换数据包中的源IP地址（source ip address），通常用于SNAT（source NAT） 处理不同方向的数据，由不同内建链负责，系统内建链与数据流向可以由下图描述 根据上图，我们能够得知报文的流向 到本机某进程的报文： PREROUTING --&gt; INPUT 由本机转发的报文： PREROUTING --&gt; FORWARD --&gt; POSTROUTING 由本机的某进程发出报文： OUTPUT --&gt; POSTROUTING 表（table）我们对每个链上都放置了一串规则，但是有些规则负责的功能有些很相似，这个时候，我们把具有相同功能的规则的集合叫做表，所以说，不同功能的规则，我们可以放置在不同的表中进行管理，而 iptables已经为我们定义了4种表，每种表对应了不同的功能 filter表：负责过滤数据包，有以下三种内建链： INPUT OUTPUT FORWARD nat表：负责网络地址转换功能；有以下三种内建链： PREROUTING POSTROUTING OUTPUT INPUT链（CentOS6中不存在，CentOS7新增加） mangle表：拆解报文，做出修改，并重新封装数据包；能改变TCP头中的QoS位；有以下5个内建链： PREROUTING OUTPUT FORWARD INPUT POSTROUTING raw表：用于处理异常， 在整个防火墙体系优先级最高，如果启动用raw表，数据将会跳过conntrack（关闭nat表上启用的连接追踪机制；），有以下2个内建链： PREROUTING OUTPUT 加上表的描述，数据包经过防火墙的流程可以总结为下图： 优先级次序优先次序关系到规则对数据包的匹配 表间优先顺序raw -–&gt; mangle –-&gt; nat -–&gt; filter 链间优先顺序入站数据：PREROUTING、INPUT出站数据：OUTPUT、POSTROUTING转发数据：PREROUTING、FORWARD、POSTROUTING 链内规则匹配顺序自上向下按顺序依次进行检查，找到相匹配的规则即停止，若在该链内找不到的相匹配的规则，则按该链的默认策略处理（未修改的情况下，默认策略为允许ACCEPT） iptables的规则牢记以下三点式理解iptables规则的关键： Rules包括一个条件和一个目标(target) 如果满足条件，就执行目标(target)中的规则或者特定值。 如果不满足条件，就判断下一条Rules 目标值（Target Values） 下面是你可以在target里指定的特殊值： ACCEPT：允许数据包通过 DROP：直接丢弃数据包，不给任何回应信息，这时候客户端会感觉自己的请求泥牛入海了，过了超时时间才会有反应 REJECT：拒绝数据包通过，必要时会给数据发送端响应信息，客户端刚请求就会收到拒绝的信息 SNAT：源地址转换，解决内网用户用同一个公网地址上网的问题 MASQUERADE：是SNAT的种特殊形式，适用于动态的、临时会变的IP上 DNAT：目标地址转换 REDIRECT：在本机做端口映射 LOG：在文件中记录日志信息，然后将数据包传递给下一条规则，也就是说除了记录以外不对数据包做任何其他操作，仍然让下一条规则去匹配 举例1iptables -t filter -I INPUT -p tcp --dport 12345 -j REJECT 该命令表示在filter表的INPUT链上添加一条REJECT规则，由以上可知，INPUT链在数据流入的方向上，将tcp连接且目标端口为12345的数据包拒绝掉，即以tcp访问本机12345的数据都会被拒绝，达到防火墙的目的 本文为原理简介，关于更多iptables的操作将有另一篇文章说明]]></content>
      <categories>
        <category>Linux系统管理</category>
      </categories>
      <tags>
        <tag>Linux系统管理</tag>
        <tag>Linux防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 安装Redis 6.x以及持久化方式介绍]]></title>
    <url>%2F2020%2F06%2F08%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%2Fcentos7_redis6_install%2F</url>
    <content type="text"><![CDATA[环境CentOS Linux release 7.10 2009 Minimal Install redis-stable（redis-6.0.9） 12345678# 创建软件目录[root@oliva ~]# mkdir -p /redis/app# 创建日志目录[root@oliva ~]# mkdir -p /redis/log/# 创建数据目录[root@oliva ~]# mkdir -p /redis/data/6379# 创建配置目录[root@oliva ~]# mkdir -p /redis/conf 准备关闭防火墙1234567# 关闭firewalld并设置开启不启动[root@oliva ~]# systemctl stop firewalld &amp;&amp; systemctl disable firewalld# 关闭selinux[root@oliva ~]# setenforce 0# 设置selinux开机不启动[root@oliva ~]# sed -i 's/=enforcing/=disabled/g' /etc/sysconfig/selinux 配置阿里云yum源12345678# 备份[root@oliva ~]# mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup# 下载新的CentOS-Base.repo 到 /etc/yum.repos.d/[root@oliva ~]# curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo# 生成缓存[root@oliva ~]# yum makecache 安装123456789101112131415161718192021222324252627282930313233343536373839404142[root@oliva ~]# yum -y install wget gcc[root@oliva ~]# yum -y install tcl# 获取安装包，解压[root@oliva ~]# wget http://download.redis.io/releases/redis-stable.tar.gz[root@oliva ~]# tar -zxvf redis-stable.tar.gz # 内存管理器jemalloc安装，方式选择一种操作即可# 安装jemalloc方式一[root@oliva ~]# yum -y install bzip2[root@oliva ~]# wget https://github.com/jemalloc/jemalloc/releases/download/5.2.1/jemalloc-5.2.1.tar.bz2# 解压[root@oliva ~]# bzip2 -d jemalloc-5.2.1.tar.bz2 [root@oliva ~]# tar -xvf jemalloc-5.2.1.tar# 编译安装[root@oliva jemalloc-5.2.1]# cd jemalloc-5.2.1[root@oliva jemalloc-5.2.1]# ./configure --prefix=/usr/local/jemalloc[root@oliva jemalloc-5.2.1]# make &amp;&amp; make install[root@oliva jemalloc-5.2.1]# cd ../# 安装jemalloc方式二# 安装epel源[root@oliva ~]# yum -y install epel-release[root@oliva ~]# yum clean all &amp;&amp; yum makecache[root@oliva ~]# yum -y install jemalloc# 由于redis编译时对gcc版本有要求，所以此处需要临时升级gcc,退出shell或重启失效[root@oliva ~]# yum -y install centos-release-scl[root@oliva ~]# yum -y install devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-binutils[root@oliva ~]# scl enable devtoolset-9 bash[root@oliva ~]# cd redis-stable# 方式一安装jemalloc时，需要手动指定内存管理器MALLOC为jemalloc 或者直接修改src/Makefile# ① ：手动指定[root@oliva redis-stable]# make MALLOC=/usr/local/jemalloc/lib/[root@oliva redis-stable]# make install PREFIX=/redis/app# ② ：直接修改Makefile[root@oliva redis-stable]# vi src/MakefilePREFIX?=/redis/appMALLOC=/usr/local/jemalloc/lib/[root@oliva redis-stable]# make &amp;&amp; make install 配置管理配置后台启动123456789101112131415161718192021222324# 基本配置[root@oliva redis-stable]# cp ./redis.conf /redis/conf/redis_6379.conf[root@oliva redis-stable]# vi /redis/conf/redis_6379.conf# 监听地址，默认是监听本地环回地址；设置为0.0.0.0，表示监听所有ip地址bind 192.168.1.171 127.0.0.1# 配置后台启动daemonize yes# 配置日志文件路径logfile "/redis/log/redis_6379.log"# 配置数据库文件路径dir /redis/data/6379# 开启aof持久化appendonly yes# 启动redis[root@oliva ~]# /redis/app/bin/redis-server /redis/conf/redis_6379.conf 6557:C 09 Jun 2020 07:16:44.327 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo6557:C 09 Jun 2020 07:16:44.327 # Redis version=6.0.4, bits=64, commit=00000000, modified=0, pid=6557, just started6557:C 09 Jun 2020 07:16:44.327 # Configuration loaded# 检查redis-server是否启动成功[root@oliva ~]# ps -ef | grep redisroot 6558 1 0 07:16 ? 00:00:00 ./redis-server 127.0.0.1:6379root 6563 5640 0 07:16 pts/0 00:00:00 grep --color=auto redis 配置路径123456# 配置全局路径[root@oliva ~]# vi /etc/profile.d/redis.sh# redis environmentexport REDIS_HOME=/redis/appexport PATH=$REDIS_HOME/bin:$PATH[root@oliva ~]# source /etc/profile 加入systemd管理123456789101112131415# 加入systemd管理前请kill掉原有的redis进程[root@oliva ~]# vi /etc/systemd/system/redis.service[Unit]Description=redis-serverAfter=network.target[Service]Type=forkingExecStart=/redis/app/bin/redis-server /redis/conf/redis_6379.conf PrivateTmp=true[Install]WantedBy=multi-user.target[root@oliva ~]# systemctl daemon-reload[root@oliva ~]# systemctl start redis.service[root@oliva ~]# systemctl enable redis.service 优化123456# 查看启动日志，根据启动日志中的warning优化配置[root@oliva ~]# cat /redis/log/redis_6379.log # 此处省略日志内容[root@oliva ~]# echo vm.overcommit_memory = 1 &gt;&gt; /etc/sysctl.conf[root@oliva ~]# echo never &gt;&gt; /sys/kernel/mm/transparent_hugepage/enabled 常用配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 监听地址，默认是监听本地环回地址；设置为0.0.0.0，表示监听所有ip地址bind 127.0.0.1# 监听端口，默认6379port 6379# 保护模式，默认开启；如果没有配置bind，那么远程服务器是不能直接查看键值数据的protected-mode yes# 密码requirepass foobared# ack队列长度tcp-backlog 511# 客户端与服务端的连接超时时间，0表示永不超时timeout 0# 会话探测时间，redis服务端默认每隔300s发ack包给客户端，探测客户端是否还在，还在就保持连接tcp-keepalive 300# 是否以守护进程方式在后台运行，默认为nodaemonize no# pid文件路径pidfile /var/run/redis_6379.pid# 日志级别，有debug,verbose,notice,warningloglevel notice# 日志路径logfile /usr/local/redis/reids_6379.log# 是否把日志输出到系统日志，默认为nosyslog-enabled no# 设置数据库个数，从0号数据库开始，默认为17个databases 16# 在启动时是否显示日志always-show-logo yes# 在900秒内修改一个键触发快照save 900 1# 在300秒修改10个键触发快照save 300 10# 在60秒修改10000个键触发快照save 60 10000# 在快照出现问题时，禁止redis写入操作stop-writes-on-bgsave-error yes# 进行持久化时，是否压缩，默认为压缩rdbcompression yes# 在保存或者加载rdb数据库时是否开启校验rdbchecksum yes# rdb文件名，可以修改dbfilename dump.rdb# 数据库文件存放路径dir /usr/local/redis/6379 持久化机制与配置redis所有数据都是保存在内存中，如果没有配置持久化，重启后数据就会全丢失了。因此需要开启redis的持久化功能，将数据保存到磁盘上，当redis重启后，可以从磁盘中恢复数据。同时，也可以对持久化数据进行备份，方便故障恢复 redis提供两种方式进行持久化，一种是RDB持久化，一种是AOF（append only file）持久化 RBDRDB模式默认开启，它是通过快照（snapshotting）完成的。当符合在Redis.conf 配置文件中设置的条件时，Redis会自动将内存中的所有数据进行快照并存储在硬盘上，完成数据备份。除了自动快照，还可以发送SAVE和BGSAVE命令让redis手动执行快照 Redis重新启动后，会读取RDB快照文件，将数据从硬盘载入到内存， 实现方式（子进程备份）Redis使用fork函数复制（写时复制）一份当前进程（父进程）的副本（子进程），父进程继续接收并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文 件，当子进程写入完所有数据后会用该临时文件替换旧的RDB文件，至此一次快照操作完成 常用配置（redis.conf）12345678910111213141516171819save 900 1 # 900秒内有至少1个键被更改则进行快照save 300 10 # 300秒内有至少10个键被更改则进行快照save 60 10000 # 60秒内有至少10000个键被更改则进行快照# 后台存储发生故障时，客户端停止写入stop-writes-on-bgsave-error yes# 在存储过程中，启动压缩rdbcompression yes# 启动redis时，是否检查rdb数据库的完整性rdbchecksum yes# rdb数据库的名字，可自定义dbfilename dump.rdb# rdb数据、aof数据存放路径，可以自定义dir /var/lib/redis AOFAOF模式默认关闭，它以日志的形式记录服务器所处理的每一个写、删除、修改操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录 AOF日志会在持续运行中持续增大，需要定期进行重写（rewrite），对AOF日志进行瘦身。可以发送bgrewriteaof命令手动重写 实现方式开启AOF持久化后，每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件 在Redis重启时，会加载AOF日志，逐个执行AOF文件中的命令来将硬盘中的数据载入到内存中，恢复时间较慢 常用配置（redis.conf）123456789101112131415161718192021222324# aof是否开启，默认为no，不开启appendonly yes # 指定aof文件名称 appendfilename appendonly.aof # 指定aof操作中文件同步策略，有三个合法值：always everysec no，认为everysec# always:每次操作同步 everysec：每秒同步 no：不同步appendfsync everysec# aof-rewrite期间，appendfsync是否暂缓文件同步，"no"表示“不暂缓”，“yes”表示“暂缓”，默认为“no” no-appendfsync-on-rewrite no # aof文件rewrite触发的最小文件尺寸(mb,gb)，只有大于此尺寸的aof文件会触发rewrite，默认“64mb” auto-aof-rewrite-min-size 64mb # aof文件大小相比上次文件大小，增长100%时，重写auto-aof-rewrite-percentage 100# 是否忽略可能存在问题的指令（比如写入一半断电）aof-load-truncated yes# rdb数据、aof数据存放路径，可以自定义dir /var/lib/redis 两者对比 redis 4.0 后支持两种模式同时开启 如果服务器开启了 AOF 持久化功能，会优先使用 AOF 文件来进行恢复。只有在 AOF 关闭状态下，服务器才会使用 RDB 文件来进行还原 模式 RDB AOF 数据安全性 丢数据 根据策略决定 恢复速度 快 慢 恢复优先级 低 高 日志文件体积 小 大 混合持久化混合持久化，其实就是 RDB 与 AOF 的混合模式，这是 Redis4 之后新增的。 实现方式混合持久化通过 aof-use-rdb-preamble 参数来开启。它在写入的时候，先把数据以 RDB 的形式写入文件的开头，再将后续的修改数据的命令以 AOF 的格式追加到文件中。这样既能保证数据恢复时的速度，同时又能减少数据丢失的风险 在 Redis 重启时，先加载 RDB 的内容，然后再重放增量 AOF 格式命令。这样就避免了 AOF 持久化时的全量加载，从而使加载速率得到大幅提升 常用配置（redis.conf）12# 混合持久化开关，默认开启aof-use-rdb-preamble yes]]></content>
      <categories>
        <category>数据库基础</category>
      </categories>
      <tags>
        <tag>数据库基础</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[华为交换机vlan配置（基于端口和子网方式）]]></title>
    <url>%2F2020%2F06%2F08%2F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%2Fhw_vlan_port_subnet%2F</url>
    <content type="text"><![CDATA[网络拓扑图 交换机SW1配置基于端口划分vlan，连接PC端口均为access口；SW2连接PC端口均为hybrid口，且配置基于子网划分vlan；vlan划分如下表所示； 交换机 端口 端口类型 VLAN设置 对端设备 SW1 0/0/1 access 2 192.168.1.1/24 SW1 0/0/2 access 3 192.168.2.1/24 SW1 0/0/3 access 4 192.168.3.1/24 SW1 0/0/24 trunk 2 3 4 SW2 SW2 0/0/1 hybrid 2 3 4 192.168.1.2/24 SW2 0/0/2 hybrid 2 3 4 192.168.2.2/24 SW2 0/0/3 hybrid 2 3 4 192.168.3.2/24 SW2 0/0/24 trunk 2 3 4 SW1 交换机SW1配置1234567891011121314151617181920&lt;Huawei&gt;sys[Huawei]vlan batch 2 4[Huawei]interface GigabitEthernet 0/0/1[Huawei-GigabitEthernet0/0/1]port link-type access [Huawei-GigabitEthernet0/0/1]port default vlan 2[Huawei-GigabitEthernet0/0/1]quit[Huawei]interface GigabitEthernet 0/0/2[Huawei-GigabitEthernet0/0/2]port link-type access [Huawei-GigabitEthernet0/0/2]port default vlan 3[Huawei-GigabitEthernet0/0/2]quit[Huawei]interface GigabitEthernet 0/0/3[Huawei-GigabitEthernet0/0/3]port link-type access [Huawei-GigabitEthernet0/0/3]port default vlan 4[Huawei-GigabitEthernet0/0/3]quit[Huawei]interface GigabitEthernet 0/0/24[Huawei-GigabitEthernet0/0/24]port link-type trunk [Huawei-GigabitEthernet0/0/24]port trunk allow-pass vlan 2 to 4[Huawei-GigabitEthernet0/0/24]quit[Huawei]quit&lt;Huawei&gt;save 交换机SW2配置12345678910111213141516171819202122232425262728293031323334&lt;Huawei&gt;sys[Huawei]vlan batch 2 4#配置端口类型并启用根据子网划分vlan功能[Huawei]interface GigabitEthernet 0/0/1[Huawei-GigabitEthernet0/0/1]port link-type hybrid [Huawei-GigabitEthernet0/0/1]port hybrid untagged vlan 2 to 4[Huawei-GigabitEthernet0/0/1]ip-subnet-vlan enable[Huawei-GigabitEthernet0/0/1]quit[Huawei]interface GigabitEthernet 0/0/2[Huawei-GigabitEthernet0/0/2]port link-type hybrid[Huawei-GigabitEthernet0/0/2]port hybrid untagged vlan 2 to 4[Huawei-GigabitEthernet0/0/2]ip-subnet-vlan enable[Huawei-GigabitEthernet0/0/2]quit[Huawei]interface GigabitEthernet 0/0/3[Huawei-GigabitEthernet0/0/3]port link-type hybrid[Huawei-GigabitEthernet0/0/3]port hybrid untagged vlan 2 to 4[Huawei-GigabitEthernet0/0/3]ip-subnet-vlan enable[Huawei-GigabitEthernet0/0/3]quit[Huawei]interface GigabitEthernet 0/0/24[Huawei-GigabitEthernet0/0/24]port link-type trunk [Huawei-GigabitEthernet0/0/24]port trunk allow-pass vlan 2 to 4[Huawei-GigabitEthernet0/0/24]quit# 配置根据子网划分vlan[Huawei]vlan 2[Huawei-vlan2]ip-subnet-vlan 2 ip 192.168.1.0 255.255.255.0[Huawei-vlan2]quit[Huawei]vlan 3[Huawei-vlan3]ip-subnet-vlan 3 ip 192.168.2.0 255.255.255.0[Huawei-vlan3]quit[Huawei]vlan 4[Huawei-vlan4]ip-subnet-vlan 4 ip 192.168.3.0 255.255.255.0[Huawei-vlan4]quit[Huawei]quit&lt;Huawei&gt;save 测试使用ip地址为192.168.1.1的PC测试ping地址为192.168.1.2的PC，能够ping通，测试通过 ensp拓扑下载百度网盘链接 链接：https://pan.baidu.com/s/1uTmnWrEhtDU2_nkFUjwyZQ提取码：5wv6]]></content>
      <categories>
        <category>网络基础</category>
      </categories>
      <tags>
        <tag>网络基础</tag>
        <tag>交换机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[华为交换机开启telnet远程配置]]></title>
    <url>%2F2020%2F05%2F30%2F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%2Fhw_remote_config%2F</url>
    <content type="text"><![CDATA[网络拓扑图 由于ensp上的PC不具有telnet客户端功能，所以此处使用Cloud桥接本机网卡，在本机上进行telnet测试 交换机SW配置1234567891011121314151617181920212223242526272829303132333435363738394041&lt;Huawei&gt;system-view# 配置vlan1的IP以及默认路由# 192.168.2.1为本机桥接网卡的IP,一般使用虚拟机的适配器进行桥接，不要使用以太网连接桥接[Huawei]interface vlanif1[Huawei-Vlanif1]ip address 192.168.2.254 24[Huawei]quit[Huawei]ip route-static 0.0.0.0 0.0.0.0 192.168.2.1# 定义允许同时建立的telnet会话数量0-4共5个# 进入用户界面视图[Huawei]user-interface vty 0 4# 启动终端服务[Huawei-ui-vty0-4]shell# 指定telnet为vty使用协议,[Huawei-ui-vty0-4]protocol inbond telnet###############口令鉴别方式和AAA鉴别方式二选一################################口令鉴别方式#################### 指定口令鉴别方式[Huawei-ui-vty0-4]authentication-mode password# 指定登录口令 cipher表示密文方式存储口令[Huawei-ui-vty0-4]set authentication password cipher 520123# 配置远程用户权限[Huawei-ui-vty0-4]user privilege level 15[Huawei-ui-vty0-4]quit################AAA鉴别方式#################### 指定AAA鉴别方式[Huawei-ui-vty0-4]authentication-mode aaa# 配置远程用户权限[Huawei-ui-vty0-4]user privilege level 15[Huawei-ui-vty0-4]quit# 进入aaa视图[Huawei]aaa# 建立一个用户名为huawei、密码为520123的授权用户[Huawei-aaa]local-user huawei password cipher 520123# 指定huawei用户为telnet用户类型[Huawei-aaa]local-user huawei service-type telnet[Huawei-aaa]quit 1234567# 配置连接PC的端口为vlan1(拓扑图中是连接cloud的端口)[Huawei]interface GigabitEthernet 0/0/1[Huawei-GigabitEthernet0/0/1]port link-type access [Huawei-GigabitEthernet0/0/1]port default vlan 1[Huawei-GigabitEthernet0/0/1]quit[Huawei]quit&lt;Huawei&gt;save Cloud配置 PC机上telnet登录验证 ensp拓扑下载百度网盘链接 链接：https://pan.baidu.com/s/1INqncPcvEYnGWaV6WjwoRQ提取码：9igf]]></content>
      <categories>
        <category>网络基础</category>
      </categories>
      <tags>
        <tag>网络基础</tag>
        <tag>交换机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 网络配置基础-IP和路由]]></title>
    <url>%2F2020%2F05%2F01%2FLinux%E5%9F%BA%E7%A1%80%2Fip-route-config%2F</url>
    <content type="text"><![CDATA[序言CentOS系统的网络管理有network和NetwokManager两种服务，建议关闭其中一种，目前笔者遇见过两个服务冲突时会出现网卡没法重启，提示：Failed to start LSB：Bring up/down networking错误 建议在生产服务器上关闭NetwokManager，而在家用、娱乐的系统上可以关闭network CentOS6默认的最小安装时只有network，没有NetwokManager，可以用以下命令检查是否安装了NetworkManager： 12345678910111213141516171819# 可以看到init3级别下，服务NetworkManager启动，而network关闭[root@Emma ~]# chkconfig --list | grep -i netwNetworkManager 0:off 1:off 2:on 3:on 4:on 5:on 6:offnetwork 0:off 1:off 2:off 3:off 4:off 5:off 6:off# 关闭NetworkManager服务[root@Emma ~]# service NetworkManager stop# 关闭NetworkManager开机启动[root@Emma ~]# chkconfig NetworkManager off# 开启network服务[root@Emma ~]# service network start# 关闭NetworkManager开机启动[root@Emma ~]# chkconfig network on# 可以使用以下命令（开启|停止|重启|查看）network服务[root@Emma ~]# /etc/init.d/network start|stop|reload|status# service控制network与以上相同效果，其实就是调用network命令[root@Emma ~]# service network start|stop|restart|status CentOS7最小安装时既有network，也有有NetwokManager；可以用以下命令关闭NetwokManager 12345678910# 将NetwokManager服务关闭[root@neil ~]# systemctl stop NetworkManager# 将NetworkManager 服务设置开机不启动[root@neil ~]# systemctl disable NetworkManagerRemoved symlink /etc/systemd/system/multi-user.target.wants/NetworkManager.service.Removed symlink /etc/systemd/system/dbus-org.freedesktop.nm-dispatcher.service.Removed symlink /etc/systemd/system/network-online.target.wants/NetworkManager-wait-online.service.# 查看是否开机开启[root@neil ~]# systemctl is-enabled NetworkManagerdisabled Centos6 下网络配置以下配置均是适用于network服务，关闭NetworkManager服务 静态IP配置以下仅列出常用配置 12345678910111213141516#添加或修改/etc/sysconfig/network-scripts/ifcfg-eth0[root@localhost ~]vi /etc/sysconfig/network-scripts/ifcfg-eth0DEVICE=eth1 #指出设备名称HWADDR=00:0C:29:D7:CE:D9 #Mac地址TYPE=Ethernet #网络类型UUID=8564ce31-d0bf-4d02-b455-36c9e69d91f7ONBOOT=yes #是否在系统启动时应用此配置NM_CONTROLLED=no #修改后无需要重启网卡立即生效，依赖于NetworkManager，不配置BOOTPROTO=static #启动类型 static，静态IPIPADDR=192.168.0.202 #IP地址NETMASK=255.255.255.0 #子网掩码NETWORK=192.168.0.0 #网络地址，可不配置，系统会自动计算BROADCAST=192.168.0.255 #广播地址，可不配置，系统会自动计算GATEWAY=192.168.0.1 #默认网关，可不配置，但生产环境推荐配置DNS=114.114.114.114 #DNS地址MTU=1452 #设置MTU值 生产环境常用最小配置如下： 123456789DEVICE=eth1 #指出设备名称HWADDR=00:0C:29:D7:CE:D9 #Mac地址TYPE=Ethernet #网络类型UUID=8564ce31-d0bf-4d02-b455-36c9e69d91f7ONBOOT=yes #是否在系统启动时应用此配置BOOTPROTO=static #启动类型 static，静态IPIPADDR=192.168.0.202 #IP地址NETMASK=255.255.255.0 #子网掩码GATEWAY=192.168.0.1 #默认网关，生产环境推荐配置 DHCP（待验证,生产环境不常用）1234567[root@localhost ~]# vi /etc/sysconfig/network-scripts/ifcfg-eth0DEVICE=eth1 #指出设备名称HWADDR=00:0C:29:D7:CE:D9 #Mac地址TYPE=Ethernet #网络类型UUID=8564ce31-d0bf-4d02-b455-36c9e69d91f7ONBOOT=yes #是否在系统启动时应用此配置BOOTPROTO=dhcp #启动类型 dhcp 单网卡配置多个静态IP方法一123456789101112131415161718[root@Emma ~]# more /etc/sysconfig/network-scripts/ifcfg-eth1 DEVICE=eth1HWADDR=00:0C:29:D7:CE:D9TYPE=EthernetUUID=8564ce31-d0bf-4d02-b455-36c9e69d91f7ONBOOT=yesNM_CONTROLLED=yesBOOTPROTO=staticIPADDR=192.168.0.202NETMASK=255.255.255.0GATEWAY=192.168.0.1MTU=1452DNS=114.114.114.114# 添加IP，设置多个IP同理增加 IPADDR_2 | IPADDR_3IPADDR1=192.168.0.242NETMASK1=255.255.255.0GATEWAY1=192.168.0.1 方法二1234567891011121314151617181920212223242526272829303132333435# 复制一个配置文件ifcfg-eth1:0[root@Emma ~]# cp /etc/sysconfig/network-scripts/ifcfg-eth1 /etc/sysconfig/network-scripts/ifcfg-eth1:0# 修改DEVICE和IP信息，保存[root@Emma ~]# vi /etc/sysconfig/network-scripts/ifcfg-eth1:0DEVICE=eth1:0 #修改为与配置文件对应的eth1:0 HWADDR=00:0C:29:D7:CE:D9TYPE=EthernetUUID=8564ce31-d0bf-4d02-b455-36c9e69d91f7ONBOOT=yesNM_CONTROLLED=yesBOOTPROTO=staticIPADDR=192.168.0.252NETMASK=255.255.255.0#GATEWAY=192.168.0.2 #生产环境尽量不要配置多个网关，会导致各种问题MTU=1452DNS=114.114.114.114# 重启network[root@Emma ~]# service network restart# 查看配置eth1:0已生效[root@Emma ~]# ifconfig -aeth1 Link encap:Ethernet HWaddr 00:0C:29:D7:CE:D9 inet addr:192.168.0.202 Bcast:192.168.0.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fed7:ced9/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1452 Metric:1 RX packets:56189 errors:0 dropped:0 overruns:0 frame:0 TX packets:9876 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:61006316 (58.1 MiB) TX bytes:1041327 (1016.9 KiB)eth1:0 Link encap:Ethernet HWaddr 00:0C:29:D7:CE:D9 inet addr:192.168.0.252 Bcast:192.168.0.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1452 Metric:1 静态路由配置(永久)目前路由如下： 123456[root@Emma network-scripts]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.1.0 0.0.0.0 255.255.255.0 U 0 0 0 eth2192.168.0.0 0.0.0.0 255.255.255.0 U 0 0 0 eth10.0.0.0 192.168.1.1 0.0.0.0 UG 0 0 0 eth2 方法一在/etc/sysconfig/network-scripts创建route-[interface]，格式为： 12$DST_NET via $GW_IP$DST_HOST via $GW_IP 123456789101112131415# 以eth1路由为例；创建route-eth1[root@Emma ~]# vi /etc/sysconfig/network-scripts/route-eth1192.168.2.0/24 via 192.168.0.1 # 到网段的路由192.168.3.1 via 192.168.0.1 # 到主机的路由# 重启network，查看路由表[root@Emma ~]# service network restart[root@Emma ~]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.3.1 192.168.0.1 255.255.255.255 UGH 0 0 0 eth1192.168.2.0 192.168.0.1 255.255.255.0 UG 0 0 0 eth1192.168.1.0 0.0.0.0 255.255.255.0 U 0 0 0 eth2192.168.0.0 0.0.0.0 255.255.255.0 U 0 0 0 eth10.0.0.0 192.168.1.1 0.0.0.0 UG 0 0 0 eth2 方法二在/etc/sysconfig/创建static-route，格式为： 12any net $DST_NET gw $GW_IPany host $DST_HOST gw $GW_IP 12345678910111213141516171819202122# [root@Emma ~]# vi /etc/sysconfig/static-routes any net 192.168.4.0/24 gw 192.168.1.254any net 192.168.5.0 netmask 255.255.255.0 gw 192.168.1.254any host 192.168.6.1 gw 192.168.0.254# 重启network，查看路由表[root@Emma ~]# service network restart[root@Emma ~]# route -n[root@Emma ~]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.3.1 192.168.0.1 255.255.255.255 UGH 0 0 0 eth1192.168.6.1 192.168.0.254 255.255.255.255 UGH 0 0 0 eth1192.168.5.0 192.168.1.254 255.255.255.0 UG 0 0 0 eth2192.168.4.0 192.168.1.254 255.255.255.0 UG 0 0 0 eth2192.168.2.0 192.168.0.1 255.255.255.0 UG 0 0 0 eth1169.254.0.0 0.0.0.0 255.255.0.0 U 1002 0 0 eth1169.254.0.0 0.0.0.0 255.255.0.0 U 1003 0 0 eth20.0.0.0 192.168.1.1 0.0.0.0 UG 0 0 0 eth2# 配置默认网关可以用如下形式any net 0.0.0.0 gw 192.168.1.254 dev eth2 静态路由配置(临时,不常用)123456789101112# 使用route 命令添加的路由，机器重启或者网卡重启后路由就失效了，方法：# 添加到主机的路由[root@Emma ~]# route add -host 192.168.100.0 dev eth1[root@Emma ~]# route add –host 192.168.100.10 gw 192.168.0.1# 添加到网络的路由[root@Emma ~]# route add –net 192.168.100.0 netmask 255.255.255.0 eth1[root@Emma ~]# route add –net 192.168.100.0 netmask 255.255.255.0 gw 192.168.0.1[root@Emma ~]# route add –net 192.168.100.0/24 eth1# 添加默认网关[root@Emma ~]# route add default gw 192.168.0.1# 删除路由[root@Emma ~]# route del –host 192.168.100.10 dev eth0 Centos7 下网络配置以下配置均是适用于network服务，关闭NetworkManager服务 静态IP配置123456789101112131415161718192021#添加或修改/etc/sysconfig/network-scripts/ifcfg-eth0[root@neil ~]# vi /etc/sysconfig/network-scripts/ifcfg-ens33 TYPE=Ethernet # 网络类型:以太网PROXY_METHOD=none # 代理方式:关闭状态BROWSER_ONLY=no # 只是浏览器:否BOOTPROTO=static # 网卡的引导协议:static,使用静态IPDEFROUTE=yes # 默认路由:是IPV4_FAILURE_FATAL=no # 是不开启IPV4致命错误检测:否IPV6INIT=yes # IPV6是否自动初始化: 是IPV6_AUTOCONF=yes # IPV6是否自动配置:是IPV6_DEFROUTE=yes # IPV6是否可以为默认路由:是IPV6_FAILURE_FATAL=no # 是否开启IPV6致命错误检测:否IPV6_ADDR_GEN_MODE=stable-privacy # IPV6地址生成模型:stable-privacyNAME=ens33 # 网卡物理设备名称UUID=1ac737f7-a9a7-4312-9be9-7677688d5345 # 通用唯一识别码DEVICE=ens33 # 网卡物理设备名称，必须和 `NAME` 值一样ONBOOT=yes # 是否开机启动IPADDR=192.168.0.212 # IP地址NETMASK=255.255.255.0 # 配置子网掩码GATEWAY=192.168.0.1 # 网关DNS1=114.114.114.114 # DNS 单网卡配置多个静态IP(与CentOS6相同)方法一1234567891011121314151617181920212223TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=staticDEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=ens33UUID=1ac737f7-a9a7-4312-9be9-7677688d5345DEVICE=ens33ONBOOT=yesIPADDR=192.168.0.212NETMASK=255.255.255.0GATEWAY=192.168.0.1DNS1=114.114.114.114# 添加IP地址，设置多个IP同理增加 IPADDR_2 | IPADDR_3IPADDR1=192.168.1.212NETMASK1=255.255.255.0GATEWAY1=192.168.1.1 方法二1234567891011121314151617181920212223242526# 复制一个配置文件ifcfg-ens33:0[root@neil ~]# cp /etc/sysconfig/network-scripts/ifcfg-ens33 /etc/sysconfig/network-scripts/ifcfg-ens33:0# 修改NAME、DEVICE和IP信息[root@neil ~]# vi /etc/sysconfig/network-scripts/ifcfg-ens33:0TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=staticDEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=ens33:0UUID=1ac737f7-a9a7-4312-9be9-7677688d5345DEVICE=ens33:0ONBOOT=yesIPADDR=192.168.0.253NETMASK=255.255.255.0GATEWAY=192.168.0.1DNS1=114.114.114.114# 重启network后生效 [root@neil ~]# systemctl restart network 静态路由配置(永久，与CentOS6相同)12345[root@neil ~]# ip route showdefault via 192.168.0.1 dev ens33 169.254.0.0/16 dev ens33 scope link metric 1002 192.168.0.0/24 dev ens33 proto kernel scope link src 192.168.0.212 192.168.1.0/24 dev ens33 proto kernel scope link src 192.168.1.212 在/etc/sysconfig/network-scripts创建route-[interface]，格式为： 12$DST_NET via $GW_IP dev $DEVICE$DST_HOST via $GW_IP dev $DEVICE 1234567891011121314# 以ens33路由为例；创建route-ens33[root@neil ~]# vi /etc/sysconfig/network-scripts/route-ens335.2.20.0/24 via 192.168.0.1 dev ens335.2.21.145 via 192.168.0.253# 重启network，验证[root@neil ~]# systemctl restart network[root@neil ~]# ip route showdefault via 192.168.0.1 dev ens33 5.2.20.0/24 via 192.168.0.1 dev ens33 5.2.21.145 via 192.168.0.253 dev ens33 169.254.0.0/16 dev ens33 scope link metric 1002 192.168.0.0/24 dev ens33 proto kernel scope link src 192.168.0.212 192.168.1.0/24 dev ens33 proto kernel scope link src 192.168.1.212 静态路由配置(临时,不常用)1234567891011121314151617181920212223242526添加路由：ip route add 192.168.2.0/24 via 192.168.150.253 dev ens33删除路由：ip route del 192.168.2.0/24 via 192.168.150.253 dev ens33查看指定网段的路由ip route list 192.168.2.0/24追加路由ip route append 192.168.2.0/24 via 192.168.1.12 #追加一个指定网络的路由，为了平滑切换网关使用修改路由ip route change 192.168.2.0/24 via 192.168.1.11ip route replace 192.168.2.0/24 via 192.168.1.111清空指定网络的路由ip route flush 192.168.2.0/24 #这个是清理所有192.168.2.0/24相关的所有路由，有时候设置错网关存在多条记录，就需要一次性清空相关路由再进行添加添加默认路由ip route add default via 192.168.1.1指定路由metircip route add 192.168.2.0/24 via 192.168.1.15 metric 10]]></content>
      <categories>
        <category>Linux基础</category>
      </categories>
      <tags>
        <tag>计算机基础</tag>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IP网络存储iSCSI概念与CentOS 6实现]]></title>
    <url>%2F2020%2F01%2F08%2F%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80%2FCentOS6-iSCSI-base%2F</url>
    <content type="text"><![CDATA[概念太长不看：iSCSI initiator就是iscsi的客户端，iSCSI target就是iscsi的server，lun在iscsi里lun就代表一个可以通过iscsi访问的存储设备 SCSI介绍SCSl是小型计算机系统接口（Small Computer System Interface）的简称，SCSI作为输入/输出接口，主要用于硬盘、光盘、磁带机、扫描仪、打印机等设备 SAN介绍存储区域网络（Storage Area Network）简称SAN，它是一种通过光纤交换机、光纤路由器、光纤集线器等设备将磁盘阵列、磁带等存储设备与相关服务器连接起来的高速专用子网SAN由3个部分组成，分别是连接设备（如路由器、光纤交换机和Hub）、接口（如SCSI、FC）、通信协议（如IP和SCSI）。这3个部分再加上存储设备和服务器就构成了一个SAN系统。SAN捉供了一个灵活的、高性能的和高扩展性的存储网络环境，它可以更加有效地传输海量的数据块 iSCSl即internet SCSI，是IETF制订的一项标准，用于将SCSI数据块映射为以太网数据包。该技术将存储行业广泛应用的SCSI接口技术与IP网络技术相结合，可以在IP网络上构建SAN。简单地说，iSCSI就是在IP网络上运行SCSI协议的一种网络存储技术 iSCSI InitiatoriSCSI Initiator是一个安装在计算机上的软件或硬件设备，它负责与iSCSI存储设备进行通信 软件方式，即iSCSI Initiator软件。在iSCSI服务器上安装lnitiator后，Initiator软件可以将以太网卡上虚拟iSCSl卡，进而接受和发送iSCSI数据报文，从而实现主机和iSCSI存储设备之间的iSCSI协议和TCP/IP协议传输功能。这种方式只需以太网卡和以太网交换机，无需其他设备，因此成本是最低的。但是iSCSI报文和TCP/IP报文转换需要消耗iSCSI服务器的一部分CPU资源，只有在低I/O和低带竞性能要求的应用环境中才能使用这种方式硬件iSCSI HBA（Host Bus Adapter）卡方式，即iSCSI Initiator硬件。这种方式需要先购买iSCSI的HBA卡，然后将其安装在iSCSI服务器上，从而实现iSCSI服务器与交换机之间、iSCSI服务器与存储设备之间的高效数据传输。与第一种方式相比，硬件iSCSIHBA卡方式不需要消耗iSCSI服务器的CPU资源，同时硬件设备是专用的，所以基于硬件的iSCSI Initiator可以提供更好的数据传输和存储性能。但是，iSCSI HBA卡的价格比较昂贵，因此用户要在性能和成本之间进行权衡 iSCSI Target一个可以用于存储数据的iSCSI磁盘阵列或者具有iSCSI功能的设备都可以被称为”iSCSI Target”，大多数操作系统都可以利用一些软件将系统转变为一个“iSCSI Target” 利用iSCSI Target软件，可以将服务器的存储空间分配给客户机使用，客户机可以像使用本地硬盘一样使用iSCSI磁盘，包括对其进行分区、格式化及读写等。而且每个客户端都可以向iSCSI磁盘写数据，互不干扰，并且不会破坏存储到服务器中的数据。同时，iSCSI Target软件对用户权限控制非常灵活，支持配置文件。对于iSCSI Target，应该为每个独立阵列中的两个独立端口配备交换机，最后将交换机连接起来，采用这种配置方式，即使两个交换机中的一个出现了故障，整个iSCSI存储系统仍然能够正常工作，这保证了存储系统的不间断运行 CentOS下的操作环境： 2台CentOS-6.10-x86_64，服务端IP：192.168.0.204，客户端IP：192.168.0.202 需要用到的软件为： 服务端：scsi-target-utils 客户端：iscsi-initiator-utils 服务端查看是否安装软件 1[root@Neil ~]# yum list installed | grep 'scsi-target-utils.x86_64' 安装软件 123456789#查找可安装的与scsi相关的软件[root@Neil ~]# yum list | grep 'scsi'iscsi-initiator-utils.x86_64 6.2.0.873-27.el6_9 base iscsi-initiator-utils-devel.x86_64 6.2.0.873-27.el6_9 base lsscsi.x86_64 0.23-3.el6 base scsi-target-utils.x86_64 1.0.24-18.el6 base #安装scsi-target-utils[root@Neil ~]# yum -y install scsi-target-utils.x86_64 划分要共享存储区域 1234567891011#此处将使用文章《CentOS 6软RAID配置》中已划分好的/dev/md0#查看/dev/md0信息[root@Neil ~]# fdisk -l | grep /dev/md0 -A10Disk /dev/md0: 3218 MB, 3218079744 bytes2 heads, 4 sectors/track, 785664 cylindersUnits = cylinders of 8 * 512 = 4096 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 262144 bytes / 786432 bytesDisk identifier: 0xfcac6c58 Device Boot Start End Blocks Id System 配置共享存储 1234567#修改/etc/tgt/targets.conf 文件[root@Neil ~]# vim /etc/tgt/targets.conf#增加以下配置&lt;target iqn.2020-01.com.example:server.target204&gt; backing-store /dev/md0 initiator-address 192.168.0.202&lt;/target&gt; 注： iqn.2020-01.com.example:server.target204 #共享名称 backing-store /dev/md0 #共享卷名及路径 initiator-address 192.168.0.202 #允许访问的地址 启动服务 12345678910111213141516171819202122232425262728293031323334353637383940414243#重启服务[root@Neil ~]# service tgtd restart#配置开机启动[root@Neil ~]# chkconfig tgtd on#查看允许状态 端口3260[root@Neil ~]# netstat -anp | grep '3260'tcp 0 0 0.0.0.0:3260 0.0.0.0:* LISTEN 1445/tgtd tcp 0 0 :::3260 :::* LISTEN 1445/tgtd#查看target状态[root@Neil ~]# tgt-admin -sTarget 1: iqn.2020-01.com.example:server.target204 System information: Driver: iscsi State: ready I_T nexus information: LUN information: LUN: 0 Type: controller SCSI ID: IET 00010000 SCSI SN: beaf10 Size: 0 MB, Block size: 1 Online: Yes Removable media: No Prevent removal: No Readonly: No Backing store type: null Backing store path: None Backing store flags: LUN: 1 Type: disk SCSI ID: IET 00010001 SCSI SN: beaf11 Size: 3218 MB, Block size: 512 Online: Yes Removable media: No Prevent removal: No Readonly: No Backing store type: rdwr Backing store path: /dev/md0 Backing store flags: Account information: ACL information: 192.168.0.202 客户端安装软件 1[root@Neil ~]# yum -y install iscsi-initiator-utils.x86_64 iscsiadm命令 iscsiadm是基于命令行的iscsi管理工具，提供了对iSCSI节点、会话、连接以及发现记录的操作。iscsiadm的使用说明可以运行man iscsiadm或iscsiadm –help 12345678910参数： -m &#123;discovery|node|session|iface&#125; #&#123;发现某服务器是否有target输出，以及输出了哪些target|管理跟某target的关联关系|会话管理 |接口管理&#125; -d &#123;0-8&#125; #打印调试信息，有0到8这9个等级 -t #这里可以使用的类型为sendtargets(可简写为st)、slp、fw和 isns，此选项仅用于discovery模式，且目前仅支持st、fw和isns；其中st表示允许每个iSCSItarget发送一个可用target列表给initiator； -T #用于指定target的名字 -p #指定target服务的IP和端口, -p 192.168.1.55:3260 -o #指定针对discoverydb数据库的操作，其仅能为new、delete、update、show和nonpersistent其中之一 -I #指定执行操作的iSCSI接口，这些接口定义在/var/lib/iscsi/ifaces中 -l #登录节点 -u #登出节点(服务器) 发现target 1234#端口为默认的3260可以不写[root@Neil ~]# iscsiadm -m discovery -t sendtargets -p 192.168.0.204Starting iscsid: [ OK ]192.168.0.204:3260,1 iqn.2020-01.com.example:server.target204 登录 123456[root@Neil ~]# iscsiadm -m node –T iqn.2020-01.com.example:server.target204 -p 192.168.0.204 -lLogging in to [iface: default, target: iqn.2020-01.com.example:server.target204, portal: 192.168.0.204,3260] (multiple)Login to [iface: default, target: iqn.2020-01.com.example:server.target204, portal: 192.168.0.204,3260] successful.#如果要系统启动时自动登入[root@Neil ~]# iscsiadm -m node –T iqn.2020-01.com.example:server.target204 -p 192.168.0.204 --op update -n node.startup -v automatic 分区 1234567891011121314151617181920212223242526272829303132#使用fdisk -l查看可以发现多出一块磁盘，我这边是/dev/sdb,对其分区[root@Neil ~]# fdisk /dev/sdb#####这里会显示一些警告信息Command (m for help): n Command action e extended p primary partition (1-4)pPartition number (1-4): 1First cylinder (1-1024, default 1): Using default value 1Last cylinder, +cylinders or +size&#123;K,M,G&#125; (1-1024, default 1024): Using default value 1024Command (m for help): wThe partition table has been altered!Calling ioctl() to re-read partition table.Syncing disks.##查看分区情况[root@Neil ~]# fdisk -l |grep -A10 '/dev/sdb' Disk /dev/sdb: 3218 MB, 3218079744 bytes99 heads, 62 sectors/track, 1024 cylindersUnits = cylinders of 6138 * 512 = 3142656 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0xfcac6c58 Device Boot Start End Blocks Id System/dev/sdb1 1 1024 3142625 83 Linux 挂载 1234567891011121314#创建文件系统[root@Neil ~]# mkfs.ext4 /dev/sdb#新建挂载点[root@Neil ~]# mkdir /root/iscsiTest#挂载[root@Neil ~]# mount /dev/sdb /root/iscsiTest#开机自动加载[root@Neil ~]# blkid /dev/sdb/dev/sdb: UUID="89023214-5338-4fa5-9ba0-9b80b26d8f3f" TYPE="ext4" [root@Neil ~]# vi /etc/fstab #添加下面这一行UUID=89023214-5338-4fa5-9ba0-9b80b26d8f3f /root/iscsiTest ext4 defaults 0 0 取消挂载和登出 12345678910[root@Neil ~]# umount /dev/sdb[root@Neil ~]# vi /etc/fstab #删除下面这一行UUID=89023214-5338-4fa5-9ba0-9b80b26d8f3f /root/iscsiTest ext4 defaults 0 0#取消开机自动登录[root@Neil ~]# iscsiadm -m node –T iqn.2020-01.com.example:server.target204 -p 192.168.0.204 --op update -n node.startup -v manual#登出[root@Neil ~]# iscsiadm -m node –T iqn.2020-01.com.example:server.target204 -p 192.168.0.204 –u]]></content>
      <categories>
        <category>存储基础</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 6软RAID配置]]></title>
    <url>%2F2020%2F01%2F01%2F%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80%2FCentOS6-RAID%2F</url>
    <content type="text"><![CDATA[Linux内核中有一个md(multiple devices)模块在底层管理RAID设备，它会在应用层给我们提供一个应用程序的工具mdadm（multiple devices admin），mdadm 是Linux下的一款标准的软件RAID 管理工具。其支持将任何块设备做成RAID，但需要注意的是为同一块磁盘的不同分区做RAID没有任何意义 mdadm命令的模式 模式 进入方法（参数） 创建模式（常用） -C 管理模式 -add 或者 –del 监控模式 -F 增长模式（常用） -G 装配模式 -A 实验环境 CentOS-6.10-x86_64，以创建raid5为例，使用4块硬盘，其中3块做raid5，1块热备 系统硬盘情况如下： 123456789101112[root@Neil ~]# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsr0 11:0 1 3.7G 0 rom sda 8:0 0 40G 0 disk ├─sda1 8:1 0 500M 0 part /boot└─sda2 8:2 0 39.5G 0 part ├─vg_neil-lv_root (dm-0) 253:0 0 35.6G 0 lvm / └─vg_neil-lv_swap (dm-1) 253:1 0 3.9G 0 lvm [SWAP]sdb 8:16 0 1G 0 disk sdc 8:32 0 1G 0 disk sdd 8:48 0 1G 0 disk sde 8:64 0 1G 0 disk 其中sdb，sdc，sdd，sde为本次实验所使用的的硬盘，尚未分区 硬盘分区分区使用fdisk或者gdisk对硬盘进行分区，以/dev/sdb为例 1234567891011121314[root@Neil ~]# fdisk /dev/sdb#####此处会显示一些提示信息#############可以使用m获取帮助，n为新建分区，根据交互创建分区即可，直接划成一个分区####Command (m for help): nCommand action e extended p primary partition (1-4)pPartition number (1-4): 1First cylinder (1-130, default 1): Using default value 1Last cylinder, +cylinders or +size&#123;K,M,G&#125; (1-130, default 130): Using default value 130 修改分区类型默认新建分区的类型是Linux，代号83，我们需要将其修改为raid 类型。输入”t” ，然后输入”L” 列出所有的文件格式，这里我们选择fd Linux raid auto, 输入fd，分区格式已经变更为Linux raid autodetect 1234567891011Command (m for help): tSelected partition 1Hex code (type L to list codes): L########此处显示支持的分区类型与id对应表，常用以下三种###############83 Linux8e Linux LVMfd Linux raid autoHex code (type L to list codes): fdChanged system type of partition 1 to fd (Linux raid autodetect) 保存分区12345Command (m for help): wThe partition table has been altered!Calling ioctl() to re-read partition table.Syncing disks. 对其他三块硬盘做同样操作，检查四个硬盘是否都分区完成 12345[root@Neil ~]# fdisk -l | grep -v 'Disk' | grep '/dev/sd[bcde]'/dev/sdb1 1 130 1044193+ fd Linux raid autodetect/dev/sdc1 1 130 1044193+ fd Linux raid autodetect/dev/sdd1 1 130 1044193+ fd Linux raid autodetect/dev/sde1 1 130 1044193+ fd Linux raid autodetect 配置RAID创建RAID512345[root@Neil ~]# mdadm -C /dev/md0 -a yes -l 5 -n 3 /dev/sd&#123;b,c,d,e&#125; -x 1 -c 256K########此处显示警告信息，已有分区是否继续创建raid#######Continue creating array? ymdadm: Defaulting to version 1.2 metadatamdadm: array /dev/md0 started. 参数说明： 参数 同义 含义 -C /dev/md0 --create 创建阵列，阵列设备/dev/md0 `-a {yes no}` --auto -l --level 阵列模式，常用阵列模式有 linear, raid0, raid1, raid4, raid5, raid6, raid10等 -n --raid-devices= 阵列中活动磁盘的数目，该数目加上备用磁盘的数目应该等于阵列中总的磁盘数目 -x --spare-devices= 指定热备盘的块数 -c 指明chunk块大小为256K 查看一下RAID状态使用mdadm -D /dev/md0查看详细信息，或者cat /proc/mdstat查看简略信息 12345678910111213141516171819202122232425262728293031[root@Neil ~]# mdadm -D /dev/md0/dev/md0: Version : 1.2 Creation Time : Sat Aug 9 12:49:57 2008 Raid Level : raid5 Array Size : 2095104 (2046.00 MiB 2145.39 MB) Used Dev Size : 1047552 (1023.00 MiB 1072.69 MB) Raid Devices : 3 Total Devices : 4 Persistence : Superblock is persistent Update Time : Sat Aug 9 12:50:03 2008 State : clean Active Devices : 3Working Devices : 4 Failed Devices : 0 Spare Devices : 1 Layout : left-symmetric Chunk Size : 256K Name : Neil.Emma:0 (local to host Neil.Emma) UUID : ddf710c0:08608d78:86a800e6:3eeb33f3 Events : 18 Number Major Minor RaidDevice State 0 8 16 0 active sync /dev/sdb 1 8 32 1 active sync /dev/sdc 4 8 48 2 active sync /dev/sdd 3 8 64 - spare /dev/sde 123456[root@Neil ~]# cat /proc/mdstatPersonalities : [raid6] [raid5] [raid4] md0 : active raid5 sdd[4] sde[3](S) sdc[1] sdb[0] 2095104 blocks super 1.2 level 5, 256k chunk, algorithm 2 [3/3] [UUU] unused devices: &lt;none&gt; 生成配置文件该配置文件的主要作用是系统启动的时候能够自动加载软RAID，同时也方便日后管理。但不是必须的，推荐对该文件进行配置。 12345[root@Neil ~]# mdadm -Ds /dev/md0 &gt;&gt; /etc/mdadm.conf[root@Neil ~]# cat /etc/mdadm.conf ARRAY /dev/md0 metadata=1.2 name=Neil.Emma:0 UUID=a07d0b5c:14ee15e3:b787794c:f2fe59e2ARRAY /dev/md0 metadata=1.2 spares=1 name=Neil.Emma:0 UUID=ddf710c0:08608d78:86a800e6:3eeb33f3 挂载创建文件系统1[root@Neil ~]# mkfs.ext4 /dev/md0 -L "RAID5-MD0" 建立挂载点并挂载123456789[root@Neil ~]# mkdir /raid5[root@Neil ~]# mount /dev/md0 /raid5[root@Neil ~]# df -hFilesystem Size Used Avail Use% Mounted on/dev/mapper/vg_neil-lv_root 35G 826M 33G 3% /tmpfs 931M 0 931M 0% /dev/shm/dev/sda1 477M 39M 413M 9% /boot/dev/md0 2.0G 3.0M 1.9G 1% /raid5 开机自动挂载将/dev/md0写入/etc/fstab 1234567891011121314151617[root@Neil ~]# cat /etc/fstab ## /etc/fstab# Created by anaconda on Sat Dec 7 03:32:26 2019## Accessible filesystems, by reference, are maintained under '/dev/disk'# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#/dev/mapper/vg_neil-lv_root / ext4 defaults 1 1UUID=169f024b-957c-4d4e-81a9-bb5cb94c1992 /boot ext4 defaults 1 2/dev/mapper/vg_neil-lv_swap swap swap defaults 0 0tmpfs /dev/shm tmpfs defaults 0 0devpts /dev/pts devpts gid=5,mode=620 0 0sysfs /sys sysfs defaults 0 0proc /proc proc defaults 0 0/dev/md0 /raid5 ext4 defaults 0 0 其他操作向RAID添加一个新的硬盘12[root@Neil ~]# mdadm -G /dev/md0 -n 4 -a /dev/sdfmdadm: added /dev/sdf 参数说明： 参数 同义 含义 -G --grow 改变阵型大小或形态 -n --raid-devices= 阵列中活动磁盘的数目 -a --add 添加设备到阵列 查看raid状态 123456[root@Neil ~]# cat /proc/mdstatPersonalities : [raid6] [raid5] [raid4] md0 : active raid5 sdf[5] sdc[1] sdb[0] sde[3](S) sdd[4] 3142656 blocks super 1.2 level 5, 256k chunk, algorithm 2 [4/4] [U unused devices: &lt;none&gt; 发现磁盘空间没有增加 123[root@Neil ~]# df -h /dev/md0Filesystem Size Used Avail Use% Mounted on/dev/md0 2.0G 3.0M 1.9G 1% /raid5 使用命令进行空间同步，ext文件系统 12345678910[root@Neil ~]# resize2fs /dev/md0resize2fs 1.41.12 (17-May-2010)Filesystem at /dev/md0 is mounted on /raid5; on-line resizing requiredold desc_blocks = 1, new_desc_blocks = 1Performing an on-line resize of /dev/md0 to 785664 (4k) blocks.The filesystem on /dev/md0 is now 785664 blocks long.[root@Neil ~]# df -h /dev/md0Filesystem Size Used Avail Use% Mounted on/dev/md0 3.0G 3.0M 2.8G 1% /raid5 移除RAID成员磁盘移除RAID成员磁盘，必须先将想要移除的磁盘标记为损坏，否则报错 123456789101112131415##未标记为损坏，报错[root@Neil ~]# mdadm /dev/md0 -r /dev/sddmdadm: hot remove failed for /dev/sdd: Device or resource busy##标记为损坏，正常移除[root@Neil ~]# mdadm /dev/md0 -f /dev/sddmdadm: set /dev/sdd faulty in /dev/md0[root@Neil ~]# mdadm /dev/md0 -r /dev/sddmdadm: hot removed /dev/sdd from /dev/md0##此时热备盘sdf已经启用[root@Neil ~]# cat /proc/mdstat Personalities : [raid6] [raid5] [raid4] md0 : active raid5 sdf[5] sdc[1] sdb[0] sde[3] 3142656 blocks super 1.2 level 5, 256k chunk, algorithm 2 [4/4] [UUUU] 参数说明： 参数 含义 -r 移除设备 -f 将设备状态定为故障 删除磁盘上的对应RAID信息,当退出的磁盘不再参与RAID阵列时，可以将此RAID信息删除。 1[root@Neil ~]# mdadm --zero-superblock /dev/sdd 将已清除raid信息的磁盘重新添加至此RAID（相当于新硬盘加入RAID），这样就会重建分区数据了，此时sdd为热备盘 123456[root@Neil ~]# mdadm /dev/md0 -a /dev/sddmdadm: added /dev/sdd[root@Neil ~]# cat /proc/mdstat Personalities : [raid6] [raid5] [raid4] md0 : active raid5 sdd[4](S) sdf[5] sdc[1] sdb[0] sde[3] 3142656 blocks super 1.2 level 5, 256k chunk, algorithm 2 [4/4] [UUUU] 停止并移除阵列 12[root@Neil ~]# mdadm -S /dev/md0[root@Neil ~]# mdadm -r /dev/md0]]></content>
      <categories>
        <category>存储基础</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大华研发技术支持笔试回顾]]></title>
    <url>%2F2019%2F12%2F25%2F%E5%AE%89%E9%98%B2%E5%9F%BA%E7%A1%80%2Fdahua-interview-2019-12-25%2F</url>
    <content type="text"><![CDATA[笔试分为三部分：网络常见问题处理；SQL基础；操作系统基础 都是简答题，网络和Linux开放性比较强，应该主要看答题逻辑；操作系统基础以Linux命令居多，没想到会笔试这样的内容，之前命令都是各种补全或者help，没有刻意去记，吃大亏了，以下是部分题目 网络PC机A可以ping通PC机B的IP，但PC机B不能ping通PC机A的IP，如何排查问题?目前能想到的就三个原因： 防火墙拦截了ICMP报文 取消您两台电脑上的防火墙设置（实际项目上该情况最多） APR病毒 APR病毒导致PC机A ping 的B不一定是真正的B，PC机B ping 的A也不一定是真正的A；通过arp -a 与ipconfig /all 来判断A确实是A，B确实是B 网络波动 判断网络里是否有大量的广播包在影响网络通信 最后尝试：PC机B tracert PC机IP，判断哪里出了问题 画出某个网络拓扑图（家庭，学校，某个项目的都行）这个网上找吧。。。 SQL前面都是基本的增删改查，较简单，最后一题如下： mysql备份还原的方式有哪些？命令方式： 备份： mysqldump备份单个数据库： 1mysqldump -u user -h host -p password dbname&gt;filename.sql mysqldump备份数据库中的指定表 1mysqldump -u user -h host -p password dbname[tbname,[tbname…]]&gt;filename.sql mysqldump备份多个数据库 1mysqldump -u user -h host -p password --databases[dbname,[dbname…]]&gt;filename.sql 备份系统中所有的数据库 1mysqldump -u user -h host -p password --all-databases&gt;filename.sql 还原： 1mysql -u username -p [dbname] &lt; filename.sql SQLyog 工具 可以用sqlyog等工具备份还原 操作系统Windows系统和Linux系统查看端口是否被占用用什么命令？Windows： 1234#查看端口被占用情况netstat -aon|findstr "80"#查看相关进程tasklist|findstr "80" Linux： 123netstat -nlp | grep 8080#或者lsof -i:8080 Linux疑似中毒，如何排查，写出命令？ top查看什么进程占用了资源 用lsof -p &lt;PID&gt;,查看疑似病毒进程 w查看当前都有谁在登录 history回顾命令历史 ps检查所有的系统进程 netstat查看异常的网络连接 cat /etc/rc.local查看是否有异常内容 tcpdump抓包查看是否有报文发送到异常IP 暂时想到就这些了。。。]]></content>
      <categories>
        <category>安防基础</category>
      </categories>
      <tags>
        <tag>安防基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GB/T28181协议业务流程基础]]></title>
    <url>%2F2019%2F12%2F12%2F%E5%AE%89%E9%98%B2%E5%9F%BA%E7%A1%80%2FGB28181-base%2F</url>
    <content type="text"><![CDATA[国标介绍GB/T28181规定了公共安全视频监控联网系统）的互联结构，传输、交换、控制的基本要求和安全性要求，以及控制、传输流程和协议接口等技术要求,适用于公共安全视频监控联网系统的方案设计、系统检测、验收以及与之相关的设备研发、生产等 编码规则：国标编码规则分为编码规则A和编码规则B。除特殊地区外，大部分地区采用的均是编码规则A，以下主要介绍编码规则A 编码规则A由中心编码（8位）、行业编码（2位）、类型编码（3位）和序号（7位）四个码段共20位十进制数字字符构成，即系统编码 =中心编码 + 行业编码 + 类型编码 + 序号 码段 码位 含义 取值说明 中心编码 1、2 省级编号 由监控中心所在地的行政区划代码确定， 符合GB/T 2260-2007的要求 3、4 市级编号 5、6 区级编号 7、8 基层接入单位编号 行业编码 9、10 行业编码 类型编码 11、12、13 111～130 表示类型为前端主设备 118-网络视频录像机（NVR）编码 131～199表示类型为前端外围设备 131-摄像机编码132-网络摄像机（IPC）编码 200～299表示类型为平台设备 200-中心信令控制服务器编码 网络标识 14 网络标识编码 0、1、2、3、4为监控报警专网，5为公安信息网，6为政务网，7为Internet网，8为社会资源接入网，9预留 序号 15～20 设备、用户序号 SIPSIP（Session Initiation Protocol，会话初始协议）是由IETF（Internet Engineering Task Force，因特网工程任务组）制定的多媒体通信协议 它是一个基于文本的应用层控制协议，用于创建、修改和释放一个或多个参与者的会话。其状态码类似于HTTP协议 国标的信令主要采用了SIP协议：其中注册设备采用REGISTER；实况采用INVITE；回放控制采用INFO；设备信息查询通知采用MESSAGE，订阅事件采用SUBSCRIBE，事件通知采用NOTIFY 主要业务流程注册和保活设备或系统进入联网系统时向SIP服务器进行注册登记的工作模式。 如果设备或系统注册不成功，宜延迟一定的随机时间后重新注册 流程如下： SIP代理向SIP服务器发送REGISTER请求 SIP服务器向SIP代理发送响应401（未鉴权），并在响应的消息头WWW_Authenticate字段中给出适合SIP代理的认证体制和参数规范 SIP代理重新向SIP服务器发送REGISTER请求，在请求的Authorization字段给出鉴权认证信息； SIP服务器对请求进行验证，如果检查SIP代理身份合法，向SIP代理发送成功响应200 OK，如果身份不合法则发送拒绝服务应答 SIP代理默认每30秒发送发送一次保活报文，保活信息于MESSAGE BODY描述，超过3次未保活成功，则SIP服务器会认为SIP代理已离线 REGISTER中Expires字段描述了注册过期时间，再过期之前，SIP代理会刷新注册（CallID会一致） 实况实时视音频点播采用SIP协议（IETF RFC 3261）中的INVITE方法实现会话连接，采用RTP/RTCP协议（IETF RFC 3550）实现媒体传输 流程描述如下： 媒体流接收者向SIP服务器发送Invite消息，消息头域中携带Subject字段，表明点播的视频源ID、发送方媒体流序列号、媒体流接收者ID、接收端媒体流序列号等参数，SDP（为区别，图中为SDP1）消息体中s字段为“Play”代表实时点播 SIP服务器收到Invite请求后，通过三方呼叫控制建立媒体服务器和媒体流发送者之间的媒体连接。向媒体服务器发送Invite消息，此消息不携带SDP消息体； 媒体服务器收到SIP服务器的Invite请求后，回复200 OK响应，携带SDP（图中为SDP2）消息体，消息体中描述了媒体服务器接收媒体流的IP、端口、媒体格式等内容； SIP服务器收到媒体服务器返回的200 OK响应后，向媒体流发送者发送Invite请求，请求中携带消息3中媒体服务器回复的200 OK响应消息体，s字段为“Play”代表实时点播 媒体流发送者收到SIP服务器的Invite请求后，回复200 OK响应，携带SDP（图中为SDP3）消息体，消息体中描述了媒体流发送者发送媒体流的IP、端口、媒体格式、SSRC字段等内容； SIP服务器收到媒体流发送者返回的200 OK响应后，向媒体服务器发送ACK请求，请求中携带消息5中媒体流发送者回复的200 OK响应消息体，完成与媒体服务器的Invite会话建立过程 SIP服务器收到媒体流发送者返回的200 OK响应后，向媒体流发送者发送ACK请求，请求中不携带消息体，完成与媒体流发送者的Invite会话建立过程 完成三方呼叫控制后，SIP服务器建立了媒体流接收者和媒体服务器之间的媒体连接。在消息1中增加SSRC值，转发给媒体服务器 媒体服务器收到Invite请求，回复200 OK响应，携带SDP（图中为SDP4）消息体，消息体中描述了媒体服务器发送媒体流的IP、端口、媒体格式、SSRC值等内容 SIP服务器将消息9转发给媒体流接收者 媒体流接收者收到200 OK响应后，回复ACK消息，完成与SIP服务器的Invite会话建立过程 SIP服务器将消息11转发给媒体服务器，完成与媒体服务器的Invite会话建立过程 媒体流接收者向SIP服务器发送BYE消息，断开消息1、10、11建立的同媒体流接收者的Invite会话； SIP服务器收到BYE消息后回复200 OK响应，会话断开； SIP服务器收到BYE消息后向媒体服务器发送BYE消息，断开消息8、9、12建立的同媒体服务器的Invite会话； 媒体服务器收到BYE消息后回复200 OK响应，会话断开 SIP服务器向媒体服务器发送BYE消息，断开消息2、3、6建立的同媒体服务器的Invite会话； 媒体服务器收到BYE消息后回复200 OK响应，会话断开 SIP服务器向媒体流发送者发送BYE消息，断开消息4、5、7建立的同媒体流发送者的Invite会话； 媒体流发送者收到BYE消息后回复200 OK响应，会话断开 录像检索与回放检索 流程大致如下： 录像检索方向录像拥有方发送目录查询请求Message消息，消息体中包含视音频文件检索条件，包括查询的设备编码，查询时间段等，其中，消息体的CmdType字段为RecordInfo代表是录像检索 录像拥有方向录像检索方发送200 OK，无消息体； 录像拥有方以Message向录像检索方发送查询结果，消息体中含文件目录，当一条Message消息无法传送完所有查询结果时，采用多条消息传送； 录像检索方向录像拥有方发送200 OK，无消息体。 回放采用SIP协议中的INVITE方法实现会话连接，采用SIP扩展协议INFO方法的消息体携带视音频回放控制命令，采用RTP/RTCP协议实现媒体传输。媒体回放控制命令引用MANSRTSP协议中的PLAY，PAUSE，TEARDOWN 的请求消息和应答消息 回放总体可以分为三个部分，分别是会话连接，回放控制和资源释放，其中会话连接和资源释放与实况流程基本一致，消息体中的字段会区别回放还是实况 会话建立 回放控制 资源释放 流程描述如下： （会话建立）媒体流接收者向SIP服务器发送Invite消息，消息头域中携带Subject字段，表明点播的视频源ID、发送方媒体流序列号、媒体流接收者ID、接收端媒体流序列号标识等参数，SDP（图中为SDP1）消息体中s字段为“Playback”代表历史回放，u字段代表回放通道ID和回放类型，t字段代表回放时间段； SIP服务器收到Invite请求后，通过三方呼叫控制建立媒体服务器和媒体流发送者之间的媒体连接。向媒体服务器发送Invite消息，此消息不携带SDP消息体； 媒体服务器收到SIP服务器的Invite请求后，回复200 OK响应，携带SDP消息体，消息体中描述了媒体服务器接收媒体流的IP、端口、媒体格式等内容； SIP服务器收到媒体服务器返回的200 OK响应后，向媒体流发送者发送Invite请求，请求中携带消息3中媒体服务器回复的200 OK响应消息体，s字段为“Playback”代表历史回放，u字段代表回放通道ID和回放类型，t字段代表回放时间段，增加y字段描述SSRC值，f字段描述媒体参数； 媒体流发送者收到SIP服务器的Invite请求后，回复200 OK响应，携带SDP消息体，消息体中描述了媒体流发送者发送媒体流的IP、端口、媒体格式、SSRC字段等内容； SIP服务器收到媒体流发送者返回的200 OK响应后，向媒体服务器发送ACK请求，请求中携带消息5中媒体流发送者回复的200 OK响应消息体，完成与媒体服务器的Invite会话建立过程； SIP服务器收到媒体流发送者返回的200 OK响应后，向媒体流发送者发送ACK请求，请求中不携带消息体，完成与媒体流发送者的Invite会话建立过程； 完成三方呼叫控制后，SIP服务器建立媒体流接收者和媒体服务器之间的媒体连接。在消息1中增加SSRC值，转发给媒体服务器； 媒体服务器收到Invite请求，回复200 OK响应，携带SDP消息体，消息体中描述了媒体服务器发送媒体流的IP、端口、媒体格式、SSRC值等内容； SIP服务器将消息9转发给媒体流接收者； 媒体流接收者收到200 OK响应后，回复ACK消息，完成与SIP服务器的Invite会话建立过程； SIP服务器将消息11转发给媒体服务器，完成与媒体服务器的Invite会话建立过程； （控制）在回放过程中，媒体流接收者通过向SIP服务器发送会话内Info消息进行回放控制，包括视频的暂停、播放、快放、慢放、随机拖放播放等操作 SIP服务器收到消息13后转发给媒体流发送者 媒体流发送者收到消息14后回复200 OK响应； SIP服务器将消息15转发给媒体流接收者 媒体流发送者在文件回放结束后发送会话内Message消息，通知SIP服务器回放已结束 SIP服务器收到消息17后转发给媒体流接收者 媒体流接收者收到消息18后回复200 OK响应，进行链路断开过程； SIP服务器将消息19转发给媒体流发送者 （释放会话）媒体流接收者向SIP服务器发送BYE消息，断开消息1、10、11建立的同媒体流接收者的Invite会话 SIP服务器收到BYE消息后回复200 OK响应，会话断开 IP服务器收到BYE消息后向媒体服务器发送BYE消息，断开消息8、9、12建立的同媒体服务器的Invite会话 媒体服务器收到BYE消息后回复200 OK响应，会话断开 SIP服务器向媒体服务器发送BYE消息，断开消息2、3、6建立的同媒体服务器的Invite会话； 媒体服务器收到BYE消息后回复200 OK响应，会话断开 SIP服务器向媒体流发送者发送BYE消息，断开消息4、5、7建立的同媒体流发送者的Invite会话； 媒体流发送者收到BYE消息后回复200 OK响应，会话断开 设备信息查询设备信息查询包括目录查询、前端设备信息查询、前端设备状态查询、设备配置查询、预置位查询等，查询的范围包括本地SIP域或者跨SIP域。网络设备信息查询命令和响应均采用方法MESSAGE实现 源设备包括SIP客户端、网关或联网系统，目标设备包括SIP设备、网关或联网系统 源设备向SIP服务器发送设备查询命令，设备查询命令采用MESSAGE方法携带 SIP服务器收到命令后返回200 OK SIP服务器向目标设备转发设备查询命令，设备查询命令采用MESSAGE方法携带 目标设备收到命令后返回200 OK 目标设备向SIP服务器发送设备查询响应命令，设备查询响应命令采用MESSAGE方法携带 SIP服务器收到命令后返回200 OK SIP服务器向源设备转发查询响应命令，设备查询响应命令采用MESSAGE方法携带 目标设备收到命令后返回200 OK 订阅与通知订阅事件订阅使用SUBSCRIBE方法，事件源接受事件订阅时，事件源向事件观察者发送确认消息。 订阅流程如下： 事件观察者向事件源发送SUBSCRIBE请求，请求消息体携带订阅参数 事件源应将订阅成功与否的响应消息返回给该事件观察者 通知 在订阅事件触发后事件源向事件观察者发送NOTIFY消息，NOTIFY的消息体应携带通知参数； 事件源应将通知的响应消息返回给该事件观察者 总结常见问题以设备注册问题、实况问题、回放问题为主，遇到有争议的问题时，最好对照下国标文档。 附GB28181-2011和GB28181-2016规范文档下载链接： https://skynemo-1258540788.cos.ap-chengdu.myqcloud.com/SkyNemo-Blog/security/protocol/GB28181-base/11-GB28181-Standard-Document.zip]]></content>
      <categories>
        <category>安防基础</category>
      </categories>
      <tags>
        <tag>安防基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[独立冗余磁盘阵列-RAID基础]]></title>
    <url>%2F2019%2F12%2F12%2F%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80%2FRAID-base%2F</url>
    <content type="text"><![CDATA[太长不看系列： RAID级别 有无容错 硬盘数 可用容量 允许故障硬盘数 使用场景 RAID0 无 $N\geq 2$ 100% 0 对性能要求高，但对数据安全性和可靠性要求低的场合，如临时数据缓存空间等 RAID1 有 $N\geq 2$且N为2的倍数 50% $\frac{N}{2}$ 对性能要求低，但对数据安全性和可靠性要求高的场合 RAID3 有 $N\geq 3$ $\frac{N-1}{N}$ 1 适用大容量数据的顺序访问应用，使用较少，被RAID5替代 RAID5 有 $N\geq 3$ $\frac{N-1}{N}$ 1 满足大部分的存储应用需求，数据中心数据存储、安防行业的音视频存储最常用的RAID级别 RAID6 有 $N\geq 4$ $\frac{N-2}{N}$ 2 对数据安全等级要求较高的场合，替代 RAID10 方案的经济性选择 RAID10 有 $N\geq 4$ 50% $\frac{N}{2}$ 对性能要求高，且对数据安全性和可靠性要求高的场合 RAID50 有 $N\geq 6$ $\frac{N-RAID5的组数}{N}$ 每组RAID5允许一块硬盘故障 对数据安全等级要求较高的场合，替代 RAID10 方案的经济性选择 RAID介绍后续增加。。。 RAID作用RAID相关技术RAID级别总结]]></content>
      <categories>
        <category>存储基础</category>
      </categories>
      <tags>
        <tag>存储基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机系统中的时间]]></title>
    <url>%2F2019%2F12%2F06%2FLinux%E5%9F%BA%E7%A1%80%2Fsystem-time%2F</url>
    <content type="text"><![CDATA[常见的时间缩写太长不看系列：UTC = GMT , CST = UTC + 时区 ，CST（国内） = 北京时间 UTC(英：Coordinated Universal Time ，法：Temps Universel Coordonné)：协调世界时 英国格林威治皇家天文台所在地的标准时间，UTC基于国际原子时间，是全世界统一的世界标准时间。也是表示地球自转速率的一种形式，需要不规则地加入闰秒。 GMT(Greenwich Mean Tim)：格林威治标准时间 一般认为UTC和GMT是相等的，但是会存在0.9秒以内的误差，这是由于地球不规则自转引起的。 CST(Central Standard Time)：中央标准时间 四大时区的时间，CST = UTC + 时区。东正西负。比如北京时间在东八区就是 UTC+(+0800)，在国内，一般认为CST就代表北京时间即可。 1234Central Standard Time (USA) UT-6:00（美国cst时间：零区时减6个小时）Central Standard Time (Australia) UT+9:30（澳大利亚cst：加9个半小时）China Standard Time UT+8:00（中国cst:加8个小时）Cuba Standard Time UT-4:00 （古巴cst:减4个小时） DST(Daylight Saving Time)，夏日节约时间，即夏令时 是指夏天太阳升起比较早，将时钟拨快一个小时来提早日光的使用。欧美主要国家都引用了这个做法。如果在夏令时时区内 DST=UTC+时区+1，中国已经废止。 CET(Central European Time)，欧洲中部时间 冬季时间为UTC+1，夏季欧洲夏令时为UTC+1+1。 Unix时间戳（Unix epoch, Unix time, POSIX time 或 Unix timestam） Unix时间戳是从1970年1月1日（UTC/GMT的午夜）开始所经过的秒数，不考虑闰秒。 计算机系统时钟 Hardware clock 硬件时钟 即BIOS时间，就是我们进行CMOS设置时看到的时间，计算机硬件有个电池供电的实时时钟(Real-time Clock, RTC)也叫(CMOS时钟，BIOS时间，三者同一)。使用的时间标准由操作系统设置。硬件时钟默认使用UTC时间，建议使用UTC全球时间标准，因为硬件时钟不能保存时区和夏令时调整，修改后就无法从硬件时钟中读取出准确标准时间，因此不建议修改为其他时间格式 Software clock 软件时钟 计算机系统运行时的时钟(Syetem clock)。 计算机系统时钟运行过程 关机状态：硬件时钟有电池供电，始终在主板上默默运行着。通电进入BIOS: 主板BIOS系统界面能够看到并设置硬件时间。电脑开机： 开机引导时：使用硬件时钟设置系统时钟。Arch Linux系统开机时间会更新到/etc/adjtime 系统运行时：系统正常运行后，由系统内核独自运行系统时钟。 时钟同步服务：需要联网，大部分操作系统都带有联网后能够和网络上的NTP服务器同步系统时钟，修正系统时间的准确性 系统关机时：会使用系统时钟设置硬件时钟，更新硬件时钟。 注：服务器系统开机后会连续运行数月，甚至数年。硬件时间与软件时间会出现差异，一般以系统时间为准 CentOS下时钟查看与维护*注：以下命令运行于系统版本：CentOS-6.10-x86_64 系统时钟查看系统时间1234# dateTue Jan 21 01:54:17 CST 2020# date -RTue, 21 Jan 2020 01:54:27 +0800 *注：+0800表示东八区（北京时间） 设置系统时间设置日期 123456# date -s 20200119Sun Jan 19 00:00:00 CST 2020# date -s 2020-01-20Mon Jan 20 00:00:00 CST 2020# date -s 2020/01/21Tue Jan 21 00:00:00 CST 2020 设置时间 12# date -s 01:40:00Tue Jan 21 01:40:00 CST 2020 设置日期和时间 12[root@Neil ~]# date -s "20080808 15:00:00"Fri Aug 8 15:00:00 CST 2008 更多时间显示方式或参数设置，请使用date --help查看 时区设置所有时区的信息存在/usr/share/zoneinfo/下面，本机的时区信息存在/etc/localtime，可以用复制（cp）或者创建链接（ln）的方式设置时区，以下以设置亚洲上海时区为例，其他时区形式可参考/usr/share/zoneinfo/路径或tzselect命令 123cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 硬件时钟hwclock可以打印/设定硬件时钟，cat /proc/driver/rtc可以查看RTC存储的时间 读硬件时钟 12# hwclockSun 08 Dec 2019 12:06:14 AM CST -0.954251 seconds 查看开机引导时更新的系统时刻 1234# cat /etc/adjtime0.000000 1575721137 0.0000001575721137UTC 1575721137 表示最近一次开机引导时，硬件时间与1970-01-01 00:00:00间隔的秒数，UTC表示硬件时间以UTC存储 设置硬件时钟 123# hwclock --set --date="20080808 14:55"# hwclockFri 08 Aug 2008 02:55:07 PM CST -0.876395 seconds 硬件时钟和系统时钟之间的同步硬件时钟与系统时钟同步将系统时间更新到硬件时钟，使用hwclock --systohc或者hwclock –w 1234567# dateFri Aug 8 14:57:28 CST 2008# hwclockFri 08 Aug 2008 12:00:21 AM CST -0.548385 seconds# hwclock -w# hwclockFri 08 Aug 2008 02:57:59 PM CST -0.469971 seconds 系统时钟与硬件时钟同步将硬件时间更新到系统时间，使用hwclock --hctosys或者hwclock –s 1234567# hwclockFri 08 Aug 2008 03:10:05 PM CST -0.157034 seconds# dateFri Aug 8 15:17:08 CST 2008# hwclock --hctosys# dateFri Aug 8 15:17:28 CST 2008 关于hwclock与硬件时钟(RTC)RTC查看硬件时钟cat /proc/driver/rtc: 1234567891011121314# cat /proc/driver/rtcrtc_time : 07:21:41rtc_date : 2008-08-08alrm_time : 00:00:00alrm_date : ****-**-**alarm_IRQ : noalrm_pending : no24hr : yesperiodic_IRQ : noupdate_IRQ : noHPET_emulated : yesDST_enable : noperiodic_freq : 1024batt_status : okay 这里的时间是“真正“的硬件时间，看下此时RTC与hwclock和hwclock --localtime的区别: 1234567891011121314151617181920# cat /proc/driver/rtcrtc_time : 07:21:41rtc_date : 2008-08-08alrm_time : 00:00:00alrm_date : ****-**-**alarm_IRQ : noalrm_pending : no24hr : yesperiodic_IRQ : noupdate_IRQ : noHPET_emulated : yesDST_enable : noperiodic_freq : 1024batt_status : okay[root@Neil ~]# hwclockFri 08 Aug 2008 03:21:49 PM CST -0.344394 seconds[root@Neil ~]# hwclock --localtimeFri 08 Aug 2008 07:22:00 AM CST -0.813282 seconds 可见hwclock --localtime和hwclock --utc的作用： 12hwclock --localtime #硬件被设定的时间hwclock --utc #显示的是当硬件时间为utc时，的真“本地时间” 注：当硬件时间存储为LOCAL时，hwclock --utc无意义 分析hwclock通过strace我们可以跟踪hwclock执行时打开的文件，分析hwclock。先安装strace: 1# yum -y install strace 追踪hwclock -r（同hwclock）: 12345678910111213141516171819# strace -e trace=open hwclock -r open("/etc/ld.so.cache", O_RDONLY) = 3open("/lib64/libaudit.so.1", O_RDONLY) = 3open("/lib64/libc.so.6", O_RDONLY) = 3open("/usr/lib/locale/locale-archive", O_RDONLY) = 4open("/dev/rtc", O_RDONLY) = 4open("/etc/adjtime", O_RDONLY) = 5open("/usr/share/zoneinfo/Universal", O_RDONLY) = 5open("/etc/localtime", O_RDONLY) = 5open("/usr/share/locale/locale.alias", O_RDONLY|O_CLOEXEC) = 5open("/usr/share/locale/en_US.UTF-8/LC_MESSAGES/util-linux-ng.mo", O_RDONLY) = -1 ENOENT (No such file or directory)open("/usr/share/locale/en_US.utf8/LC_MESSAGES/util-linux-ng.mo", O_RDONLY) = -1 ENOENT (No such file or directory)open("/usr/share/locale/en_US/LC_MESSAGES/util-linux-ng.mo", O_RDONLY) = -1 ENOENT (No such file or directory)open("/usr/share/locale/en.UTF-8/LC_MESSAGES/util-linux-ng.mo", O_RDONLY) = -1 ENOENT (No such file or directory)open("/usr/share/locale/en.utf8/LC_MESSAGES/util-linux-ng.mo", O_RDONLY) = -1 ENOENT (No such file or directory)open("/usr/share/locale/en/LC_MESSAGES/util-linux-ng.mo", O_RDONLY) = -1 ENOENT (No such file or directory)Sun 08 Dec 2019 10:16:29 PM CST -0.565908 seconds+++ exited with 0 +++ 可以看到： hwclock首先打开了/dev/rtc,读取硬件时钟； 打开/etc/adjtime文件，通过先前的记录来估算硬件时钟的偏差，读取并用来校正目前的时间，读取硬件时间标准（UTC或者LOCAL）； 打开/etc/localtime时区文件，若硬件时间为UTC，则将硬件时间转换为当前时区对映的时间。 更改硬件时间标准更改硬件时间标准为本地时间，不建议（LOCAL）: 12345# hwclock --systohc --localtime# cat /etc/adjtime0.000000 1575742061 0.0000001575742061LOCAL 更改硬件时间标准为UTC: 12345# hwclock --systohc --utc# cat /etc/adjtime0.000000 1575742277 0.0000001575742277UTC 其他时间操作查看最近一次开机时刻who -b： 12# who -b system boot 2019-12-08 23:11 查看系统连续运行时间uptime 12# uptime 15:55:06 up 2:29, 1 user, load average: 0.00, 0.00, 0.00 连续运行秒数cat /proc/uptime 12cat /proc/uptime8996.88 8968.96 CentOS 7的timedatectl*注：以下命令运行于系统版本：CentOS-7-x86_64-1908 关于timedatectl太长不看系列：一个比date更好用的命令 （官文翻译）timedatectl可用于查询和更改系统时钟及其设置，以及启用或禁用时间同步服务。使用systemd初始化已装载（但未引导）系统映像的系统时区。使用timedatectl可用于显示时间同步服务的当前状态 使用timedatectl查询系统时间/查看当前设置 123456789# timedatectl Local time: Mon 2019-12-09 02:03:45 CST Universal time: Sun 2019-12-08 18:03:45 UTC RTC time: Sun 2019-12-08 18:03:45 Time zone: Asia/Shanghai (CST, +0800) NTP enabled: n/aNTP synchronized: no RTC in local TZ: no DST active: n/a Local time：本地时间（系统时间） Universal time：全球时间 RTC time：硬件时间 Time zone：时区 NTP enabled：时间同步 NTP synchronized：NTP网络同步服务 RTC in local TZ：硬件时钟时间标准 DST active：夏令时 由上可以看到大部分常用的时间设置，值得注意的时，因为本机硬件时间为UTC标准，所以RTC时间（RTC time）与全球时间（Universal time）一致，与本地时间（Local time，东八区）相差8小时；如果硬件时间设置为LOCAL，则此处RTC时间与本地时间会相近（系统运行长时间后，硬件时间与系统时间不一定会相等；通常以系统时间为准） 设置系统时间 12# timedatectl set-time "2019-12-30 00:01:02"# timedatectl set-time "01:02:03" 列出所有时区 1# timedatectl list-timezones 巧用grep过滤下，timedatectl list-timezones | grep Asia列出所有亚洲时区 设置时区 1# timedatectl set-timezone Asia/Shanghai 更改硬件时间标准 12# timedatectl set-local-rtc 1# timedatectl set-local-rtc 0 0表示使用UTC作为硬件时间标准； 1表示使用本地时间作为硬件时间标准（不建议），执意使用，查询时间时（timedatectl）会出现警告： 123456Warning: The system is configured to read the RTC time in the local time zone. This mode can not be fully supported. It will create various problems with time zone changes and daylight saving time adjustments. The RTC time is never updated, it relies on external facilities to maintain it. If at all possible, use RTC in UTC by calling 'timedatectl set-local-rtc 0'. 是否开启NTP服务器同步** 12# timedatectl set-ntp yes# timedatectl set-ntp no 由于时间同步服务比较复杂，决定另开一篇介绍。]]></content>
      <categories>
        <category>计算机基础</category>
      </categories>
      <tags>
        <tag>计算机基础</tag>
        <tag>Linux基础</tag>
        <tag>时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode-11：盛最多水的容器]]></title>
    <url>%2F2019%2F07%2F29%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%2FLeetCode-11%2F</url>
    <content type="text"><![CDATA[示例: 12输入: [1,8,6,2,5,4,8,3,7]输出: 49 分析如题意，垂直的两条线段将会与坐标轴构成一个矩形区域，较短线段的长度将会作为矩形区域的宽度，两线间距将会作为矩形区域的长度，而我们必须最大化该矩形区域的面积。 矩阵的面积与两个因素有关： 矩阵的长度：两条垂直线的距离。 矩阵的宽度：两条垂直线其中较短一条的长度因此。 要矩阵面积最大化，两条垂直线的距离越远越好，两条垂直线的最短长度也要越长越好。矩形面积可以表示为：$S_{ij} = (i - j) \times min( a[i] , a[j] ) $，其中$(0\leq j&lt;i\leq n-1)$，$n$为数组长度。 解决方案方法一：暴力法算法这是最容易想到的方法，考虑每对可能出现的线段组合，使用变量maxarea来持续存储到目前为止所获得的最大面积。代码如下（C++，LeetCode运行直接超时）： 12345678910111213141516int maxArea_bruteForce(vector&lt;int&gt;&amp; height) &#123; int maxarea = 0; // 两层循环，外层循环遍历所有线段，内层遍历每条线段与在其之前线段组成的所有可能性，找到最大值 for (int i = 1; i &lt; height.size(); i++) &#123; for (int j = 0; j &lt; i; j++) &#123; int capcity = height.at(i) &lt; height.at(j) ? (i - j) * height.at(i) : (i - j) * height.at(j); if (maxarea &lt; capcity) &#123; maxarea = capcity; &#125; &#125; &#125; return maxarea;&#125; Java代码如下(执行用时：402 ms)： 1234567public int maxArea_bruteForce(int[] height) &#123; int maxarea = 0; for (int i = 0; i &lt; height.length; i++) for (int j = i + 1; j &lt; height.length; j++) maxarea = Math.max(maxarea, Math.min(height[i], height[j]) * (j - i)); return maxarea;&#125; 复杂度分析 时间复杂度：$O(n^2)$，计算所有种$O(\frac{n \times (n-1)}{2})$高度组合的面积。 空间复杂度：$O(1)$，使用恒定的额外空间。 方法二：双指针法算法这种方法背后的思路在于，两线段之间形成的区域总是会受到其中较短那条高度的限制。此外，两线段距离越远，宽度越大，得到的面积就越大。我们在由线段长度构成的数组中使用两个指针，一个放在开始，一个置于末尾。此外，我们会使用变量maxarea来持续存储到目前为止所获得的最大面积。$p$ 指针由开始向末尾移动，$q$ 指针由末尾向开始移动，当 $p = q$ 时，停止遍历。在每一步中，我们会找出指针所指向的两条线段形成的区域，更新maxarea，并将指向较短线段的指针向较长线段那端移动一步。 为什么是指向较短线段的指针向较长线段那端移动一步？最初我们考虑由最外围两条线段构成的区域。现在，为了使面积最大化，我们需要考虑更长的两条线段之间的区域。如果我们试图将指向较长线段的指针向内侧移动，矩形区域的面积将受限于较短的线段而不会获得任何增加。但是，在同样的条件下，移动指向较短线段的指针尽管造成了矩形宽度的减小，但却可能会有助于面积的增大。因为移动较短线段的指针会得到一条相对较长的线段，这可以克服由宽度减小而引起的面积减小。 如果两个指针指向的值相等，该移动哪一个呢？ 我们假设 $a[1]$ 和 $a[8]$ 高度是相等的。如果它们之间只有1个元素比它俩高或者没有比它俩高的，那么最大面积就一定选取是 $i = 1$ 和 $j = 8$ 了，所以 $i$ 接着变大，或者 $j$ 接着减小都是无所谓的，因为答案已经确定了。 假设$a[1]$和$a[8]$之间有2个元素比它俩高，假设是 $a[4]$ 和 $a[6]$ 两个元素。$i = 1$会变到 $i = 2$、$i = 3$，最终为 $i = 4$； $j = 8$ 会变到 $j = 7 $， $j = 6$，而在这个过程中产生的面积一定不会比 $i = 1$ 和 $j = 8$ 产生的面积大，因为变换过程中的高度都比$a[1]$和$a[8]$低。所以是先变 $i = 1$ 还是先变 $j = 8$ 是无所谓的，无非是谁先到达更长的柱子而已。 代码如下（C++，执行时间：24 ms）： 12345678910111213141516171819202122232425262728293031323334int maxArea_twoPointer(vector&lt;int&gt;&amp; height) &#123; int p = 0, q = height.size() - 1; // 前指针p，后指针q int maxarea = 0; // 变量area存储每次指针推进（p++或q--）后的矩形区域大小 int area = 0; // 变量maxarea存储当前出现最大的矩形区域 int width = q - p; // 变量width用于表示矩阵宽度，每次推进width-1 int heightP = 0; // 变量heightP存储a[p]的高度 int heightQ = 0; // 变量heightQ存储a[q]的高度 int maxHP = 0; // 变量maxHP存储当前出现的，p方向上最大高度max&#123;a[p]&#125; int maxHQ = 0; // 变量maxHQ存储当前出现的，q方向上最大高度max&#123;a[q]&#125; // 两边指针向中间推进 while (p &lt; q) &#123; heightP = height.at(p); heightQ = height.at(q); // 矩形面积为 S = 宽度 * 两边较小高度 if (heightP &lt; heightQ) &#123; area = weight * heightP; p++; &#125; else &#123; area = weight * heightQ; q--; &#125; if (maxarea &lt; area) &#123; maxarea = area; &#125; weight--; &#125; return maxarea;&#125; Java代码如下（执行用时：6 ms）： 123456789101112public int maxArea(int[] height) &#123; int maxArea = 0, l = 0, r = height.length - 1; while (l &lt; r) &#123; maxArea = Math.max(maxArea, Math.min(height[l], height[r]) * (r - l)); if (height[l] &lt; height[r]) l++; else r--; &#125; return maxArea;&#125; 优化如果移动后当前线段高度小于移动前线段的高度，因为移动后 $weidth$ 等于移动前 $weidth - 1 $，宽度高度均减小，最大矩形区域maxarea一定不会在该情况下出现，可以不用计算当前区域的面积，直接进行下一次指针移动。 再扩展一下，如果当前线段高度小于之前出现的最大高度，因为 $weidth$ 减小，所以最大矩形区域maxarea一定不会在该情况下出现，可以不用计算当前区域的面积，直接进行下一次指针移动。所以需要两个变量（maxHP、maxHQ）来记录左右指针遍历过的线段中的最大高度。这样不用每移动一次就要计算面积并与最大面积比较，减少计算次数。 代码如下（C++，执行时间：16 ms）： 1234567891011121314151617181920212223242526272829303132333435363738394041int maxArea_twoPointer(vector&lt;int&gt;&amp; height) &#123; int p = 0, q = height.size() - 1; // 前指针p，后指针q int maxarea = 0; // 变量area存储每次指针推进（p++或q--）后的矩形区域大小 int area = 0; // 变量maxarea存储当前出现最大的矩形区域 int width = q - p; // 变量width用于表示矩阵宽度，每次推进width-1 int heightP = 0; // 变量heightP存储a[p]的高度 int heightQ = 0; // 变量heightQ存储a[q]的高度 int maxHP = 0; // 变量maxHP存储当前出现的，p方向上最大高度max&#123;a[p]&#125; int maxHQ = 0; // 变量maxHQ存储当前出现的，q方向上最大高度max&#123;a[q]&#125; // 两边指针向中间推进 while (p &lt; q) &#123; heightP = height.at(p); heightQ = height.at(q); // 若当前高度a[p或q]小于当前方向上出现的最大高度，maxarea不会出现 if (heightP &lt; maxHP) &#123; p++; &#125; else if ( heightQ &lt; maxHQ) &#123; q++; &#125; else &#123; // 矩形面积为 S = 宽度 * 两边较小高度 if (heightP &lt; heightQ) &#123; area = width * heightP; p++; &#125; else &#123; area = width * heightQ; q--; &#125; if (maxarea &lt; area) &#123; maxarea = area; &#125; &#125; width--; &#125; return maxarea;&#125; 复杂度分析 时间复杂度：$O(n)$，一次扫描。 空间复杂度：$O(1)$，使用恒定的空间。]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>数组</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数组</tag>
        <tag>双指针</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法-3：桶排序、计数排序、基数排序]]></title>
    <url>%2F2019%2F07%2F17%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%2Falgo-sort-3%2F</url>
    <content type="text"><![CDATA[前两篇文章分析了几种常用排序算法的原理、时间复杂度、空间复杂度、稳定性等；本篇文章会讲三种时间复杂度为$O(n)$的排序算法：桶排序、计数排序、基数排序等。也因为其时间复杂度线性的，我们也称这类排序算法为线性排序（Linear sort）。之所以能够做到线性复杂度，主要原因是，这三个算法不是基于比较的排序算法，都不涉及元素之间的比较操作。 这几种排序算法理解起来都不难，时间、空间复杂度分析起来也很简单，但是对要排序的数据要求很苛刻，所以、学习重点的是掌握这些排序算法的适用场景。 桶排序（Bucket sort）桶排序，，核心思想是将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。 桶排序的时间复杂度为什么是$O(n)$呢？假设排序的数据有n个，我们把它们均匀地划分到m个桶内，每个桶里就有$k = \frac{n}{m}$个元素。每个桶内部使用快速排序，时间复杂度为$O(n\log(n))$。m个桶排序的时间复杂度就是$O(m \cdot k\cdot \log(k))$，因为$k = \frac{n}{m}$，所以整个桶排序的时间复杂度就是$O(n\cdot\log(\frac{n}{m}))$。当桶的个数m接近数据个数n时，$\log(\frac{n}{m})$就是一个非常小的常量，这个时候桶排序的时间复杂度接近$O(n)$。 桶排序是不是可以替代我们之前讲的排序算法呢？答案当然是否定的。刚才做了很多假设。实际上，桶排序对要排序数据的要求是非常苛刻的。首先，要排序的数据需要很容易就能划分成m个桶，并且，桶与桶之间有着天然的大小顺序。 这样每个桶内的数据都排序完之后，桶与桶之间的数据不需要再进行排序。其次，数据在各个桶之间的分布是比较均匀的。如果数据经过桶的划分之后，有些桶里的数据非常多，有些非常少，很不平均，那桶内数据排序的时间复杂度就不是常量级了。在极端情况下，如果数据都被划分到一个桶里，那就退化为$O(n\log(n))$的排序算法了。 桶排序比较适合用在外部排序中所谓的外部排序就是数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。 比如说我们有10GB的订单数据，我们希望按订单金额（假设金额都是正整数）进行排序，但是我们的内存有限，只有几百MB，没办法一次性把10GB的数据都加载到内存中。这个时候该怎么办呢？现在我来讲一下，如何借助桶排序的处理思想来解决这个问题。我们可以先扫描一遍文件，看订单金额所处的数据范围。假设经过扫描之后我们得到，订单金额最小是1元，最大是10万元。我们将所有订单根据金额划分到100个桶里，第一个桶我们存储金额在1元到1000元之内的订单，第二桶存储金额在1001元到2000元之内的订单，以此类推。每一个桶对应一个文件，并且按照金额范围的大小顺序编号命名（00，01，02..99）。理想的情况下，如果订单金额在1到10万之间均匀分布，那订单会被均匀划分到100个文件中，每个小文件中存储大约100MB的订单数据，我们就可以将这100个小文件依次放到内存中，用快排来排序。等所有文件都排好序之后，我们只需要按照文件编号，从小到大依次读取每个小文件中的订单数据，并将其写入到一个文件中，那这个文件中存储的就是按照金额从小到大排序的订单数据了。不过，你可能也发现了，订单按照金额在1元到10万元之间并不一定是均匀分布的，所以10GB订单数据是无法均匀地被划分到100个文件中的。有可能某个金额区间的数据特别多，划分之后对应的文件就会很大，没法一次性读入内存。这又该怎么办呢？ 针对这些划分之后还是比较大的文件，我们可以继续划分，比如，订单金额在1元到1000元之间的比较多，我们就将这个区间继续划分为10个小区间，1元到100元，101元到200元，201元到300元..901元到1000元。如果划分之后，101元到200元之间的订单还是太多，无法一次性读入内存，那就继续再划分，直到所有的文件都能读入内存为止。 计数排序（Counting sort）计数排序与桶排序十分类似。当要排序的n个数据，所处的范围并不大的时候，比如最大值是k，我们就可以把数据划分成k个桶。每个桶内的数据值都是相同的，省掉了桶内排序的时间。我们都经历过高考，高考查分数系统你还记得吗？我们查分数的时候，系统会显示我们的成绩以及所在省的排名。如果你所在的省有50万考生，如何通过成绩快速排序得出名次呢？考生的满分是750分，最小是0分，这个数据的范围很小，所以我们可以分成751个桶，对应分数从0分到750分。根据考生的成绩，我们将这50万考生划分到这750个桶里。桶内的数据都是分数相同的考生，所以并不需要再进行排序。我们只需要依次扫描每个桶，将桶内的考生依次输出到一个数组中，就实现了50万考生的排序。因为只涉及扫描遍历操作，所以时间复杂度是$O(n)$。 计数排序的算法思想就是这么简单，跟桶排序非常类似，只是桶的大小粒度不一样。不过，为什么这个排序算法叫“计数”排序呢？“计数”的含义来自哪里呢？ 想弄明白这个问题，我们就要来看计数排序算法的实现方法。我还拿考生那个例子来解释。为了方便说明，我对数据规模做了简化。 假设只有8个考生，分数在0到5分之间。我们使用数组A[8]存储这8个考生的成绩，它们分别是：{ 2，5，3，0，2，3，0，3 }。 考生的成绩从0到5分，我们使用大小为6的数组C[6]表示桶，其中下标对应分数。不过，C[6]内存储的并不是考生，而是某个分数对应的考生个数。像我刚刚举的那个例子，我们只需要遍历一遍考生分数，就可以得到C[6]的值，{ 2, 0, 2, 3 ,0, 1 }。 假设排序后的有序数组为R[8]，即成绩为3的考生，在R[8]中存储在下标为4，5，6三个位置。那么，我们需要如何快速计算出，每个分数的考生在有序数组R[8]中的位置？ 思路是这样的：我们对C[6]数组顺序求和，C[6]存储的数据就变成了{ 2, 2, 4, 7, 7, 8 }。即C[k]里存储小于等于分数k的考生个数。 我们从后到前依次扫描数组A。当扫描到3时，我们可以从数组C中取出下标为3的值7（ $c[3] = 7$ ），也就是说，到目前为止，包括自己在内，分数小于等于3的考生有7个，也就是说3是数组R中的第7个元素（也就是数组R中下标为6的位置）。当3放入到数组R中后，小于等于3的元素就只剩下了6个了，所以相应的C[3]要减1，变成6。以此类推，当我们扫描到第2个分数为3的考生的时候，就会把它放入数组R中的第6个元素的位置（也就是下标为5的位置）。当我们扫描完整个数组A后，数组R内的数据就是按照分数从小到大有序排列的了。 这种利用另外一个数组来计数的实现方式是不是很巧妙呢？这也是为什么这种排序算法叫计数排序的原因。不过，你千万不要死记硬背上面的排序过程，重要的是理解和会用。我总结一下，计数排序只能用在数据范围不大的场景中，如果数据范围k比要排序的数据n大很多，就不适合用计数排序了。而且，计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数。比如，还是拿考生这个例子。如果考生成绩精确到小数后一位，我们就需要将所有的分数都先乘以10，转化成整数，然后再放到9010个桶内。再比如，如果要排序的数据中有负数，数据的范围是[-1000，1000]，那我们就需要先对每个数据都加1000，转化成非负整数。]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法-2：归并、快速]]></title>
    <url>%2F2019%2F06%2F27%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%2Falgo-sort-2%2F</url>
    <content type="text"><![CDATA[上一篇文章讲了冒泡排序、插入排序、选择排序这三种排序算法，它们的时间复杂度都是$O(n^2)$，比较高，适合小规模数据的排序。而归并排序和快速排序时间复杂度均为$O(n\log(n))$。适合大规模的数据排序。归并排序和快速排序有一个共同点，它们都用到了分治思想。 归并排序（Merge Sort）归并排序的核心思想还是蛮简单的。如果要排序一个数组，我们先把数组从中间分成前后两部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起，这样整个数组就都有序了 这就是分治思想。将一个大问题分解成小的子问题来解决。小的子问题解决了，大问题也就解决了。 分治思想与递归思想很像。分治是一种解决问题的处理思想，递归是一种编程技巧，分治算法一般都是用递归来实现的。 回顾：递归代码两要素：1.递推公式，2.终止条件。然后将递推公式翻译成递归代码。 所以，要想写出归并排序的代码，我们先写出归并排序的递推公式。 12345递推公式：merge_sort(p…r) = merge(merge_sort(p…q), merge_sort(q+1…r))终止条件：p &gt;= r 不用再继续分解 merge_sort(p..r)表示，给下标从p到r之间的数组排序。我们将这个排序问题转化为了两个子问题，merge_sort(p..q)和merge_sort(q+1..r)，其中下标q等于p和r的中间位置，也就是$\frac{(\ p\ +\ r\ )}{2}$。当下标从p到q和从q+1到r这两个子数组都排好序之后，我们再将两个有序的子数组合并在一起，这样下标从p到r之间的数据就也排好序了。当p &gt;= r时，表示数组中只有一个元素。 将递推公式转化成代码（C） 123456789void __merge_sort(int* arr, int p, int r) &#123; int q; if (p &gt;= r) return; q = (p + r) / 2; __merge_sort(arr, p, q); __merge_sort(arr, q + 1, r); __merge(arr, p, q, r);&#125; 你可能已经发现了， __merge()这个函数的作用就是，将已经有序的arr[p..q]和arr[q+1..r]合并成一个有序的数组。那这个过程具体该如何做呢？我们可以申请一个临时数组tmp，大小与arr[p..r]相同。我们用两个游标 i 和 j ，分别指向arr[p..q]和arr[q+1..r]的第一个元素。比较这两个元素arr[i]和arr[j]，如果arr[i]&lt;=arr[j]，我们就把arr[i]放入到临时数组tmp，并且 i 后移一位，否则将arr[j]放入到数组tmp， j 后移一位。继续上述比较过程，直到其中一个子数组中的所有数据都放入临时数组中，再把另一个数组中的数据依次加入到临时数组的未尾，这个时候，临时数组中存储的就是两个子数组合并之后的结果了。最后再把临时数组tmp中的数据拷贝到原数组arr[p..r]中。 代码如下（C）： 1234567891011121314151617181920212223242526272829303132// 合并两个有序数组arr[p]-arr[q]、arr[q+1]-arr[r]，p为下标起点，q为下标中点，r为下标终点void __merge(int* arr, int p, int q, int r) &#123; int* tmp; int i, j, k; // 申请一个临时数组，大小与arr[p...r]相同 tmp = (int*)malloc((r - p + 1) * sizeof(int)); if (!tmp) &#123; abort(); &#125; // 循环判断两个数组中较小的数据，拷贝至临时数组 for (i = p, j = q + 1, k = 0; i &lt;= q &amp;&amp; j &lt;= r;) &#123; if (arr[i] &lt;= arr[j]) &#123; tmp[k++] = arr[i++]; &#125; else &#123; tmp[k++] = arr[j++]; &#125; &#125; // 判断哪个子数组有剩余数据 ，拷贝至临时数组中 if (i == q + 1) &#123; for (; j &lt;= r;) tmp[k++] = arr[j++]; &#125; else &#123; for (; i &lt;= q;) tmp[k++] = arr[i++]; &#125; // 将tmp数组在内存区直接复制到原数组中 memcpy(arr + p, tmp, (r - p + 1) * sizeof(int)); free(tmp);&#125; 归并排序的性能分析还记得分析排序算法的三个问题吗？接下来，我们来看归并排序的三个问题。 归并排序是稳定的排序算法吗？ 是。我们可以很明显看出，归并排序稳不稳定关键要看__merge()函数，也就是两个有序子数组合并成一个大的有序数组的那部分代码。在合并的过程中，如果arr[p..q]和arr[q+1..r]之间有值相同的元素，我们可以先把arr[p..q]中的元素（前部分中的元素）放入tmp数组。这样就保证了值相同的元素，在合并前后的先后顺序不变。所以，归并排序是一个稳定的排序算法。 归并排序的时间复杂度是多少？ 情况 时间复杂度 最好、最坏、平均情况 $O(n\log(n))$ 递归时间复杂度分析较复杂，初学者可以跳过。 回顾：递归的适用场景是，一个问题a可以分解为多个子问题b、c，那求解问题a就可以分解为求解问题b、c。问题b、c解决之后，我们再把b、c的结果合并成a的结果。 如果我们定义求解问题a的时间是T(a)，求解问题b、c的时间分别是T(b)和T(c)，那我们就可以得到这样的递推关系式： 1T(a) = T(b) + T(c) + K 其中K等于将两个子问题b、c的结果合并成问题a的结果所消耗的时间。 套用这个公式，我们来分析一下归并排序的时间复杂度。 我们假设对n个元素进行归并排序需要的时间是T(n)，那分解成两个子数组排序的时间都是T($\frac{n}{2}$)。我们知道，merge0函数合并两个有序子数组的时间复杂度是$O(n)$。所以，套用前面的公式，归并排序的时间复杂度的计算公式就是: 12T(1) = C； n=1 时，只需要常量级的执行时间，所以表示为 C。T(n) = 2*T(n/2) + n； n&gt;1 继续分解： 1234567T(n) = 2*T(n/2) + n = 2*(2*T(n/4) + n/2) + n = 4*T(n/4) + 2*n = 4*(2*T(n/8) + n/4) + 2*n = 8*T(n/8) + 3*n = 8*(2*T(n/16) + n/8) + 3*n = 16*T(n/16) + 4*n ...... = 2^k * T(n/2^k) + k * n ...... 通过这样一步一步分解推导，我们可以得到 ：$$T(n) = 2\cdot k \cdot T(\frac{n}{2^k}) + k\cdot n$$当 $T(\frac{n}{2^k}) = T(1)$时，也就是$\frac{n}{2^k} = 1$，我们得到 $k = log_2(n)$。们将k值代入上面的公式，得到 $T(n) = c \cdot n + n \cdot \log_2(n)$ 。如果我们用大O标记法来表示的话，T(n)就等于$O(n\log(n))$。所以归并排序的时间复杂度是$O(n\log(n))$。 归并排序的空间复杂度是多少？ 归并排序的空间复杂度$O(n)$。不是原地排序算法。 因为归并排序的合并函数，在合并两个有序数组为一个有序数组时，需要借助额外的存储空间。合并完成之后，临时开辟的内存空间就被释放掉了。临时内存空间最大也不会超过n个数据的大小，所以空间复杂度是$O(n)$。 快速排序（Quick Sort）快速排序算法（Quicksort），简称为“快排”。快排利用的也是分治思想。 快排的思想是这样的：如果要排序数组中下标从p到r之间的一组数据arr[p..r]，我们选择p到r之间的任意一个数据作为pivot（分区点）。遍历p到r之间的数据，将小于pivot的放到左边，将大于pivot的放到右边，将pivot放到中间。经过这一步骤之后，数组p到r之间的数据就被分成了三个部分，前面p到q-1之间都是小于pivot的（arr[p..q-1] &lt; pivot），中间是pivot，后面的q+1到r之间是大于pivot的（arr[p..q-1] &gt;= pivot）。 根据分治、递归的处理思想，我们可以用递归排序下标从p到q-1之间的数据和下标从q+1到r之间的数据，直到区间缩小为1，就说明所有的数据都有序了。如果我们用递推公式来将上面的过程写出来的话，就是这样： 12345递推公式：quick_sort(p…r) = quick_sort(p…q-1) + quick_sort(q+1, r)终止条件：p &gt;= r 翻译成代码(C)就是 : 12345678910111213// 快速排序递归函数，p，r为下标void _quick_sort(int* arr, int p, int r) &#123; // q为分区点下标 int q; if (p &gt;= r) &#123; return; &#125; // 获取分区点,对两个分区再快排 q = _quick_partition(arr, p, r); _quick_sort(arr, p, q - 1); _quick_sort(arr, q + 1, r);&#125; 归并排序中有一个 __merge()合并函数，我们这里有一个_quick_partition()分区函数。_quick_partition()分区函数实际上我们前面已经讲过了，就是随机选择一个元素作为pivot（一般情况下，可以选择p到r区间的最后一个元素），然后对arr[p..r]分区，函数返回pivot的下标。如果我们不考虑空间消耗的话，_quick_partition()分区函数可以写得非常简单。我们申请两个临时数组X和Y，遍历arr[p..r]，将小于pivot的元素都拷贝到临时数组X，将大于pivot的元素都拷贝到临时数组Y，最后再将数组X和数组Y中数据顺序拷贝到arr[p..r]。 但是，如果按照这种思路实现的话，_quick_partition()函数就需要很多额外的内存空间，所以快排就不是原地排序算法了。如果我们希望快排是原地排序算法，那它的空间复杂度得是$O(1)$，那_quick_partition()分区函数就不能占用太多额外的内存空间，我们就需要在arr[p..r]的原地完成分区操作。 这里先给出伪代码 123456789101112partition(A, p, r) &#123; pivot := A[r] i := p for j := p to r-1 do &#123; if A[j] &lt; pivot &#123; swap A[i] with A[j] i := i+1 &#125; &#125; swap A[i] with A[r] return i&#125; 这里的思想类似于选择排序。我们通过游标 i把arr[p..r-1]分成两部分。arr[p..i-1]的元素都是小于pivot的，我们暂且叫它“已处理区间“，arr[i..r-1]是“未处理区间“。我们每次都从未处理的区间arr[i..r-1]中取一个元素arr[j]，与pivot对比，如果小于pivot，则将其加入到已处理区间的尾部，也就是A[i]的位置。数组的插入操作还记得吗？在数组某个位置插入元素，需要搬移数据，非常耗时。当时我们也讲了一种处理技巧，就是交换，在$O(1)$的时间复杂度内完成插入操作。这里我们也借助这个思想，只需要将arr[i]与arr[j]交换，就可以在$O(n)$时间复杂度内将arr[j]放到下标为i的位置。 翻译成代码（C）： 12345678910111213141516171819202122232425262728// 交换元素void swap(int* a, int* b) &#123; int tmp = *a; *a = *b; *b = tmp;&#125;// 分区函数，返回分区点下标,取a[r]为pivotint _quick_partition(int* a, int p, int r) &#123; // i将数组分成已处理区间（arr[p]--arr[i-1]）和 // 未处理区间(arr[i]--arr[r-1]) // j遍历arr[p]--arr[r-1] int i,j; i = j = p; for (; j &lt; r ; j++) &#123; // 为方便起见，取a[r]为pivot if (a[j] &lt; a[r]) &#123; if (i != j) &#123; swap(a + i, a + j); &#125; i++; &#125; &#125; swap(a + r, a + i); return i;&#125; 快速排序的性能分析 快速排序是稳定的排序算法吗？ 不是，分区函数采用交换的方式，不是稳定的排序算法。 快速排序的空间复杂度是多少？ 空间复杂度$O(1)$，分区函数采用交换的方式，不需要额外的空间。 快速排序的时间复杂度是多少？ 情况 数组 时间复杂度 最坏情况 已有序 $O(n^2)$ 最好情况、平均情况 $O(n\log(n))$ 快排也是用递归来实现的。对于递归代码的时间复杂度，可以用之前的公式来分析。 12T(1) = C； n=1 时，只需要常量级的执行时间，所以表示为 C。T(n) = 2*T(n/2) + n； n&gt;1 但是，公式成立的前提是每次分区操作，我们选择的pivot都很合适，正好能将大区间对等地一分为二。但实际上这种情况是很难实现的。我举一个比较极端的例子。如果数组中的元素原来已经是有序的了，比如1，3，5，6，8。如果我们每次选择最后一个元素作为pivot，那每次分区得到的两个区间都是不均等的。我们需要进行大约n次分区操作，才能完成快排的整个过程。每次分区我们平均要扫描大约n/2个元素，这种情况下，快排的时间复杂度就从$O(n\log(n))$退化成了$O(n^2)$。我们刚刚讲了两个极端情况下的时间复杂度，一个是分区极其均衡，一个是分区极其不均衡。它们分别对应快排的最好情况时间复杂度和最坏情况时间复杂度。那快排的平均情况时间复杂度是多少呢？我们可以继续套用递归时间复杂度的公式进行求解。因为这边平均情况下的递推过程非常复杂，这里直接给出结论:T(n)在大部分情况下的时间复杂度都可以做到$O(n\log(n))$，只有在极端情况下，才会退化到$O(n^2)$。 解答开篇回到开篇的问题：如何用快排思想在$O(n)$内查找第K大元素？比如，4，2，5，12，3这样一组数据，第3大元素就是4，如何快速地找到它。 快排核心思想就是分治和分区，我们可以利用分区的思想，来解答开篇的问题。我们选择数组区间arr[0..n-1]的最后一个元素arr[n-1]作为pivot，对数组arr[0..n-1]原地分区，这样数组就分成了三部分，arr[0.…p-1]、arr[p]以及arr[p+1..n-1]。 如果p + 1 = K，那arr[p]就是要求解的元素；如果K &gt; p + 1，说明第K大元素出现在arr[p+1..n-1]区间，我们再按照上面的思路递归地在arr[p+1..n-1]这个区间内查找。同理，如果K &lt; p + 1，那我们就在arr[0..p-1]区间查找。 我们再来分析下这样查找的时间复杂度。 第一次分区查找，我们需要对大小为n的数组执行分区操作，需要遍历n个元素；第二次分区查找，我们只需要对大小为 $\frac{n}{2}$ 的数组执行分区操作，需要遍历$\frac{n}{2}$个元素。依次类推，分区遍历元素的个数分别为、$\frac{n}{2}$、$\frac{n}{4}$、$\frac{n}{8}$、$\frac{n}{16}$…..直到区间缩小为1。如果我们把每次分区遍历的元素个数加起来，就是：$$n + \frac{n}{2} + \frac{n}{4} + \frac{n}{8} + .. + 1$$这是一个等比数列求和，最后的和等于$2n-1$ 。所以，上述解决思路的时间复杂度就为$O(n)$。你可能会说，我有个很笨的办法，每次取数组中的最小值，将其移动到数组的最前面，然后在剩下的数组中继续找最小值，以此类推，执行K次，找到的数据不就是第K大元素了吗？不过，时间复杂度就并不是$O(n)$了，而是 $O(K \cdot n)$ 。你可能会说，时间复杂度前面的系数不是可以忽略吗？$O(K \cdot n)$ 不就等于$O(n)$吗？这个可不能这么简单地划等号。当K是比较小的常量时，比如1、2，那最好时间复杂度确实是 $O(n)$ ；但当K等于n/2或者n时，这种最坏情况下的时间复杂度就是 $O(n^2)$ 了。 小结归并排序和快速排序是两种稍微复杂的排序算法，它们用的都是分治的思想，代码都通过递归来实现，过程非常相似。理解归并排序的重点是理解递推公式和merge0合并函数。同理，理解快排的重点也是理解递推公式，还有 partition0分区函数。 归并排序算法是一种在任何情况下时间复杂度都比较稳定的排序算法，这也使它存在致命的缺点，即归并排序不是原地排序算法，空间复杂度比较高，是$O(n)$。正因为此，它也没有快排应用广泛。快速排序算法虽然最坏情况下的时间复杂度是$O(n^2)$ ，但是平均情况下时间复杂度都是$O(n\log(n))$。不仅如此，快速排序算法时间复杂度退化到$O(n^2)$的概率非常小，我们可以通过合理地选择pivot来避免这种情况。 归并排序和快速排序的区别，归并排序的处理过程是由下到上的，先处理子问题，然后再合并。而快排正好相反，它的处理过程是由上到下的，先分区，然后再处理子问题。 思考题现在你有10个接口访问日志文件，每个日志文件大小约300MB，每个文件里的日志都是按照时间戳从小到大排序的。你希望将这10个较小的日志文件，合并为1个日志文件，合并之后的日志仍然按照时间戳从小到大排列。如果处理上述排序任务的机器内存只有1GB，你有什么好的解决思路，能“快速”地将这10个日志文件合并吗？]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法-1：插入、冒泡、选择]]></title>
    <url>%2F2019%2F06%2F17%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%2Falgo-sort-1%2F</url>
    <content type="text"><![CDATA[排序算法可以说是一项基本功，也是大部分程序员学习的第一个算法，一个优秀的算法可以节省大量的资源。目前大部分编程语言都提供了排序函数，但分析理解各种排序算法的特性，结合各个领域中考虑到数据的各种限制和规范，往往能够分析推理一个符合实际的优秀算法。 排序算法太多了，我们将其按照时间复杂度分为3类，分3篇文章进行分析。 注：以下排序均以升序为例 排序算法 时间复杂度 是否基于比较 冒泡、插入、选择 $O(n^2)$ √ 快排、归并 $O(nlogn)$ √ 桶、计数、基数 $O(n)$ × 如何分析一个“排序算法”排序算法的执行效率 最好情况、最坏情况、平均情况的时间复杂度我们在分析算法时，往往需要对最好情况、最坏情况、平均情况进行区分，并且分析对应情况下的时间复杂度。 时间复杂度的系数、常数、低阶时间复杂度反应的是n极大情况下的时间增长趋势，而实际软件开发中，我们需要排序的往往只有10个、20个、100个这种数据。在小规模数据排序情况下，时间复杂度同阶的算法进行对比时，系数、常数、低阶的影响还是比较大的，往往需要进行分析。 比较次数和交换（移动）次数基于比较的排序算法，在执行过程中会涉及到两种操作：一是比较元素的大小，二是元素交换和移动。所以分析排序算法执行效率时，需要考虑元素的比较以及移动次数。 排序算法的内存消耗算法的内存消耗可以通过空间复杂度衡量。针对排序算法，有一个原地排序（Sorted in place）的概念。原地排序，即空间复杂度为$O(1)$的排序算法。本篇的冒泡、插入、选择排序皆为原地排序。 排序算法的稳定性针对排序算法，还有一个重要的指标：稳定性。指的是：待排列的序列（数组）中存在值相等的元素，而这些相等元素经过排序后，相等元素之间原有的顺序是否改变，若不变，则称排序算法稳定，若改变了，不稳定。 冒泡排序（Buddle Sort）冒泡排序只操作相邻的两个元素，每次冒泡操作都会对相邻的两个元素进行比较，根据大小关系，决定是否互换两个元素。一次冒泡操作会至少让一个元素放到正确的位置上，重复n-1次冒泡操作，就完成了n个元素的排序。 以升序为例，假设有一个整型数组a[] = {5，4，6，3，2，1}，第一次冒泡会先对a[0]和a[1]进行比较，即对5和4比较，5比4大，互换元素，此时a[] = {4,5,6,3,2,1}；紧接着再对a[1]和a[2]进行比较，即5和6比较，5比6小，不互换a不变；再对a[2]和a[3]进行比较，6比3大，互换…以此类推，第一次冒泡完成后，数组为a[] = {4,5,3,2,1,6}，其中最大的元素6已经放到了正确的位置上。我们只需要重复n-1次冒泡操作（外层循环次数n-1）即可完成排序。而第二次冒泡时，因为最后一个元素已经正确，我们无需理会，只需要比较前n-1个元素即可，同理，第k次循环只需比较前n-k个元素（内层循环次数n-k）。 代码如下（C++）： 1234567891011121314151617// 冒泡排序，a为数组，n表示数组大小void bubbleSort(int* a, int n) &#123; if (n &lt;= 1) &#123; return; &#125; // 长度为n的数组，需执行n-1次冒泡循环（0到n-2，为方便数组操作，下标从0开始） for (int i = 0; i &lt; n - 1; i++) &#123; // 第k次循环需比较前n-k个元素（k=i+1） for (int j = 0; j &lt; n - i - 1; j++) &#123; if (a[j] &gt;a[j+1]) &#123; // 交换操作 int tmp = a[j]; a[j] = a[j + 1]; a[j + 1] = tmp; &#125; &#125; &#125;&#125; 优化：当某次冒泡操作时，已经没有数据交换，说明序列已经有序，不需要继续执行后续的冒泡操作，可以设置一个标志位提前退出冒泡循环。 代码如下（C++）： 1234567891011121314151617181920212223// 冒泡排序，a为数组，n表示数组大小void bubbleSort(int* a, int n) &#123; if (n &lt;= 1) &#123; return; &#125; // 长度为n的数组，需执行n-1次冒泡循环（0到n-2，为方便数组操作，下标从0开始） for (int i = 0; i &lt; n - 1; i++) &#123; // 提前退出循环的标志位 bool flag = false; // 第k次循环需比较前n-k个元素（k=i+1） for (int j = 0; j &lt; n - i - 1; j++) &#123; if (a[j] &gt;a[j+1]) &#123; // 交换操作 int tmp = a[j]; a[j] = a[j + 1]; a[j + 1] = tmp; flag = true; // 表示存在元素交换 &#125; &#125; if (!flag) &#123; // 不存在元素交换，提前退出 break; &#125; &#125;&#125; 现在，结合排序算法的分析，有三个问题 三个问题 是原地排序吗？ 是，冒泡排序仅涉及相邻元素交换操作，只需常量级临时空间，所以空间复杂度为$O(1)$。 是稳定的排序吗？ 是，冒泡排序时交换元素改变顺序，在元素相同的情况下，可以不做交换，所以冒泡排序是稳定的排序算法。 时间复杂度是多少？ 情况 原始数据展示 时间复杂度 最好情况 {1,2,3,4,5,6} $O(n)$ 最坏情况 {6,5,4,3,2,1} $O(n^2)$ 平均情况 {6,3,2,1,4,5} $O(n^2)$ 最好情况下，需要排序的原序列已经有序，只需进行一次冒泡操作就可以结束，所以时间复杂度为：$O(n)$。 最坏情况下，需要排序的原序列是倒序，需要进行n次冒泡操作，所以时间复杂度为为：$O(n^2)$。 平均情况下，我们可以采用 逆序度 的方式进行分析。 冒泡排序包含两个操作：比较和交换，每交换一次，逆序度减一，所以逆序度表示了原序列到有序序列需要交换的次数，最好情况下逆序度为0，最坏情况下逆序度为$\frac{n \times (n - 1) }{2}$。平均情况我们可以取一个中间值$\frac{n \times (n+1) }{4}$。比较操作肯定比交换操作要多，而复杂度上限为$O(n^2)$，所以平均情况下的时间复杂度就是$O(n^2)$。 插入排序（Insertion Sort）假设已经有一个有序序列，现在需要往其中添加一个新元素，要求添加后仍然有序，该如何操作呢？只需要遍历原有的有序数组，找到新元素应该插入的位置插入即可，插入排序就是这么来的。 首先，我们将序列中的元素分成两个区间：已排序区间以及未排序区间，当然，初始状态下，已排序区间只有一个元素，即第一个元素，插入排序的思维就是取一个未排序区间的数，在已排序区间内找到合适的位置插入，并且保证已排序区间一直有序，直到未排序区间内没有元素，此时排序完成。 插入排序也包含两种操作：元素的比较和元素的交换。对于不同的查找插入点的方法（从头到尾、从尾到头），元素的比较次数是不一样的，而元素的移动次数都是相同的，等于序列的逆序度。 代码如下（C++） 1234567891011121314151617181920// 插入排序 a 表示数组，n 表示数组大小void insertionSort(int* a, int n) &#123; if (n &lt;= 1) &#123; return; &#125; // 先将a[0]看成已排序区间，所以未排序区间从a[1]开始 for (int i = 1; i &lt; n; i++) &#123; int value = a[i]; // j表示需元素需插入的位置，范围[0,i],a[i]为元素原位置，所以从a[i-1]开始比较 int j = i - 1; for (; j &gt;= 0; j--) &#123; if (a[j] &gt; value) &#123; // 若a[j]&gt;a[i],a[j]元素后移一位 a[j + 1] = a[j]; &#125; else &#123; // 若a[j]&lt;=a[i],即a[j+1]为元素需要插入位置 break; &#125; &#125; a[j + 1] = value; &#125;&#125; 还是三个问题 是原地排序吗？ 是，插入排序不需要额外的存储空间（可以将代码中value直接替换成a[i]，增加value是为了代码更容易看懂），所以空间复杂度为$O(1)$，即，插入排序是原地排序算法。 是稳定的排序吗？ 是，插入排序不需要额外的存储空间（可以将代码中value直接替换成a[i]，增加value是为了代码更容易看懂），所以空间复杂度为$O(1)$，即，插入排序是原地排序算法。 时间复杂度是多少？ 情况 原始数据 时间复杂度 最好情况 已有序 $O(n)$ 最坏情况 倒序 $O(n^2)$ 平均情况 $O(n^2)$ 最好情况下，因为采用的是从尾到头遍历有序数据，所以在第一次比较时就会跳出内层循环。因此不需要搬移任何数据，每次比较一个数据就能确定插入位置。所以最好情况下的时间复杂度为$O(n)$。 最坏情况下，序列倒序，相当于每次插入都需要移动大量元素（i个元素）。所以最坏情况的时间复杂度为$O(n^2)$。 平均情况下，因为我们在数组中插入一个元素的平均时间复杂度为$O(n)$，插入排序每次插入都相当于在数组中插入一个元素，重复了n次插入的过程，所以时间复杂度为$O(n^2)$。 选择排序（Selection Sort）选择排序的思想类似于插入排序，将序列分为已排序区间和未排序区间。但选择排序每次都会从未排序区间内寻找最小的元素，放到已排序区间的末尾（交换操作）。所以重复n-1次操作后，序列即有序。 代码如下： 123456789101112131415161718192021// 选择排序 a 表示数组，n 表示数组大小void selectionSort(int* a, int n) &#123; if (n &lt;= 1) &#123; return; &#125; for (int i = 0; i &lt; n - 1; i++) &#123; // 先默认第i个元素为当前最小元素 int minPos = i; int minValue = a[i]; // 因为默认最小为a[i],所以从a[i+1]开始比较寻找最小元素 int j = i + 1; for (; j &lt; n; j++) &#123; if (a[j] &lt; minValue) &#123; // 若a[j]元素比当前最小元素小，则标记a[j]为当前最小元素 minValue = a[j]; minPos = j; &#125; &#125; a[minPos] = a[i]; a[i] = minValue; &#125;&#125; 依旧三个问题 是原地排序吗？ 是，选择排序空间复杂度为 O(1)，是一种原地排序算法。 是稳定的排序吗？ 否，选择排序每次都要找剩余未排序元素中的最小值，并和前面的元素交换，这样破坏了稳定性。 举例：{5,2,3,4,5,1} 第一次操作会将第一个元素5和最后一个元素1交换，这样，两个5的顺序就变了，所以就不稳定。 时间复杂度是多少？ 情况 时间复杂度 最好、最坏、平均情况 $O(n^2)$ 所有情况下，选择排序的时间复杂度均为$O(n^2)$，因为选择排序在任何情况下，遍历的次数都是固定的，第一次循环对n-1个元素执行比较操作；第k次循环，对n-k个元素执行比较操作，总共需要比较(n-1) + (n-2) + ... + 2，即$\frac{(n - 2) \times (n + 1) }{2}$次，所以选择排序时间复杂度恒为$O(n^2)$。 解答开篇回到开篇的问题：冒泡排序和插入排序的时间复杂度都是$O(n^2)$，都是原地排序算法，都稳定，为什么插入排序比冒泡排序更受欢迎呢？ 前面我们分析到：冒泡排序不管怎么买优化，元素交换的次数都是固定值，等于原始序列的逆序度；同样的，插入排序不管怎么优化，元素移动的次数也是原始序列的逆序度。 但是，从代码实现上来看，冒泡排序的元素交换要比插入排序的元素移动复杂，冒泡排序需要3个赋值操作，而插入排序只需要一个。 代码如下： 1234567891011121314冒泡排序中数据的交换操作：if (a[j] &gt; a[j+1]) &#123; // 交换 int tmp = a[j]; a[j] = a[j+1]; a[j+1] = tmp; flag = true;&#125;插入排序中数据的移动操作：if (a[j] &gt; value) &#123; a[j+1] = a[j]; // 数据移动&#125; else &#123; break;&#125; 因此，虽然两者的时间复杂度一致，但如果追求极致的性能优化，肯定首选插入排序。而且，插入排序的算法思想有很大的优化空间，比如希尔排序。 小结分析排序算法三个方面 执行效率、内存消耗、稳定性 排序算法总结 排序算法 是否原地排序 是否稳定 最好 最坏 平均 冒泡排序 是 是 $O(n)$ $O(n^2)$ $O(n^2)$ 插入排序 是 是 $O(n)$ $O(n^2)$ $O(n^2)$ 选择排序 是 否 $O(n^2)$ $O(n^2)$ $O(n^2)$ 冒泡排序、选择排序实际开发应用并不多，但插入排序还是很有用的，有些编程语言的排序函数的实现原理就用到了插入排序算法。 思考题这三种排序算法数据如果存储在链表中，排序算法还能工作吗，如果能，那时间复杂度、空间复杂度又是多少？]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序算法</tag>
      </tags>
  </entry>
</search>
