<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[大华研发技术支持笔试回顾]]></title>
    <url>%2F2019%2F12%2F25%2F%E5%AE%89%E9%98%B2%E5%9F%BA%E7%A1%80%2Fdahua-interview-2019-12-25%2F</url>
    <content type="text"><![CDATA[笔试分为三部分：网络常见问题处理；SQL基础；操作系统基础 都是简答题，网络和Linux开放性比较强，应该主要看答题逻辑；操作系统基础以Linux命令居多，没想到会笔试这样的内容，之前命令都是各种补全或者help，没有刻意去记，吃大亏了，以下是部分题目 网络PC机A可以ping通PC机B的IP，但PC机B不能ping通PC机A的IP，如何排查问题?目前能想到的就三个原因： 防火墙拦截了ICMP报文 取消您两台电脑上的防火墙设置（实际项目上该情况最多） APR病毒 APR病毒导致PC机A ping 的B不一定是真正的B，PC机B ping 的A也不一定是真正的A；通过arp -a 与ipconfig /all 来判断A确实是A，B确实是B 网络波动 判断网络里是否有大量的广播包在影响网络通信 最后尝试：PC机B tracert PC机IP，判断哪里出了问题 画出某个网络拓扑图（家庭，学校，某个项目的都行）这个网上找吧。。。 SQL前面都是基本的增删改查，较简单，最后一题如下： mysql备份还原的方式有哪些？命令方式： 备份： mysqldump备份单个数据库： 1mysqldump -u user -h host -p password dbname&gt;filename.sql mysqldump备份数据库中的指定表 1mysqldump -u user -h host -p password dbname[tbname,[tbname…]]&gt;filename.sql mysqldump备份多个数据库 1mysqldump -u user -h host -p password --databases[dbname,[dbname…]]&gt;filename.sql 备份系统中所有的数据库 1mysqldump -u user -h host -p password --all-databases&gt;filename.sql 还原： 1mysql -u username -p [dbname] &lt; filename.sql SQLyog 工具 可以用sqlyog等工具备份还原 操作系统Windows系统和Linux系统查看端口是否被占用用什么命令？Windows： 1234#查看端口被占用情况netstat -aon|findstr "80"#查看相关进程tasklist|findstr "80" Linux： 123netstat -nlp | grep 8080#或者lsof -i:8080 Linux疑似中毒，如何排查，写出命令？ top查看什么进程占用了资源 用lsof -p &lt;PID&gt;,查看疑似病毒进程 w查看当前都有谁在登录 history回顾命令历史 ps检查所有的系统进程 netstat查看异常的网络连接 cat /etc/rc.local查看是否有异常内容 tcpdump抓包查看是否有报文发送到异常IP 暂时想到就这些了。。。]]></content>
      <categories>
        <category>安防基础</category>
      </categories>
      <tags>
        <tag>安防基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GB/T28181协议业务流程基础]]></title>
    <url>%2F2019%2F12%2F12%2F%E5%AE%89%E9%98%B2%E5%9F%BA%E7%A1%80%2FGB28181-base%2F</url>
    <content type="text"><![CDATA[国标介绍GB/T28181规定了公共安全视频监控联网系统）的互联结构，传输、交换、控制的基本要求和安全性要求，以及控制、传输流程和协议接口等技术要求,适用于公共安全视频监控联网系统的方案设计、系统检测、验收以及与之相关的设备研发、生产等 编码规则：国标编码规则分为编码规则A和编码规则B。除特殊地区外，大部分地区采用的均是编码规则A，以下主要介绍编码规则A 编码规则A由中心编码（8位）、行业编码（2位）、类型编码（3位）和序号（7位）四个码段共20位十进制数字字符构成，即系统编码 =中心编码 + 行业编码 + 类型编码 + 序号 码段 码位 含义 取值说明 中心编码 1、2 省级编号 由监控中心所在地的行政区划代码确定， 符合GB/T 2260-2007的要求 3、4 市级编号 5、6 区级编号 7、8 基层接入单位编号 行业编码 9、10 行业编码 类型编码 11、12、13 111～130 表示类型为前端主设备 118-网络视频录像机（NVR）编码 131～199表示类型为前端外围设备 131-摄像机编码132-网络摄像机（IPC）编码 200～299表示类型为平台设备 200-中心信令控制服务器编码 网络标识 14 网络标识编码 0、1、2、3、4为监控报警专网，5为公安信息网，6为政务网，7为Internet网，8为社会资源接入网，9预留 序号 15～20 设备、用户序号 SIPSIP（Session Initiation Protocol，会话初始协议）是由IETF（Internet Engineering Task Force，因特网工程任务组）制定的多媒体通信协议 它是一个基于文本的应用层控制协议，用于创建、修改和释放一个或多个参与者的会话。其状态码类似于HTTP协议 国标的信令主要采用了SIP协议：其中注册设备采用REGISTER；实况采用INVITE；回放控制采用INFO；设备信息查询通知采用MESSAGE，订阅事件采用SUBSCRIBE，事件通知采用NOTIFY 主要业务流程注册和保活设备或系统进入联网系统时向SIP服务器进行注册登记的工作模式。 如果设备或系统注册不成功，宜延迟一定的随机时间后重新注册 流程如下： SIP代理向SIP服务器发送REGISTER请求 SIP服务器向SIP代理发送响应401（未鉴权），并在响应的消息头WWW_Authenticate字段中给出适合SIP代理的认证体制和参数规范 SIP代理重新向SIP服务器发送REGISTER请求，在请求的Authorization字段给出鉴权认证信息； SIP服务器对请求进行验证，如果检查SIP代理身份合法，向SIP代理发送成功响应200 OK，如果身份不合法则发送拒绝服务应答 SIP代理默认每30秒发送发送一次保活报文，保活信息于MESSAGE BODY描述，超过3次未保活成功，则SIP服务器会认为SIP代理已离线 REGISTER中Expires字段描述了注册过期时间，再过期之前，SIP代理会刷新注册（CallID会一致） 实况实时视音频点播采用SIP协议（IETF RFC 3261）中的INVITE方法实现会话连接，采用RTP/RTCP协议（IETF RFC 3550）实现媒体传输 流程描述如下： 媒体流接收者向SIP服务器发送Invite消息，消息头域中携带Subject字段，表明点播的视频源ID、发送方媒体流序列号、媒体流接收者ID、接收端媒体流序列号等参数，SDP（为区别，图中为SDP1）消息体中s字段为“Play”代表实时点播 SIP服务器收到Invite请求后，通过三方呼叫控制建立媒体服务器和媒体流发送者之间的媒体连接。向媒体服务器发送Invite消息，此消息不携带SDP消息体； 媒体服务器收到SIP服务器的Invite请求后，回复200 OK响应，携带SDP（图中为SDP2）消息体，消息体中描述了媒体服务器接收媒体流的IP、端口、媒体格式等内容； SIP服务器收到媒体服务器返回的200 OK响应后，向媒体流发送者发送Invite请求，请求中携带消息3中媒体服务器回复的200 OK响应消息体，s字段为“Play”代表实时点播 媒体流发送者收到SIP服务器的Invite请求后，回复200 OK响应，携带SDP（图中为SDP3）消息体，消息体中描述了媒体流发送者发送媒体流的IP、端口、媒体格式、SSRC字段等内容； SIP服务器收到媒体流发送者返回的200 OK响应后，向媒体服务器发送ACK请求，请求中携带消息5中媒体流发送者回复的200 OK响应消息体，完成与媒体服务器的Invite会话建立过程 SIP服务器收到媒体流发送者返回的200 OK响应后，向媒体流发送者发送ACK请求，请求中不携带消息体，完成与媒体流发送者的Invite会话建立过程 完成三方呼叫控制后，SIP服务器建立了媒体流接收者和媒体服务器之间的媒体连接。在消息1中增加SSRC值，转发给媒体服务器 媒体服务器收到Invite请求，回复200 OK响应，携带SDP（图中为SDP4）消息体，消息体中描述了媒体服务器发送媒体流的IP、端口、媒体格式、SSRC值等内容 SIP服务器将消息9转发给媒体流接收者 媒体流接收者收到200 OK响应后，回复ACK消息，完成与SIP服务器的Invite会话建立过程 SIP服务器将消息11转发给媒体服务器，完成与媒体服务器的Invite会话建立过程 媒体流接收者向SIP服务器发送BYE消息，断开消息1、10、11建立的同媒体流接收者的Invite会话； SIP服务器收到BYE消息后回复200 OK响应，会话断开； SIP服务器收到BYE消息后向媒体服务器发送BYE消息，断开消息8、9、12建立的同媒体服务器的Invite会话； 媒体服务器收到BYE消息后回复200 OK响应，会话断开 SIP服务器向媒体服务器发送BYE消息，断开消息2、3、6建立的同媒体服务器的Invite会话； 媒体服务器收到BYE消息后回复200 OK响应，会话断开 SIP服务器向媒体流发送者发送BYE消息，断开消息4、5、7建立的同媒体流发送者的Invite会话； 媒体流发送者收到BYE消息后回复200 OK响应，会话断开 录像检索与回放检索 流程大致如下： 录像检索方向录像拥有方发送目录查询请求Message消息，消息体中包含视音频文件检索条件，包括查询的设备编码，查询时间段等，其中，消息体的CmdType字段为RecordInfo代表是录像检索 录像拥有方向录像检索方发送200 OK，无消息体； 录像拥有方以Message向录像检索方发送查询结果，消息体中含文件目录，当一条Message消息无法传送完所有查询结果时，采用多条消息传送； 录像检索方向录像拥有方发送200 OK，无消息体。 回放采用SIP协议中的INVITE方法实现会话连接，采用SIP扩展协议INFO方法的消息体携带视音频回放控制命令，采用RTP/RTCP协议实现媒体传输。媒体回放控制命令引用MANSRTSP协议中的PLAY，PAUSE，TEARDOWN 的请求消息和应答消息 回放总体可以分为三个部分，分别是会话连接，回放控制和资源释放，其中会话连接和资源释放与实况流程基本一致，消息体中的字段会区别回放还是实况 会话建立 回放控制 资源释放 流程描述如下： （会话建立）媒体流接收者向SIP服务器发送Invite消息，消息头域中携带Subject字段，表明点播的视频源ID、发送方媒体流序列号、媒体流接收者ID、接收端媒体流序列号标识等参数，SDP（图中为SDP1）消息体中s字段为“Playback”代表历史回放，u字段代表回放通道ID和回放类型，t字段代表回放时间段； SIP服务器收到Invite请求后，通过三方呼叫控制建立媒体服务器和媒体流发送者之间的媒体连接。向媒体服务器发送Invite消息，此消息不携带SDP消息体； 媒体服务器收到SIP服务器的Invite请求后，回复200 OK响应，携带SDP消息体，消息体中描述了媒体服务器接收媒体流的IP、端口、媒体格式等内容； SIP服务器收到媒体服务器返回的200 OK响应后，向媒体流发送者发送Invite请求，请求中携带消息3中媒体服务器回复的200 OK响应消息体，s字段为“Playback”代表历史回放，u字段代表回放通道ID和回放类型，t字段代表回放时间段，增加y字段描述SSRC值，f字段描述媒体参数； 媒体流发送者收到SIP服务器的Invite请求后，回复200 OK响应，携带SDP消息体，消息体中描述了媒体流发送者发送媒体流的IP、端口、媒体格式、SSRC字段等内容； SIP服务器收到媒体流发送者返回的200 OK响应后，向媒体服务器发送ACK请求，请求中携带消息5中媒体流发送者回复的200 OK响应消息体，完成与媒体服务器的Invite会话建立过程； SIP服务器收到媒体流发送者返回的200 OK响应后，向媒体流发送者发送ACK请求，请求中不携带消息体，完成与媒体流发送者的Invite会话建立过程； 完成三方呼叫控制后，SIP服务器建立媒体流接收者和媒体服务器之间的媒体连接。在消息1中增加SSRC值，转发给媒体服务器； 媒体服务器收到Invite请求，回复200 OK响应，携带SDP消息体，消息体中描述了媒体服务器发送媒体流的IP、端口、媒体格式、SSRC值等内容； SIP服务器将消息9转发给媒体流接收者； 媒体流接收者收到200 OK响应后，回复ACK消息，完成与SIP服务器的Invite会话建立过程； SIP服务器将消息11转发给媒体服务器，完成与媒体服务器的Invite会话建立过程； （控制）在回放过程中，媒体流接收者通过向SIP服务器发送会话内Info消息进行回放控制，包括视频的暂停、播放、快放、慢放、随机拖放播放等操作 SIP服务器收到消息13后转发给媒体流发送者 媒体流发送者收到消息14后回复200 OK响应； SIP服务器将消息15转发给媒体流接收者 媒体流发送者在文件回放结束后发送会话内Message消息，通知SIP服务器回放已结束 SIP服务器收到消息17后转发给媒体流接收者 媒体流接收者收到消息18后回复200 OK响应，进行链路断开过程； SIP服务器将消息19转发给媒体流发送者 （释放会话）媒体流接收者向SIP服务器发送BYE消息，断开消息1、10、11建立的同媒体流接收者的Invite会话 SIP服务器收到BYE消息后回复200 OK响应，会话断开 IP服务器收到BYE消息后向媒体服务器发送BYE消息，断开消息8、9、12建立的同媒体服务器的Invite会话 媒体服务器收到BYE消息后回复200 OK响应，会话断开 SIP服务器向媒体服务器发送BYE消息，断开消息2、3、6建立的同媒体服务器的Invite会话； 媒体服务器收到BYE消息后回复200 OK响应，会话断开 SIP服务器向媒体流发送者发送BYE消息，断开消息4、5、7建立的同媒体流发送者的Invite会话； 媒体流发送者收到BYE消息后回复200 OK响应，会话断开 设备信息查询设备信息查询包括目录查询、前端设备信息查询、前端设备状态查询、设备配置查询、预置位查询等，查询的范围包括本地SIP域或者跨SIP域。网络设备信息查询命令和响应均采用方法MESSAGE实现 源设备包括SIP客户端、网关或联网系统，目标设备包括SIP设备、网关或联网系统 源设备向SIP服务器发送设备查询命令，设备查询命令采用MESSAGE方法携带 SIP服务器收到命令后返回200 OK SIP服务器向目标设备转发设备查询命令，设备查询命令采用MESSAGE方法携带 目标设备收到命令后返回200 OK 目标设备向SIP服务器发送设备查询响应命令，设备查询响应命令采用MESSAGE方法携带 SIP服务器收到命令后返回200 OK SIP服务器向源设备转发查询响应命令，设备查询响应命令采用MESSAGE方法携带 目标设备收到命令后返回200 OK 订阅与通知订阅事件订阅使用SUBSCRIBE方法，事件源接受事件订阅时，事件源向事件观察者发送确认消息。 订阅流程如下： 事件观察者向事件源发送SUBSCRIBE请求，请求消息体携带订阅参数 事件源应将订阅成功与否的响应消息返回给该事件观察者 通知 在订阅事件触发后事件源向事件观察者发送NOTIFY消息，NOTIFY的消息体应携带通知参数； 事件源应将通知的响应消息返回给该事件观察者 总结常见问题以设备注册问题、实况问题、回放问题为主，遇到有争议的问题时，最好对照下国标文档。]]></content>
      <categories>
        <category>安防基础</category>
      </categories>
      <tags>
        <tag>安防基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[独立冗余磁盘阵列-RAID基础]]></title>
    <url>%2F2019%2F12%2F12%2F%E5%AE%89%E9%98%B2%E5%9F%BA%E7%A1%80%2FRAID-base%2F</url>
    <content type="text"><![CDATA[太长不看系列： RAID级别 有无容错 硬盘数 可用容量 允许故障硬盘数 使用场景 RAID0 无 $N\geq 2$ 100% 0 对性能要求高，但对数据安全性和可靠性要求低的场合，如临时数据缓存空间等 RAID1 有 $N\geq 2$且N为2的倍数 50% $\frac{N}{2}$ 对性能要求低，但对数据安全性和可靠性要求高的场合 RAID3 有 $N\geq 3$ $\frac{N-1}{N}$ 1 适用大容量数据的顺序访问应用，使用较少，被RAID5替代 RAID5 有 $N\geq 3$ $\frac{N-1}{N}$ 1 满足大部分的存储应用需求，数据中心数据存储、安防行业的音视频存储最常用的RAID级别 RAID6 有 $N\geq 4$ $\frac{N-2}{N}$ 2 对数据安全等级要求较高的场合，替代 RAID10 方案的经济性选择 RAID10 有 $N\geq 4$ 50% $\frac{N}{2}$ 对性能要求高，且对数据安全性和可靠性要求高的场合 RAID50 有 $N\geq 6$ $\frac{N-RAID5的组数}{N}$ 每组RAID5允许一块硬盘故障 对数据安全等级要求较高的场合，替代 RAID10 方案的经济性选择 RAID介绍后续增加。。。 RAID作用RAID相关技术RAID级别总结]]></content>
      <categories>
        <category>安防基础</category>
      </categories>
      <tags>
        <tag>安防基础</tag>
        <tag>计算机基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机系统中的时间]]></title>
    <url>%2F2019%2F12%2F06%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%2Fsystem-time%2F</url>
    <content type="text"><![CDATA[常见的时间缩写太长不看系列：UTC = GMT , CST = UTC + 时区 ，CST（国内） = 北京时间 UTC(英：Coordinated Universal Time ，法：Temps Universel Coordonné)：协调世界时 英国格林威治皇家天文台所在地的标准时间，UTC基于国际原子时间，是全世界统一的世界标准时间。也是表示地球自转速率的一种形式，需要不规则地加入闰秒。 GMT(Greenwich Mean Tim)：格林威治标准时间 一般认为UTC和GMT是相等的，但是会存在0.9秒以内的误差，这是由于地球不规则自转引起的。 CST(Central Standard Time)：中央标准时间 四大时区的时间，CST = UTC + 时区。东正西负。比如北京时间在东八区就是 UTC+(+0800)，在国内，一般认为CST就代表北京时间即可。 1234Central Standard Time (USA) UT-6:00（美国cst时间：零区时减6个小时）Central Standard Time (Australia) UT+9:30（澳大利亚cst：加9个半小时）China Standard Time UT+8:00（中国cst:加8个小时）Cuba Standard Time UT-4:00 （古巴cst:减4个小时） DST(Daylight Saving Time)，夏日节约时间，即夏令时 是指夏天太阳升起比较早，将时钟拨快一个小时来提早日光的使用。欧美主要国家都引用了这个做法。如果在夏令时时区内 DST=UTC+时区+1，中国已经废止。 CET(Central European Time)，欧洲中部时间 冬季时间为UTC+1，夏季欧洲夏令时为UTC+1+1。 Unix时间戳（Unix epoch, Unix time, POSIX time 或 Unix timestam） Unix时间戳是从1970年1月1日（UTC/GMT的午夜）开始所经过的秒数，不考虑闰秒。 计算机系统时钟 Hardware clock 硬件时钟 即BIOS时间，就是我们进行CMOS设置时看到的时间，计算机硬件有个电池供电的实时时钟(Real-time Clock, RTC)也叫(CMOS时钟，BIOS时间，三者同一)。使用的时间标准由操作系统设置。硬件时钟默认使用UTC时间，建议使用UTC全球时间标准，因为硬件时钟不能保存时区和夏令时调整，修改后就无法从硬件时钟中读取出准确标准时间，因此不建议修改为其他时间格式 Software clock 软件时钟 计算机系统运行时的时钟(Syetem clock)。 计算机系统时钟运行过程 关机状态：硬件时钟有电池供电，始终在主板上默默运行着。通电进入BIOS: 主板BIOS系统界面能够看到并设置硬件时间。电脑开机： 开机引导时：使用硬件时钟设置系统时钟。Arch Linux系统开机时间会更新到/etc/adjtime 系统运行时：系统正常运行后，由系统内核独自运行系统时钟。 时钟同步服务：需要联网，大部分操作系统都带有联网后能够和网络上的NTP服务器同步系统时钟，修正系统时间的准确性 系统关机时：会使用系统时钟设置硬件时钟，更新硬件时钟。 注：服务器系统开机后会连续运行数月，甚至数年。硬件时间与软件时间会出现差异，一般以系统时间为准 CentOS下时钟查看与维护*注：以下命令运行于系统版本：CentOS-6.10-x86_64 系统时钟查看系统时间1234# dateTue Jan 21 01:54:17 CST 2020# date -RTue, 21 Jan 2020 01:54:27 +0800 *注：+0800表示东八区（北京时间） 设置系统时间设置日期 123456# date -s 20200119Sun Jan 19 00:00:00 CST 2020# date -s 2020-01-20Mon Jan 20 00:00:00 CST 2020# date -s 2020/01/21Tue Jan 21 00:00:00 CST 2020 设置时间 12# date -s 01:40:00Tue Jan 21 01:40:00 CST 2020 设置日期和时间 12[root@Neil ~]# date -s "20080808 15:00:00"Fri Aug 8 15:00:00 CST 2008 更多时间显示方式或参数设置，请使用date --help查看 时区设置所有时区的信息存在/usr/share/zoneinfo/下面，本机的时区信息存在/etc/localtime，可以用复制（cp）或者创建链接（ln）的方式设置时区，以下以设置亚洲上海时区为例，其他时区形式可参考/usr/share/zoneinfo/路径或tzselect命令 123cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 硬件时钟hwclock可以打印/设定硬件时钟，cat /proc/driver/rtc可以查看RTC存储的时间 读硬件时钟 12# hwclockSun 08 Dec 2019 12:06:14 AM CST -0.954251 seconds 查看开机引导时更新的系统时刻 1234# cat /etc/adjtime0.000000 1575721137 0.0000001575721137UTC 1575721137 表示最近一次开机引导时，硬件时间与1970-01-01 00:00:00间隔的秒数，UTC表示硬件时间以UTC存储 设置硬件时钟 123# hwclock --set --date="20080808 14:55"# hwclockFri 08 Aug 2008 02:55:07 PM CST -0.876395 seconds 硬件时钟和系统时钟之间的同步硬件时钟与系统时钟同步将系统时间更新到硬件时钟，使用hwclock --systohc或者hwclock –w 1234567# dateFri Aug 8 14:57:28 CST 2008# hwclockFri 08 Aug 2008 12:00:21 AM CST -0.548385 seconds# hwclock -w# hwclockFri 08 Aug 2008 02:57:59 PM CST -0.469971 seconds 系统时钟与硬件时钟同步将硬件时间更新到系统时间，使用hwclock --hctosys或者hwclock –s 1234567# hwclockFri 08 Aug 2008 03:10:05 PM CST -0.157034 seconds# dateFri Aug 8 15:17:08 CST 2008# hwclock --hctosys# dateFri Aug 8 15:17:28 CST 2008 关于hwclock与硬件时钟(RTC)RTC查看硬件时钟cat /proc/driver/rtc: 1234567891011121314# cat /proc/driver/rtcrtc_time : 07:21:41rtc_date : 2008-08-08alrm_time : 00:00:00alrm_date : ****-**-**alarm_IRQ : noalrm_pending : no24hr : yesperiodic_IRQ : noupdate_IRQ : noHPET_emulated : yesDST_enable : noperiodic_freq : 1024batt_status : okay 这里的时间是“真正“的硬件时间，看下此时RTC与hwclock和hwclock --localtime的区别: 1234567891011121314151617181920# cat /proc/driver/rtcrtc_time : 07:21:41rtc_date : 2008-08-08alrm_time : 00:00:00alrm_date : ****-**-**alarm_IRQ : noalrm_pending : no24hr : yesperiodic_IRQ : noupdate_IRQ : noHPET_emulated : yesDST_enable : noperiodic_freq : 1024batt_status : okay[root@Neil ~]# hwclockFri 08 Aug 2008 03:21:49 PM CST -0.344394 seconds[root@Neil ~]# hwclock --localtimeFri 08 Aug 2008 07:22:00 AM CST -0.813282 seconds 可见hwclock --localtime和hwclock --utc的作用： 12hwclock --localtime #硬件被设定的时间hwclock --utc #显示的是当硬件时间为utc时，的真“本地时间” 注：当硬件时间存储为LOCAL时，hwclock --utc无意义 分析hwclock通过strace我们可以跟踪hwclock执行时打开的文件，分析hwclock。先安装strace: 1# yum -y install strace 追踪hwclock -r（同hwclock）: 12345678910111213141516171819# strace -e trace=open hwclock -r open("/etc/ld.so.cache", O_RDONLY) = 3open("/lib64/libaudit.so.1", O_RDONLY) = 3open("/lib64/libc.so.6", O_RDONLY) = 3open("/usr/lib/locale/locale-archive", O_RDONLY) = 4open("/dev/rtc", O_RDONLY) = 4open("/etc/adjtime", O_RDONLY) = 5open("/usr/share/zoneinfo/Universal", O_RDONLY) = 5open("/etc/localtime", O_RDONLY) = 5open("/usr/share/locale/locale.alias", O_RDONLY|O_CLOEXEC) = 5open("/usr/share/locale/en_US.UTF-8/LC_MESSAGES/util-linux-ng.mo", O_RDONLY) = -1 ENOENT (No such file or directory)open("/usr/share/locale/en_US.utf8/LC_MESSAGES/util-linux-ng.mo", O_RDONLY) = -1 ENOENT (No such file or directory)open("/usr/share/locale/en_US/LC_MESSAGES/util-linux-ng.mo", O_RDONLY) = -1 ENOENT (No such file or directory)open("/usr/share/locale/en.UTF-8/LC_MESSAGES/util-linux-ng.mo", O_RDONLY) = -1 ENOENT (No such file or directory)open("/usr/share/locale/en.utf8/LC_MESSAGES/util-linux-ng.mo", O_RDONLY) = -1 ENOENT (No such file or directory)open("/usr/share/locale/en/LC_MESSAGES/util-linux-ng.mo", O_RDONLY) = -1 ENOENT (No such file or directory)Sun 08 Dec 2019 10:16:29 PM CST -0.565908 seconds+++ exited with 0 +++ 可以看到： hwclock首先打开了/dev/rtc,读取硬件时钟； 打开/etc/adjtime文件，通过先前的记录来估算硬件时钟的偏差，读取并用来校正目前的时间，读取硬件时间标准（UTC或者LOCAL）； 打开/etc/localtime时区文件，若硬件时间为UTC，则将硬件时间转换为当前时区对映的时间。 更改硬件时间标准更改硬件时间标准为本地时间，不建议（LOCAL）: 12345# hwclock --systohc --localtime# cat /etc/adjtime0.000000 1575742061 0.0000001575742061LOCAL 更改硬件时间标准为UTC: 12345# hwclock --systohc --utc# cat /etc/adjtime0.000000 1575742277 0.0000001575742277UTC 其他时间操作查看最近一次开机时刻who -b： 12# who -b system boot 2019-12-08 23:11 查看系统连续运行时间uptime 12# uptime 15:55:06 up 2:29, 1 user, load average: 0.00, 0.00, 0.00 连续运行秒数cat /proc/uptime 12cat /proc/uptime8996.88 8968.96 CentOS 7的timedatectl*注：以下命令运行于系统版本：CentOS-7-x86_64-1908 关于timedatectl太长不看系列：一个比date更好用的命令 （官文翻译）timedatectl可用于查询和更改系统时钟及其设置，以及启用或禁用时间同步服务。使用systemd初始化已装载（但未引导）系统映像的系统时区。使用timedatectl可用于显示时间同步服务的当前状态 使用timedatectl查询系统时间/查看当前设置 123456789# timedatectl Local time: Mon 2019-12-09 02:03:45 CST Universal time: Sun 2019-12-08 18:03:45 UTC RTC time: Sun 2019-12-08 18:03:45 Time zone: Asia/Shanghai (CST, +0800) NTP enabled: n/aNTP synchronized: no RTC in local TZ: no DST active: n/a Local time：本地时间（系统时间） Universal time：全球时间 RTC time：硬件时间 Time zone：时区 NTP enabled：时间同步 NTP synchronized：NTP网络同步服务 RTC in local TZ：硬件时钟时间标准 DST active：夏令时 由上可以看到大部分常用的时间设置，值得注意的时，因为本机硬件时间为UTC标准，所以RTC时间（RTC time）与全球时间（Universal time）一致，与本地时间（Local time，东八区）相差8小时；如果硬件时间设置为LOCAL，则此处RTC时间与本地时间会相近（系统运行长时间后，硬件时间与系统时间不一定会相等；通常以系统时间为准） 设置系统时间 12# timedatectl set-time "2019-12-30 00:01:02"# timedatectl set-time "01:02:03" 列出所有时区 1# timedatectl list-timezones 巧用grep过滤下，timedatectl list-timezones | grep Asia列出所有亚洲时区 设置时区 1# timedatectl set-timezone Asia/Shanghai 更改硬件时间标准 12# timedatectl set-local-rtc 1# timedatectl set-local-rtc 0 0表示使用UTC作为硬件时间标准； 1表示使用本地时间作为硬件时间标准（不建议），执意使用，查询时间时（timedatectl）会出现警告： 123456Warning: The system is configured to read the RTC time in the local time zone. This mode can not be fully supported. It will create various problems with time zone changes and daylight saving time adjustments. The RTC time is never updated, it relies on external facilities to maintain it. If at all possible, use RTC in UTC by calling 'timedatectl set-local-rtc 0'. 是否开启NTP服务器同步** 12# timedatectl set-ntp yes# timedatectl set-ntp no 由于时间同步服务比较复杂，决定另开一篇介绍。]]></content>
      <categories>
        <category>计算机基础</category>
      </categories>
      <tags>
        <tag>计算机基础</tag>
        <tag>Linux基础</tag>
        <tag>时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode-11：盛最多水的容器]]></title>
    <url>%2F2019%2F07%2F29%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%2FLeetCode-11%2F</url>
    <content type="text"><![CDATA[示例: 12输入: [1,8,6,2,5,4,8,3,7]输出: 49 分析如题意，垂直的两条线段将会与坐标轴构成一个矩形区域，较短线段的长度将会作为矩形区域的宽度，两线间距将会作为矩形区域的长度，而我们必须最大化该矩形区域的面积。 矩阵的面积与两个因素有关： 矩阵的长度：两条垂直线的距离。 矩阵的宽度：两条垂直线其中较短一条的长度因此。 要矩阵面积最大化，两条垂直线的距离越远越好，两条垂直线的最短长度也要越长越好。矩形面积可以表示为：$S_{ij} = (i - j) \times min( a[i] , a[j] ) $，其中$(0\leq j&lt;i\leq n-1)$，$n$为数组长度。 解决方案方法一：暴力法算法这是最容易想到的方法，考虑每对可能出现的线段组合，使用变量maxarea来持续存储到目前为止所获得的最大面积。代码如下（C++，LeetCode运行直接超时）： 12345678910111213141516int maxArea_bruteForce(vector&lt;int&gt;&amp; height) &#123; int maxarea = 0; // 两层循环，外层循环遍历所有线段，内层遍历每条线段与在其之前线段组成的所有可能性，找到最大值 for (int i = 1; i &lt; height.size(); i++) &#123; for (int j = 0; j &lt; i; j++) &#123; int capcity = height.at(i) &lt; height.at(j) ? (i - j) * height.at(i) : (i - j) * height.at(j); if (maxarea &lt; capcity) &#123; maxarea = capcity; &#125; &#125; &#125; return maxarea;&#125; Java代码如下(执行用时：402 ms)： 1234567public int maxArea_bruteForce(int[] height) &#123; int maxarea = 0; for (int i = 0; i &lt; height.length; i++) for (int j = i + 1; j &lt; height.length; j++) maxarea = Math.max(maxarea, Math.min(height[i], height[j]) * (j - i)); return maxarea;&#125; 复杂度分析 时间复杂度：$O(n^2)$，计算所有种$O(\frac{n \times (n-1)}{2})$高度组合的面积。 空间复杂度：$O(1)$，使用恒定的额外空间。 方法二：双指针法算法这种方法背后的思路在于，两线段之间形成的区域总是会受到其中较短那条高度的限制。此外，两线段距离越远，宽度越大，得到的面积就越大。我们在由线段长度构成的数组中使用两个指针，一个放在开始，一个置于末尾。此外，我们会使用变量maxarea来持续存储到目前为止所获得的最大面积。$p$ 指针由开始向末尾移动，$q$ 指针由末尾向开始移动，当 $p = q$ 时，停止遍历。在每一步中，我们会找出指针所指向的两条线段形成的区域，更新maxarea，并将指向较短线段的指针向较长线段那端移动一步。 为什么是指向较短线段的指针向较长线段那端移动一步？最初我们考虑由最外围两条线段构成的区域。现在，为了使面积最大化，我们需要考虑更长的两条线段之间的区域。如果我们试图将指向较长线段的指针向内侧移动，矩形区域的面积将受限于较短的线段而不会获得任何增加。但是，在同样的条件下，移动指向较短线段的指针尽管造成了矩形宽度的减小，但却可能会有助于面积的增大。因为移动较短线段的指针会得到一条相对较长的线段，这可以克服由宽度减小而引起的面积减小。 如果两个指针指向的值相等，该移动哪一个呢？ 我们假设 $a[1]$ 和 $a[8]$ 高度是相等的。如果它们之间只有1个元素比它俩高或者没有比它俩高的，那么最大面积就一定选取是 $i = 1$ 和 $j = 8$ 了，所以 $i$ 接着变大，或者 $j$ 接着减小都是无所谓的，因为答案已经确定了。 假设$a[1]$和$a[8]$之间有2个元素比它俩高，假设是 $a[4]$ 和 $a[6]$ 两个元素。$i = 1$会变到 $i = 2$、$i = 3$，最终为 $i = 4$； $j = 8$ 会变到 $j = 7 $， $j = 6$，而在这个过程中产生的面积一定不会比 $i = 1$ 和 $j = 8$ 产生的面积大，因为变换过程中的高度都比$a[1]$和$a[8]$低。所以是先变 $i = 1$ 还是先变 $j = 8$ 是无所谓的，无非是谁先到达更长的柱子而已。 代码如下（C++，执行时间：24 ms）： 12345678910111213141516171819202122232425262728293031323334int maxArea_twoPointer(vector&lt;int&gt;&amp; height) &#123; int p = 0, q = height.size() - 1; // 前指针p，后指针q int maxarea = 0; // 变量area存储每次指针推进（p++或q--）后的矩形区域大小 int area = 0; // 变量maxarea存储当前出现最大的矩形区域 int width = q - p; // 变量width用于表示矩阵宽度，每次推进width-1 int heightP = 0; // 变量heightP存储a[p]的高度 int heightQ = 0; // 变量heightQ存储a[q]的高度 int maxHP = 0; // 变量maxHP存储当前出现的，p方向上最大高度max&#123;a[p]&#125; int maxHQ = 0; // 变量maxHQ存储当前出现的，q方向上最大高度max&#123;a[q]&#125; // 两边指针向中间推进 while (p &lt; q) &#123; heightP = height.at(p); heightQ = height.at(q); // 矩形面积为 S = 宽度 * 两边较小高度 if (heightP &lt; heightQ) &#123; area = weight * heightP; p++; &#125; else &#123; area = weight * heightQ; q--; &#125; if (maxarea &lt; area) &#123; maxarea = area; &#125; weight--; &#125; return maxarea;&#125; Java代码如下（执行用时：6 ms）： 123456789101112public int maxArea(int[] height) &#123; int maxArea = 0, l = 0, r = height.length - 1; while (l &lt; r) &#123; maxArea = Math.max(maxArea, Math.min(height[l], height[r]) * (r - l)); if (height[l] &lt; height[r]) l++; else r--; &#125; return maxArea;&#125; 优化如果移动后当前线段高度小于移动前线段的高度，因为移动后 $weidth$ 等于移动前 $weidth - 1 $，宽度高度均减小，最大矩形区域maxarea一定不会在该情况下出现，可以不用计算当前区域的面积，直接进行下一次指针移动。 再扩展一下，如果当前线段高度小于之前出现的最大高度，因为 $weidth$ 减小，所以最大矩形区域maxarea一定不会在该情况下出现，可以不用计算当前区域的面积，直接进行下一次指针移动。所以需要两个变量（maxHP、maxHQ）来记录左右指针遍历过的线段中的最大高度。这样不用每移动一次就要计算面积并与最大面积比较，减少计算次数。 代码如下（C++，执行时间：16 ms）： 1234567891011121314151617181920212223242526272829303132333435363738394041int maxArea_twoPointer(vector&lt;int&gt;&amp; height) &#123; int p = 0, q = height.size() - 1; // 前指针p，后指针q int maxarea = 0; // 变量area存储每次指针推进（p++或q--）后的矩形区域大小 int area = 0; // 变量maxarea存储当前出现最大的矩形区域 int width = q - p; // 变量width用于表示矩阵宽度，每次推进width-1 int heightP = 0; // 变量heightP存储a[p]的高度 int heightQ = 0; // 变量heightQ存储a[q]的高度 int maxHP = 0; // 变量maxHP存储当前出现的，p方向上最大高度max&#123;a[p]&#125; int maxHQ = 0; // 变量maxHQ存储当前出现的，q方向上最大高度max&#123;a[q]&#125; // 两边指针向中间推进 while (p &lt; q) &#123; heightP = height.at(p); heightQ = height.at(q); // 若当前高度a[p或q]小于当前方向上出现的最大高度，maxarea不会出现 if (heightP &lt; maxHP) &#123; p++; &#125; else if ( heightQ &lt; maxHQ) &#123; q++; &#125; else &#123; // 矩形面积为 S = 宽度 * 两边较小高度 if (heightP &lt; heightQ) &#123; area = width * heightP; p++; &#125; else &#123; area = width * heightQ; q--; &#125; if (maxarea &lt; area) &#123; maxarea = area; &#125; &#125; width--; &#125; return maxarea;&#125; 复杂度分析 时间复杂度：$O(n)$，一次扫描。 空间复杂度：$O(1)$，使用恒定的空间。]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>数组</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数组</tag>
        <tag>双指针</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法-3：桶排序、计数排序、基数排序]]></title>
    <url>%2F2019%2F07%2F17%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%2Falgo-sort-3%2F</url>
    <content type="text"><![CDATA[前两篇文章分析了几种常用排序算法的原理、时间复杂度、空间复杂度、稳定性等；本篇文章会讲三种时间复杂度为$O(n)$的排序算法：桶排序、计数排序、基数排序等。也因为其时间复杂度线性的，我们也称这类排序算法为线性排序（Linear sort）。之所以能够做到线性复杂度，主要原因是，这三个算法不是基于比较的排序算法，都不涉及元素之间的比较操作。 这几种排序算法理解起来都不难，时间、空间复杂度分析起来也很简单，但是对要排序的数据要求很苛刻，所以、学习重点的是掌握这些排序算法的适用场景。 桶排序（Bucket sort）桶排序，，核心思想是将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。 桶排序的时间复杂度为什么是$O(n)$呢？假设排序的数据有n个，我们把它们均匀地划分到m个桶内，每个桶里就有$k = \frac{n}{m}$个元素。每个桶内部使用快速排序，时间复杂度为$O(n\log(n))$。m个桶排序的时间复杂度就是$O(m \cdot k\cdot \log(k))$，因为$k = \frac{n}{m}$，所以整个桶排序的时间复杂度就是$O(n\cdot\log(\frac{n}{m}))$。当桶的个数m接近数据个数n时，$\log(\frac{n}{m})$就是一个非常小的常量，这个时候桶排序的时间复杂度接近$O(n)$。 桶排序是不是可以替代我们之前讲的排序算法呢？答案当然是否定的。刚才做了很多假设。实际上，桶排序对要排序数据的要求是非常苛刻的。首先，要排序的数据需要很容易就能划分成m个桶，并且，桶与桶之间有着天然的大小顺序。 这样每个桶内的数据都排序完之后，桶与桶之间的数据不需要再进行排序。其次，数据在各个桶之间的分布是比较均匀的。如果数据经过桶的划分之后，有些桶里的数据非常多，有些非常少，很不平均，那桶内数据排序的时间复杂度就不是常量级了。在极端情况下，如果数据都被划分到一个桶里，那就退化为$O(n\log(n))$的排序算法了。 桶排序比较适合用在外部排序中所谓的外部排序就是数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。 比如说我们有10GB的订单数据，我们希望按订单金额（假设金额都是正整数）进行排序，但是我们的内存有限，只有几百MB，没办法一次性把10GB的数据都加载到内存中。这个时候该怎么办呢？现在我来讲一下，如何借助桶排序的处理思想来解决这个问题。我们可以先扫描一遍文件，看订单金额所处的数据范围。假设经过扫描之后我们得到，订单金额最小是1元，最大是10万元。我们将所有订单根据金额划分到100个桶里，第一个桶我们存储金额在1元到1000元之内的订单，第二桶存储金额在1001元到2000元之内的订单，以此类推。每一个桶对应一个文件，并且按照金额范围的大小顺序编号命名（00，01，02..99）。理想的情况下，如果订单金额在1到10万之间均匀分布，那订单会被均匀划分到100个文件中，每个小文件中存储大约100MB的订单数据，我们就可以将这100个小文件依次放到内存中，用快排来排序。等所有文件都排好序之后，我们只需要按照文件编号，从小到大依次读取每个小文件中的订单数据，并将其写入到一个文件中，那这个文件中存储的就是按照金额从小到大排序的订单数据了。不过，你可能也发现了，订单按照金额在1元到10万元之间并不一定是均匀分布的，所以10GB订单数据是无法均匀地被划分到100个文件中的。有可能某个金额区间的数据特别多，划分之后对应的文件就会很大，没法一次性读入内存。这又该怎么办呢？ 针对这些划分之后还是比较大的文件，我们可以继续划分，比如，订单金额在1元到1000元之间的比较多，我们就将这个区间继续划分为10个小区间，1元到100元，101元到200元，201元到300元..901元到1000元。如果划分之后，101元到200元之间的订单还是太多，无法一次性读入内存，那就继续再划分，直到所有的文件都能读入内存为止。 计数排序（Counting sort）计数排序与桶排序十分类似。当要排序的n个数据，所处的范围并不大的时候，比如最大值是k，我们就可以把数据划分成k个桶。每个桶内的数据值都是相同的，省掉了桶内排序的时间。我们都经历过高考，高考查分数系统你还记得吗？我们查分数的时候，系统会显示我们的成绩以及所在省的排名。如果你所在的省有50万考生，如何通过成绩快速排序得出名次呢？考生的满分是750分，最小是0分，这个数据的范围很小，所以我们可以分成751个桶，对应分数从0分到750分。根据考生的成绩，我们将这50万考生划分到这750个桶里。桶内的数据都是分数相同的考生，所以并不需要再进行排序。我们只需要依次扫描每个桶，将桶内的考生依次输出到一个数组中，就实现了50万考生的排序。因为只涉及扫描遍历操作，所以时间复杂度是$O(n)$。 计数排序的算法思想就是这么简单，跟桶排序非常类似，只是桶的大小粒度不一样。不过，为什么这个排序算法叫“计数”排序呢？“计数”的含义来自哪里呢？ 想弄明白这个问题，我们就要来看计数排序算法的实现方法。我还拿考生那个例子来解释。为了方便说明，我对数据规模做了简化。 假设只有8个考生，分数在0到5分之间。我们使用数组A[8]存储这8个考生的成绩，它们分别是：{ 2，5，3，0，2，3，0，3 }。 考生的成绩从0到5分，我们使用大小为6的数组C[6]表示桶，其中下标对应分数。不过，C[6]内存储的并不是考生，而是某个分数对应的考生个数。像我刚刚举的那个例子，我们只需要遍历一遍考生分数，就可以得到C[6]的值，{ 2, 0, 2, 3 ,0, 1 }。 假设排序后的有序数组为R[8]，即成绩为3的考生，在R[8]中存储在下标为4，5，6三个位置。那么，我们需要如何快速计算出，每个分数的考生在有序数组R[8]中的位置？ 思路是这样的：我们对C[6]数组顺序求和，C[6]存储的数据就变成了{ 2, 2, 4, 7, 7, 8 }。即C[k]里存储小于等于分数k的考生个数。 我们从后到前依次扫描数组A。当扫描到3时，我们可以从数组C中取出下标为3的值7（ $c[3] = 7$ ），也就是说，到目前为止，包括自己在内，分数小于等于3的考生有7个，也就是说3是数组R中的第7个元素（也就是数组R中下标为6的位置）。当3放入到数组R中后，小于等于3的元素就只剩下了6个了，所以相应的C[3]要减1，变成6。以此类推，当我们扫描到第2个分数为3的考生的时候，就会把它放入数组R中的第6个元素的位置（也就是下标为5的位置）。当我们扫描完整个数组A后，数组R内的数据就是按照分数从小到大有序排列的了。 这种利用另外一个数组来计数的实现方式是不是很巧妙呢？这也是为什么这种排序算法叫计数排序的原因。不过，你千万不要死记硬背上面的排序过程，重要的是理解和会用。我总结一下，计数排序只能用在数据范围不大的场景中，如果数据范围k比要排序的数据n大很多，就不适合用计数排序了。而且，计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数。比如，还是拿考生这个例子。如果考生成绩精确到小数后一位，我们就需要将所有的分数都先乘以10，转化成整数，然后再放到9010个桶内。再比如，如果要排序的数据中有负数，数据的范围是[-1000，1000]，那我们就需要先对每个数据都加1000，转化成非负整数。]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法-2：归并、快速]]></title>
    <url>%2F2019%2F06%2F27%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%2Falgo-sort-2%2F</url>
    <content type="text"><![CDATA[上一篇文章讲了冒泡排序、插入排序、选择排序这三种排序算法，它们的时间复杂度都是$O(n^2)$，比较高，适合小规模数据的排序。而归并排序和快速排序时间复杂度均为$O(n\log(n))$。适合大规模的数据排序。归并排序和快速排序有一个共同点，它们都用到了分治思想。 归并排序（Merge Sort）归并排序的核心思想还是蛮简单的。如果要排序一个数组，我们先把数组从中间分成前后两部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起，这样整个数组就都有序了 这就是分治思想。将一个大问题分解成小的子问题来解决。小的子问题解决了，大问题也就解决了。 分治思想与递归思想很像。分治是一种解决问题的处理思想，递归是一种编程技巧，分治算法一般都是用递归来实现的。 回顾：递归代码两要素：1.递推公式，2.终止条件。然后将递推公式翻译成递归代码。 所以，要想写出归并排序的代码，我们先写出归并排序的递推公式。 12345递推公式：merge_sort(p…r) = merge(merge_sort(p…q), merge_sort(q+1…r))终止条件：p &gt;= r 不用再继续分解 merge_sort(p..r)表示，给下标从p到r之间的数组排序。我们将这个排序问题转化为了两个子问题，merge_sort(p..q)和merge_sort(q+1..r)，其中下标q等于p和r的中间位置，也就是$\frac{(\ p\ +\ r\ )}{2}$。当下标从p到q和从q+1到r这两个子数组都排好序之后，我们再将两个有序的子数组合并在一起，这样下标从p到r之间的数据就也排好序了。当p &gt;= r时，表示数组中只有一个元素。 将递推公式转化成代码（C） 123456789void __merge_sort(int* arr, int p, int r) &#123; int q; if (p &gt;= r) return; q = (p + r) / 2; __merge_sort(arr, p, q); __merge_sort(arr, q + 1, r); __merge(arr, p, q, r);&#125; 你可能已经发现了， __merge()这个函数的作用就是，将已经有序的arr[p..q]和arr[q+1..r]合并成一个有序的数组。那这个过程具体该如何做呢？我们可以申请一个临时数组tmp，大小与arr[p..r]相同。我们用两个游标 i 和 j ，分别指向arr[p..q]和arr[q+1..r]的第一个元素。比较这两个元素arr[i]和arr[j]，如果arr[i]&lt;=arr[j]，我们就把arr[i]放入到临时数组tmp，并且 i 后移一位，否则将arr[j]放入到数组tmp， j 后移一位。继续上述比较过程，直到其中一个子数组中的所有数据都放入临时数组中，再把另一个数组中的数据依次加入到临时数组的未尾，这个时候，临时数组中存储的就是两个子数组合并之后的结果了。最后再把临时数组tmp中的数据拷贝到原数组arr[p..r]中。 代码如下（C）： 1234567891011121314151617181920212223242526272829303132// 合并两个有序数组arr[p]-arr[q]、arr[q+1]-arr[r]，p为下标起点，q为下标中点，r为下标终点void __merge(int* arr, int p, int q, int r) &#123; int* tmp; int i, j, k; // 申请一个临时数组，大小与arr[p...r]相同 tmp = (int*)malloc((r - p + 1) * sizeof(int)); if (!tmp) &#123; abort(); &#125; // 循环判断两个数组中较小的数据，拷贝至临时数组 for (i = p, j = q + 1, k = 0; i &lt;= q &amp;&amp; j &lt;= r;) &#123; if (arr[i] &lt;= arr[j]) &#123; tmp[k++] = arr[i++]; &#125; else &#123; tmp[k++] = arr[j++]; &#125; &#125; // 判断哪个子数组有剩余数据 ，拷贝至临时数组中 if (i == q + 1) &#123; for (; j &lt;= r;) tmp[k++] = arr[j++]; &#125; else &#123; for (; i &lt;= q;) tmp[k++] = arr[i++]; &#125; // 将tmp数组在内存区直接复制到原数组中 memcpy(arr + p, tmp, (r - p + 1) * sizeof(int)); free(tmp);&#125; 归并排序的性能分析还记得分析排序算法的三个问题吗？接下来，我们来看归并排序的三个问题。 归并排序是稳定的排序算法吗？ 是。我们可以很明显看出，归并排序稳不稳定关键要看__merge()函数，也就是两个有序子数组合并成一个大的有序数组的那部分代码。在合并的过程中，如果arr[p..q]和arr[q+1..r]之间有值相同的元素，我们可以先把arr[p..q]中的元素（前部分中的元素）放入tmp数组。这样就保证了值相同的元素，在合并前后的先后顺序不变。所以，归并排序是一个稳定的排序算法。 归并排序的时间复杂度是多少？ 情况 时间复杂度 最好、最坏、平均情况 $O(n\log(n))$ 递归时间复杂度分析较复杂，初学者可以跳过。 回顾：递归的适用场景是，一个问题a可以分解为多个子问题b、c，那求解问题a就可以分解为求解问题b、c。问题b、c解决之后，我们再把b、c的结果合并成a的结果。 如果我们定义求解问题a的时间是T(a)，求解问题b、c的时间分别是T(b)和T(c)，那我们就可以得到这样的递推关系式： 1T(a) = T(b) + T(c) + K 其中K等于将两个子问题b、c的结果合并成问题a的结果所消耗的时间。 套用这个公式，我们来分析一下归并排序的时间复杂度。 我们假设对n个元素进行归并排序需要的时间是T(n)，那分解成两个子数组排序的时间都是T($\frac{n}{2}$)。我们知道，merge0函数合并两个有序子数组的时间复杂度是$O(n)$。所以，套用前面的公式，归并排序的时间复杂度的计算公式就是: 12T(1) = C； n=1 时，只需要常量级的执行时间，所以表示为 C。T(n) = 2*T(n/2) + n； n&gt;1 继续分解： 1234567T(n) = 2*T(n/2) + n = 2*(2*T(n/4) + n/2) + n = 4*T(n/4) + 2*n = 4*(2*T(n/8) + n/4) + 2*n = 8*T(n/8) + 3*n = 8*(2*T(n/16) + n/8) + 3*n = 16*T(n/16) + 4*n ...... = 2^k * T(n/2^k) + k * n ...... 通过这样一步一步分解推导，我们可以得到 ：$$T(n) = 2\cdot k \cdot T(\frac{n}{2^k}) + k\cdot n$$当 $T(\frac{n}{2^k}) = T(1)$时，也就是$\frac{n}{2^k} = 1$，我们得到 $k = log_2(n)$。们将k值代入上面的公式，得到 $T(n) = c \cdot n + n \cdot \log_2(n)$ 。如果我们用大O标记法来表示的话，T(n)就等于$O(n\log(n))$。所以归并排序的时间复杂度是$O(n\log(n))$。 归并排序的空间复杂度是多少？ 归并排序的空间复杂度$O(n)$。不是原地排序算法。 因为归并排序的合并函数，在合并两个有序数组为一个有序数组时，需要借助额外的存储空间。合并完成之后，临时开辟的内存空间就被释放掉了。临时内存空间最大也不会超过n个数据的大小，所以空间复杂度是$O(n)$。 快速排序（Quick Sort）快速排序算法（Quicksort），简称为“快排”。快排利用的也是分治思想。 快排的思想是这样的：如果要排序数组中下标从p到r之间的一组数据arr[p..r]，我们选择p到r之间的任意一个数据作为pivot（分区点）。遍历p到r之间的数据，将小于pivot的放到左边，将大于pivot的放到右边，将pivot放到中间。经过这一步骤之后，数组p到r之间的数据就被分成了三个部分，前面p到q-1之间都是小于pivot的（arr[p..q-1] &lt; pivot），中间是pivot，后面的q+1到r之间是大于pivot的（arr[p..q-1] &gt;= pivot）。 根据分治、递归的处理思想，我们可以用递归排序下标从p到q-1之间的数据和下标从q+1到r之间的数据，直到区间缩小为1，就说明所有的数据都有序了。如果我们用递推公式来将上面的过程写出来的话，就是这样： 12345递推公式：quick_sort(p…r) = quick_sort(p…q-1) + quick_sort(q+1, r)终止条件：p &gt;= r 翻译成代码(C)就是 : 12345678910111213// 快速排序递归函数，p，r为下标void _quick_sort(int* arr, int p, int r) &#123; // q为分区点下标 int q; if (p &gt;= r) &#123; return; &#125; // 获取分区点,对两个分区再快排 q = _quick_partition(arr, p, r); _quick_sort(arr, p, q - 1); _quick_sort(arr, q + 1, r);&#125; 归并排序中有一个 __merge()合并函数，我们这里有一个_quick_partition()分区函数。_quick_partition()分区函数实际上我们前面已经讲过了，就是随机选择一个元素作为pivot（一般情况下，可以选择p到r区间的最后一个元素），然后对arr[p..r]分区，函数返回pivot的下标。如果我们不考虑空间消耗的话，_quick_partition()分区函数可以写得非常简单。我们申请两个临时数组X和Y，遍历arr[p..r]，将小于pivot的元素都拷贝到临时数组X，将大于pivot的元素都拷贝到临时数组Y，最后再将数组X和数组Y中数据顺序拷贝到arr[p..r]。 但是，如果按照这种思路实现的话，_quick_partition()函数就需要很多额外的内存空间，所以快排就不是原地排序算法了。如果我们希望快排是原地排序算法，那它的空间复杂度得是$O(1)$，那_quick_partition()分区函数就不能占用太多额外的内存空间，我们就需要在arr[p..r]的原地完成分区操作。 这里先给出伪代码 123456789101112partition(A, p, r) &#123; pivot := A[r] i := p for j := p to r-1 do &#123; if A[j] &lt; pivot &#123; swap A[i] with A[j] i := i+1 &#125; &#125; swap A[i] with A[r] return i&#125; 这里的思想类似于选择排序。我们通过游标 i把arr[p..r-1]分成两部分。arr[p..i-1]的元素都是小于pivot的，我们暂且叫它“已处理区间“，arr[i..r-1]是“未处理区间“。我们每次都从未处理的区间arr[i..r-1]中取一个元素arr[j]，与pivot对比，如果小于pivot，则将其加入到已处理区间的尾部，也就是A[i]的位置。数组的插入操作还记得吗？在数组某个位置插入元素，需要搬移数据，非常耗时。当时我们也讲了一种处理技巧，就是交换，在$O(1)$的时间复杂度内完成插入操作。这里我们也借助这个思想，只需要将arr[i]与arr[j]交换，就可以在$O(n)$时间复杂度内将arr[j]放到下标为i的位置。 翻译成代码（C）： 12345678910111213141516171819202122232425262728// 交换元素void swap(int* a, int* b) &#123; int tmp = *a; *a = *b; *b = tmp;&#125;// 分区函数，返回分区点下标,取a[r]为pivotint _quick_partition(int* a, int p, int r) &#123; // i将数组分成已处理区间（arr[p]--arr[i-1]）和 // 未处理区间(arr[i]--arr[r-1]) // j遍历arr[p]--arr[r-1] int i,j; i = j = p; for (; j &lt; r ; j++) &#123; // 为方便起见，取a[r]为pivot if (a[j] &lt; a[r]) &#123; if (i != j) &#123; swap(a + i, a + j); &#125; i++; &#125; &#125; swap(a + r, a + i); return i;&#125; 快速排序的性能分析 快速排序是稳定的排序算法吗？ 不是，分区函数采用交换的方式，不是稳定的排序算法。 快速排序的空间复杂度是多少？ 空间复杂度$O(1)$，分区函数采用交换的方式，不需要额外的空间。 快速排序的时间复杂度是多少？ 情况 数组 时间复杂度 最坏情况 已有序 $O(n^2)$ 最好情况、平均情况 $O(n\log(n))$ 快排也是用递归来实现的。对于递归代码的时间复杂度，可以用之前的公式来分析。 12T(1) = C； n=1 时，只需要常量级的执行时间，所以表示为 C。T(n) = 2*T(n/2) + n； n&gt;1 但是，公式成立的前提是每次分区操作，我们选择的pivot都很合适，正好能将大区间对等地一分为二。但实际上这种情况是很难实现的。我举一个比较极端的例子。如果数组中的元素原来已经是有序的了，比如1，3，5，6，8。如果我们每次选择最后一个元素作为pivot，那每次分区得到的两个区间都是不均等的。我们需要进行大约n次分区操作，才能完成快排的整个过程。每次分区我们平均要扫描大约n/2个元素，这种情况下，快排的时间复杂度就从$O(n\log(n))$退化成了$O(n^2)$。我们刚刚讲了两个极端情况下的时间复杂度，一个是分区极其均衡，一个是分区极其不均衡。它们分别对应快排的最好情况时间复杂度和最坏情况时间复杂度。那快排的平均情况时间复杂度是多少呢？我们可以继续套用递归时间复杂度的公式进行求解。因为这边平均情况下的递推过程非常复杂，这里直接给出结论:T(n)在大部分情况下的时间复杂度都可以做到$O(n\log(n))$，只有在极端情况下，才会退化到$O(n^2)$。 解答开篇回到开篇的问题：如何用快排思想在$O(n)$内查找第K大元素？比如，4，2，5，12，3这样一组数据，第3大元素就是4，如何快速地找到它。 快排核心思想就是分治和分区，我们可以利用分区的思想，来解答开篇的问题。我们选择数组区间arr[0..n-1]的最后一个元素arr[n-1]作为pivot，对数组arr[0..n-1]原地分区，这样数组就分成了三部分，arr[0.…p-1]、arr[p]以及arr[p+1..n-1]。 如果p + 1 = K，那arr[p]就是要求解的元素；如果K &gt; p + 1，说明第K大元素出现在arr[p+1..n-1]区间，我们再按照上面的思路递归地在arr[p+1..n-1]这个区间内查找。同理，如果K &lt; p + 1，那我们就在arr[0..p-1]区间查找。 我们再来分析下这样查找的时间复杂度。 第一次分区查找，我们需要对大小为n的数组执行分区操作，需要遍历n个元素；第二次分区查找，我们只需要对大小为 $\frac{n}{2}$ 的数组执行分区操作，需要遍历$\frac{n}{2}$个元素。依次类推，分区遍历元素的个数分别为、$\frac{n}{2}$、$\frac{n}{4}$、$\frac{n}{8}$、$\frac{n}{16}$…..直到区间缩小为1。如果我们把每次分区遍历的元素个数加起来，就是：$$n + \frac{n}{2} + \frac{n}{4} + \frac{n}{8} + .. + 1$$这是一个等比数列求和，最后的和等于$2n-1$ 。所以，上述解决思路的时间复杂度就为$O(n)$。你可能会说，我有个很笨的办法，每次取数组中的最小值，将其移动到数组的最前面，然后在剩下的数组中继续找最小值，以此类推，执行K次，找到的数据不就是第K大元素了吗？不过，时间复杂度就并不是$O(n)$了，而是 $O(K \cdot n)$ 。你可能会说，时间复杂度前面的系数不是可以忽略吗？$O(K \cdot n)$ 不就等于$O(n)$吗？这个可不能这么简单地划等号。当K是比较小的常量时，比如1、2，那最好时间复杂度确实是 $O(n)$ ；但当K等于n/2或者n时，这种最坏情况下的时间复杂度就是 $O(n^2)$ 了。 小结归并排序和快速排序是两种稍微复杂的排序算法，它们用的都是分治的思想，代码都通过递归来实现，过程非常相似。理解归并排序的重点是理解递推公式和merge0合并函数。同理，理解快排的重点也是理解递推公式，还有 partition0分区函数。 归并排序算法是一种在任何情况下时间复杂度都比较稳定的排序算法，这也使它存在致命的缺点，即归并排序不是原地排序算法，空间复杂度比较高，是$O(n)$。正因为此，它也没有快排应用广泛。快速排序算法虽然最坏情况下的时间复杂度是$O(n^2)$ ，但是平均情况下时间复杂度都是$O(n\log(n))$。不仅如此，快速排序算法时间复杂度退化到$O(n^2)$的概率非常小，我们可以通过合理地选择pivot来避免这种情况。 归并排序和快速排序的区别，归并排序的处理过程是由下到上的，先处理子问题，然后再合并。而快排正好相反，它的处理过程是由上到下的，先分区，然后再处理子问题。 思考题现在你有10个接口访问日志文件，每个日志文件大小约300MB，每个文件里的日志都是按照时间戳从小到大排序的。你希望将这10个较小的日志文件，合并为1个日志文件，合并之后的日志仍然按照时间戳从小到大排列。如果处理上述排序任务的机器内存只有1GB，你有什么好的解决思路，能“快速”地将这10个日志文件合并吗？]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法-1：插入、冒泡、选择]]></title>
    <url>%2F2019%2F06%2F17%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%2Falgo-sort-1%2F</url>
    <content type="text"><![CDATA[排序算法可以说是一项基本功，也是大部分程序员学习的第一个算法，一个优秀的算法可以节省大量的资源。目前大部分编程语言都提供了排序函数，但分析理解各种排序算法的特性，结合各个领域中考虑到数据的各种限制和规范，往往能够分析推理一个符合实际的优秀算法。 排序算法太多了，我们将其按照时间复杂度分为3类，分3篇文章进行分析。 注：以下排序均以升序为例 排序算法 时间复杂度 是否基于比较 冒泡、插入、选择 $O(n^2)$ √ 快排、归并 $O(nlogn)$ √ 桶、计数、基数 $O(n)$ × 如何分析一个“排序算法”排序算法的执行效率 最好情况、最坏情况、平均情况的时间复杂度我们在分析算法时，往往需要对最好情况、最坏情况、平均情况进行区分，并且分析对应情况下的时间复杂度。 时间复杂度的系数、常数、低阶时间复杂度反应的是n极大情况下的时间增长趋势，而实际软件开发中，我们需要排序的往往只有10个、20个、100个这种数据。在小规模数据排序情况下，时间复杂度同阶的算法进行对比时，系数、常数、低阶的影响还是比较大的，往往需要进行分析。 比较次数和交换（移动）次数基于比较的排序算法，在执行过程中会涉及到两种操作：一是比较元素的大小，二是元素交换和移动。所以分析排序算法执行效率时，需要考虑元素的比较以及移动次数。 排序算法的内存消耗算法的内存消耗可以通过空间复杂度衡量。针对排序算法，有一个原地排序（Sorted in place）的概念。原地排序，即空间复杂度为$O(1)$的排序算法。本篇的冒泡、插入、选择排序皆为原地排序。 排序算法的稳定性针对排序算法，还有一个重要的指标：稳定性。指的是：待排列的序列（数组）中存在值相等的元素，而这些相等元素经过排序后，相等元素之间原有的顺序是否改变，若不变，则称排序算法稳定，若改变了，不稳定。 冒泡排序（Buddle Sort）冒泡排序只操作相邻的两个元素，每次冒泡操作都会对相邻的两个元素进行比较，根据大小关系，决定是否互换两个元素。一次冒泡操作会至少让一个元素放到正确的位置上，重复n-1次冒泡操作，就完成了n个元素的排序。 以升序为例，假设有一个整型数组a[] = {5，4，6，3，2，1}，第一次冒泡会先对a[0]和a[1]进行比较，即对5和4比较，5比4大，互换元素，此时a[] = {4,5,6,3,2,1}；紧接着再对a[1]和a[2]进行比较，即5和6比较，5比6小，不互换a不变；再对a[2]和a[3]进行比较，6比3大，互换…以此类推，第一次冒泡完成后，数组为a[] = {4,5,3,2,1,6}，其中最大的元素6已经放到了正确的位置上。我们只需要重复n-1次冒泡操作（外层循环次数n-1）即可完成排序。而第二次冒泡时，因为最后一个元素已经正确，我们无需理会，只需要比较前n-1个元素即可，同理，第k次循环只需比较前n-k个元素（内层循环次数n-k）。 代码如下（C++）： 1234567891011121314151617// 冒泡排序，a为数组，n表示数组大小void bubbleSort(int* a, int n) &#123; if (n &lt;= 1) &#123; return; &#125; // 长度为n的数组，需执行n-1次冒泡循环（0到n-2，为方便数组操作，下标从0开始） for (int i = 0; i &lt; n - 1; i++) &#123; // 第k次循环需比较前n-k个元素（k=i+1） for (int j = 0; j &lt; n - i - 1; j++) &#123; if (a[j] &gt;a[j+1]) &#123; // 交换操作 int tmp = a[j]; a[j] = a[j + 1]; a[j + 1] = tmp; &#125; &#125; &#125;&#125; 优化：当某次冒泡操作时，已经没有数据交换，说明序列已经有序，不需要继续执行后续的冒泡操作，可以设置一个标志位提前退出冒泡循环。 代码如下（C++）： 1234567891011121314151617181920212223// 冒泡排序，a为数组，n表示数组大小void bubbleSort(int* a, int n) &#123; if (n &lt;= 1) &#123; return; &#125; // 长度为n的数组，需执行n-1次冒泡循环（0到n-2，为方便数组操作，下标从0开始） for (int i = 0; i &lt; n - 1; i++) &#123; // 提前退出循环的标志位 bool flag = false; // 第k次循环需比较前n-k个元素（k=i+1） for (int j = 0; j &lt; n - i - 1; j++) &#123; if (a[j] &gt;a[j+1]) &#123; // 交换操作 int tmp = a[j]; a[j] = a[j + 1]; a[j + 1] = tmp; flag = true; // 表示存在元素交换 &#125; &#125; if (!flag) &#123; // 不存在元素交换，提前退出 break; &#125; &#125;&#125; 现在，结合排序算法的分析，有三个问题 三个问题 是原地排序吗？ 是，冒泡排序仅涉及相邻元素交换操作，只需常量级临时空间，所以空间复杂度为$O(1)$。 是稳定的排序吗？ 是，冒泡排序时交换元素改变顺序，在元素相同的情况下，可以不做交换，所以冒泡排序是稳定的排序算法。 时间复杂度是多少？ 情况 原始数据展示 时间复杂度 最好情况 {1,2,3,4,5,6} $O(n)$ 最坏情况 {6,5,4,3,2,1} $O(n^2)$ 平均情况 {6,3,2,1,4,5} $O(n^2)$ 最好情况下，需要排序的原序列已经有序，只需进行一次冒泡操作就可以结束，所以时间复杂度为：$O(n)$。 最坏情况下，需要排序的原序列是倒序，需要进行n次冒泡操作，所以时间复杂度为为：$O(n^2)$。 平均情况下，我们可以采用 逆序度 的方式进行分析。 冒泡排序包含两个操作：比较和交换，每交换一次，逆序度减一，所以逆序度表示了原序列到有序序列需要交换的次数，最好情况下逆序度为0，最坏情况下逆序度为$\frac{n \times (n - 1) }{2}$。平均情况我们可以取一个中间值$\frac{n \times (n+1) }{4}$。比较操作肯定比交换操作要多，而复杂度上限为$O(n^2)$，所以平均情况下的时间复杂度就是$O(n^2)$。 插入排序（Insertion Sort）假设已经有一个有序序列，现在需要往其中添加一个新元素，要求添加后仍然有序，该如何操作呢？只需要遍历原有的有序数组，找到新元素应该插入的位置插入即可，插入排序就是这么来的。 首先，我们将序列中的元素分成两个区间：已排序区间以及未排序区间，当然，初始状态下，已排序区间只有一个元素，即第一个元素，插入排序的思维就是取一个未排序区间的数，在已排序区间内找到合适的位置插入，并且保证已排序区间一直有序，直到未排序区间内没有元素，此时排序完成。 插入排序也包含两种操作：元素的比较和元素的交换。对于不同的查找插入点的方法（从头到尾、从尾到头），元素的比较次数是不一样的，而元素的移动次数都是相同的，等于序列的逆序度。 代码如下（C++） 1234567891011121314151617181920// 插入排序 a 表示数组，n 表示数组大小void insertionSort(int* a, int n) &#123; if (n &lt;= 1) &#123; return; &#125; // 先将a[0]看成已排序区间，所以未排序区间从a[1]开始 for (int i = 1; i &lt; n; i++) &#123; int value = a[i]; // j表示需元素需插入的位置，范围[0,i],a[i]为元素原位置，所以从a[i-1]开始比较 int j = i - 1; for (; j &gt;= 0; j--) &#123; if (a[j] &gt; value) &#123; // 若a[j]&gt;a[i],a[j]元素后移一位 a[j + 1] = a[j]; &#125; else &#123; // 若a[j]&lt;=a[i],即a[j+1]为元素需要插入位置 break; &#125; &#125; a[j + 1] = value; &#125;&#125; 还是三个问题 是原地排序吗？ 是，插入排序不需要额外的存储空间（可以将代码中value直接替换成a[i]，增加value是为了代码更容易看懂），所以空间复杂度为$O(1)$，即，插入排序是原地排序算法。 是稳定的排序吗？ 是，插入排序不需要额外的存储空间（可以将代码中value直接替换成a[i]，增加value是为了代码更容易看懂），所以空间复杂度为$O(1)$，即，插入排序是原地排序算法。 时间复杂度是多少？ 情况 原始数据 时间复杂度 最好情况 已有序 $O(n)$ 最坏情况 倒序 $O(n^2)$ 平均情况 $O(n^2)$ 最好情况下，因为采用的是从尾到头遍历有序数据，所以在第一次比较时就会跳出内层循环。因此不需要搬移任何数据，每次比较一个数据就能确定插入位置。所以最好情况下的时间复杂度为$O(n)$。 最坏情况下，序列倒序，相当于每次插入都需要移动大量元素（i个元素）。所以最坏情况的时间复杂度为$O(n^2)$。 平均情况下，因为我们在数组中插入一个元素的平均时间复杂度为$O(n)$，插入排序每次插入都相当于在数组中插入一个元素，重复了n次插入的过程，所以时间复杂度为$O(n^2)$。 选择排序（Selection Sort）选择排序的思想类似于插入排序，将序列分为已排序区间和未排序区间。但选择排序每次都会从未排序区间内寻找最小的元素，放到已排序区间的末尾（交换操作）。所以重复n-1次操作后，序列即有序。 代码如下： 123456789101112131415161718192021// 选择排序 a 表示数组，n 表示数组大小void selectionSort(int* a, int n) &#123; if (n &lt;= 1) &#123; return; &#125; for (int i = 0; i &lt; n - 1; i++) &#123; // 先默认第i个元素为当前最小元素 int minPos = i; int minValue = a[i]; // 因为默认最小为a[i],所以从a[i+1]开始比较寻找最小元素 int j = i + 1; for (; j &lt; n; j++) &#123; if (a[j] &lt; minValue) &#123; // 若a[j]元素比当前最小元素小，则标记a[j]为当前最小元素 minValue = a[j]; minPos = j; &#125; &#125; a[minPos] = a[i]; a[i] = minValue; &#125;&#125; 依旧三个问题 是原地排序吗？ 是，选择排序空间复杂度为 O(1)，是一种原地排序算法。 是稳定的排序吗？ 否，选择排序每次都要找剩余未排序元素中的最小值，并和前面的元素交换，这样破坏了稳定性。 举例：{5,2,3,4,5,1} 第一次操作会将第一个元素5和最后一个元素1交换，这样，两个5的顺序就变了，所以就不稳定。 时间复杂度是多少？ 情况 时间复杂度 最好、最坏、平均情况 $O(n^2)$ 所有情况下，选择排序的时间复杂度均为$O(n^2)$，因为选择排序在任何情况下，遍历的次数都是固定的，第一次循环对n-1个元素执行比较操作；第k次循环，对n-k个元素执行比较操作，总共需要比较(n-1) + (n-2) + ... + 2，即$\frac{(n - 2) \times (n + 1) }{2}$次，所以选择排序时间复杂度恒为$O(n^2)$。 解答开篇回到开篇的问题：冒泡排序和插入排序的时间复杂度都是$O(n^2)$，都是原地排序算法，都稳定，为什么插入排序比冒泡排序更受欢迎呢？ 前面我们分析到：冒泡排序不管怎么买优化，元素交换的次数都是固定值，等于原始序列的逆序度；同样的，插入排序不管怎么优化，元素移动的次数也是原始序列的逆序度。 但是，从代码实现上来看，冒泡排序的元素交换要比插入排序的元素移动复杂，冒泡排序需要3个赋值操作，而插入排序只需要一个。 代码如下： 1234567891011121314冒泡排序中数据的交换操作：if (a[j] &gt; a[j+1]) &#123; // 交换 int tmp = a[j]; a[j] = a[j+1]; a[j+1] = tmp; flag = true;&#125;插入排序中数据的移动操作：if (a[j] &gt; value) &#123; a[j+1] = a[j]; // 数据移动&#125; else &#123; break;&#125; 因此，虽然两者的时间复杂度一致，但如果追求极致的性能优化，肯定首选插入排序。而且，插入排序的算法思想有很大的优化空间，比如希尔排序。 小结分析排序算法三个方面 执行效率、内存消耗、稳定性 排序算法总结 排序算法 是否原地排序 是否稳定 最好 最坏 平均 冒泡排序 是 是 $O(n)$ $O(n^2)$ $O(n^2)$ 插入排序 是 是 $O(n)$ $O(n^2)$ $O(n^2)$ 选择排序 是 否 $O(n^2)$ $O(n^2)$ $O(n^2)$ 冒泡排序、选择排序实际开发应用并不多，但插入排序还是很有用的，有些编程语言的排序函数的实现原理就用到了插入排序算法。 思考题这三种排序算法数据如果存储在链表中，排序算法还能工作吗，如果能，那时间复杂度、空间复杂度又是多少？]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序算法</tag>
      </tags>
  </entry>
</search>
